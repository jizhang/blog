
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Spark快速入门 - Ji ZHANG's Blog</title>
  <meta name="author" content="Ji ZHANG">

  
  <meta name="description" content="Apache Spark是新兴的一种快速通用的大规模数据处理引擎。它的优势有三个方面： 通用计算引擎 能够运行MapReduce、数据挖掘、图运算、流式计算、SQL等多种框架；
基于内存 数据可缓存在内存中，特别适用于需要迭代多次运算的场景；
与Hadoop集成 能够直接读写HDFS中的数据， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://shzhangji.com/blog/2014/12/16/spark-quick-start">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Ji ZHANG's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/jquery.min.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!--<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>-->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37223379-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner"><hgroup>
  <h1><a href="/">Ji ZHANG's Blog</a></h1>
  
    <h2>If I rest, I rust.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:shzhangji.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/categories/tutorial">Tutorial</a></li>
  <li><a href="/blog/categories/translation">Translation</a></li>
  <li><a href="/blog/categories/notes">Notes</a></li>
  <li><a href="/blog/categories/big-data">Big Data</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Spark快速入门</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-12-16T15:59:00+08:00" pubdate data-updated="true">Dec 16<span>th</span>, 2014</time>
        
      </p>
    
  </header>


<div class="entry-content"><p><img src="http://spark.apache.org/images/spark-logo.png" alt="" /></p>

<p><a href="http://spark.apache.org">Apache Spark</a>是新兴的一种快速通用的大规模数据处理引擎。它的优势有三个方面：</p>

<ul>
<li><strong>通用计算引擎</strong> 能够运行MapReduce、数据挖掘、图运算、流式计算、SQL等多种框架；</li>
<li><strong>基于内存</strong> 数据可缓存在内存中，特别适用于需要迭代多次运算的场景；</li>
<li><strong>与Hadoop集成</strong> 能够直接读写HDFS中的数据，并能运行在YARN之上。</li>
</ul>


<p>Spark是用<a href="http://www.scala-lang.org/">Scala语言</a>编写的，所提供的API也很好地利用了这门语言的特性。它也可以使用Java和Python编写应用。本文将用Scala进行讲解。</p>

<h2>安装Spark和SBT</h2>

<ul>
<li>从<a href="http://spark.apache.org/downloads.html">官网</a>上下载编译好的压缩包，解压到一个文件夹中。下载时需注意对应的Hadoop版本，如要读写CDH4 HDFS中的数据，则应下载Pre-built for CDH4这个版本。</li>
<li>为了方便起见，可以将spark/bin添加到$PATH环境变量中：</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">export </span><span class="nv">SPARK_HOME</span><span class="o">=</span>/path/to/spark
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SPARK_HOME</span>/bin
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>在练习例子时，我们还会用到<a href="http://www.scala-sbt.org/">SBT</a>这个工具，它是用来编译打包Scala项目的。Linux下的安装过程比较简单：

<ul>
<li>下载<a href="https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.7/sbt-launch.jar">sbt-launch.jar</a>到$HOME/bin目录；</li>
<li>新建$HOME/bin/sbt文件，权限设置为755，内容如下：</li>
</ul>
</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">SBT_OPTS</span><span class="o">=</span><span class="s2">&quot;-Xms512M -Xmx1536M -Xss1M -XX:+CMSClassUnloadingEnabled -XX:MaxPermSize=256M&quot;</span>
</span><span class='line'>java <span class="nv">$SBT_OPTS</span> -jar <span class="sb">`</span>dirname <span class="nv">$0</span><span class="sb">`</span>/sbt-launch.jar <span class="s2">&quot;$@&quot;</span>
</span></code></pre></td></tr></table></div></figure>




<!-- more -->


<h2>日志分析示例</h2>

<p>假设我们有如下格式的日志文件，保存在/tmp/logs.txt文件中：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>2014-12-11 18:33:52  INFO    Java    some message
</span><span class='line'>2014-12-11 18:34:33   INFO    MySQL   some message
</span><span class='line'>2014-12-11 18:34:54   WARN    Java    some message
</span><span class='line'>2014-12-11 18:35:25   WARN    Nginx   some message
</span><span class='line'>2014-12-11 18:36:09   INFO    Java    some message
</span></code></pre></td></tr></table></div></figure>


<p>每条记录有四个字段，即时间、级别、应用、信息，使用制表符分隔。</p>

<p>Spark提供了一个交互式的命令行工具，可以直接执行Spark查询：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='text'><span class='line'>$ spark-shell
</span><span class='line'>Welcome to
</span><span class='line'>      ____              __
</span><span class='line'>     / __/__  ___ _____/ /__
</span><span class='line'>    _\ \/ _ \/ _ `/ __/  &#39;_/
</span><span class='line'>   /___/ .__/\_,_/_/ /_/\_\   version 1.1.0
</span><span class='line'>      /_/
</span><span class='line'>Spark context available as sc.
</span><span class='line'>scala&gt;
</span></code></pre></td></tr></table></div></figure>


<h3>加载并预览数据</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/tmp/logs.txt&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">lines</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">logs</span><span class="o">.</span><span class="n">txt</span> <span class="nc">MappedRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">12</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">lines</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</span><span class='line'><span class="n">res0</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">33</span><span class="kt">:</span><span class="err">52</span>    <span class="kt">INFO</span>    <span class="kt">Java</span>    <span class="kt">some</span> <span class="kt">message</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>sc是一个SparkContext类型的变量，可以认为是Spark的入口，这个对象在spark-shell中已经自动创建了。</li>
<li>sc.textFile()用于生成一个RDD，并声明该RDD指向的是/tmp/logs.txt文件。RDD可以暂时认为是一个列表，列表中的元素是一行行日志（因此是String类型）。这里的路径也可以是HDFS上的文件，如hdfs://127.0.0.1:8020/user/hadoop/logs.txt。</li>
<li>lines.first()表示调用RDD提供的一个方法：first()，返回第一行数据。</li>
</ul>


<h3>解析日志</h3>

<p>为了能对日志进行筛选，如只处理级别为ERROR的日志，我们需要将每行日志按制表符进行分割：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">logs</span> <span class="k">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;\t&quot;</span><span class="o">))</span>
</span><span class='line'><span class="n">logs</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="nc">MappedRDD</span><span class="o">[</span><span class="err">2</span><span class="o">]</span> <span class="n">at</span> <span class="n">map</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">14</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">logs</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</span><span class='line'><span class="n">res1</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">33</span><span class="kt">:</span><span class="err">52</span><span class="o">,</span> <span class="nc">INFO</span><span class="o">,</span> <span class="nc">Java</span><span class="o">,</span> <span class="n">some</span> <span class="n">message</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>lines.map(f)表示对RDD中的每一个元素使用f函数来处理，并返回一个新的RDD。</li>
<li>line => line.split(&ldquo;\t&rdquo;)是一个匿名函数，又称为Lambda表达式、闭包等。它的作用和普通的函数是一样的，如这个匿名函数的参数是line（String类型），返回值是Array数组类型，因为String.split()函数返回的是数组。</li>
<li>同样使用first()方法来看这个RDD的首条记录，可以发现日志已经被拆分成四个元素了。</li>
</ul>


<h3>过滤并计数</h3>

<p>我们想要统计错误日志的数量：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">errors</span> <span class="k">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">log</span> <span class="k">=&gt;</span> <span class="n">log</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="o">==</span> <span class="s">&quot;ERROR&quot;</span><span class="o">)</span>
</span><span class='line'><span class="n">errors</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="nc">FilteredRDD</span><span class="o">[</span><span class="err">3</span><span class="o">]</span> <span class="n">at</span> <span class="n">filter</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">16</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">errors</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</span><span class='line'><span class="n">res2</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">39</span><span class="kt">:</span><span class="err">42</span><span class="o">,</span> <span class="nc">ERROR</span><span class="o">,</span> <span class="nc">Java</span><span class="o">,</span> <span class="n">some</span> <span class="n">message</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">errors</span><span class="o">.</span><span class="n">count</span><span class="o">()</span>
</span><span class='line'><span class="n">res3</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">158</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>logs.filter(f)表示筛选出满足函数f的记录，其中函数f需要返回一个布尔值。</li>
<li>log(1) == &ldquo;ERROR&#8221;表示获取每行日志的第二个元素（即日志级别），并判断是否等于ERROR。</li>
<li>errors.count()用于返回该RDD中的记录。</li>
</ul>


<h3>缓存</h3>

<p>由于我们还会对错误日志做一些处理，为了加快速度，可以将错误日志缓存到内存中，从而省去解析和过滤的过程：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">errors</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>errors.cache()函数会告知Spark计算完成后将结果保存在内存中。所以说Spark是否缓存结果是需要用户手动触发的。在实际应用中，我们需要迭代处理的往往只是一部分数据，因此很适合放到内存里。</p>

<p>需要注意的是，cache函数并不会立刻执行缓存操作，事实上map、filter等函数都不会立刻执行，而是在用户执行了一些特定操作后才会触发，比如first、count、reduce等。这两类操作分别称为Transformations和Actions。</p>

<h3>显示前10条记录</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">firstTenErrors</span> <span class="k">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
</span><span class='line'><span class="n">firstTenErrors</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">39</span><span class="kt">:</span><span class="err">42</span><span class="o">,</span> <span class="nc">ERROR</span><span class="o">,</span> <span class="nc">Java</span><span class="o">,</span> <span class="n">some</span> <span class="n">message</span><span class="o">),</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">40</span><span class="kt">:</span><span class="err">23</span><span class="o">,</span> <span class="nc">ERROR</span><span class="o">,</span> <span class="nc">Nginx</span><span class="o">,</span> <span class="n">some</span> <span class="n">message</span><span class="o">),</span> <span class="o">...)</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">firstTenErrors</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">log</span> <span class="k">=&gt;</span> <span class="n">log</span><span class="o">.</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;\t&quot;</span><span class="o">)).</span><span class="n">foreach</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">println</span><span class="o">(</span><span class="n">line</span><span class="o">))</span>
</span><span class='line'><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">39</span><span class="kt">:</span><span class="err">42</span>    <span class="kt">ERROR</span>   <span class="kt">Java</span>    <span class="kt">some</span> <span class="kt">message</span>
</span><span class='line'><span class="mi">2014</span><span class="o">-</span><span class="mi">12</span><span class="o">-</span><span class="mi">11</span> <span class="mi">18</span><span class="k">:</span><span class="err">40</span><span class="kt">:</span><span class="err">23</span>    <span class="kt">ERROR</span>   <span class="kt">Nginx</span>   <span class="kt">some</span> <span class="kt">message</span>
</span><span class='line'><span class="o">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>errors.take(n)方法可用于返回RDD前N条记录，它的返回值是一个数组。之后对firstTenErrors的处理使用的是Scala集合类库中的方法，如map、foreach，和RDD提供的接口基本一致。所以说用Scala编写Spark程序是最自然的。</p>

<h3>按应用进行统计</h3>

<p>我们想要知道错误日志中有几条Java、几条Nginx，这和常见的Wordcount思路是一样的。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">apps</span> <span class="k">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">log</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">log</span><span class="o">(</span><span class="mi">2</span><span class="o">),</span> <span class="mi">1</span><span class="o">))</span>
</span><span class='line'><span class="n">apps</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">MappedRDD</span><span class="o">[</span><span class="err">15</span><span class="o">]</span> <span class="n">at</span> <span class="n">map</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">18</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">apps</span><span class="o">.</span><span class="n">first</span><span class="o">()</span>
</span><span class='line'><span class="n">res20</span><span class="k">:</span> <span class="o">(</span><span class="kt">String</span><span class="o">,</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">(</span><span class="nc">Java</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="n">counts</span> <span class="k">=</span> <span class="n">apps</span><span class="o">.</span><span class="n">reduceByKey</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
</span><span class='line'><span class="n">counts</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">ShuffledRDD</span><span class="o">[</span><span class="err">17</span><span class="o">]</span> <span class="n">at</span> <span class="n">reduceByKey</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">20</span>
</span><span class='line'>
</span><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="n">counts</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">t</span> <span class="k">=&gt;</span> <span class="n">println</span><span class="o">(</span><span class="n">t</span><span class="o">))</span>
</span><span class='line'><span class="o">(</span><span class="nc">Java</span><span class="o">,</span><span class="mi">58</span><span class="o">)</span>
</span><span class='line'><span class="o">(</span><span class="nc">Nginx</span><span class="o">,</span><span class="mi">53</span><span class="o">)</span>
</span><span class='line'><span class="o">(</span><span class="nc">MySQL</span><span class="o">,</span><span class="mi">47</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>errors.map(log => (log(2), 1))用于将每条日志转换为键值对，键是应用（Java、Nginx等），值是1，如<code>("Java", 1)</code>，这种数据结构在Scala中称为元组（Tuple），这里它有两个元素，因此称为二元组。</p>

<p>对于数据类型是二元组的RDD，Spark提供了额外的方法，reduceByKey(f)就是其中之一。它的作用是按键进行分组，然后对同一个键下的所有值使用f函数进行归约（reduce）。归约的过程是：使用列表中第一、第二个元素进行计算，然后用结果和第三元素进行计算，直至列表耗尽。如：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">scala</span><span class="o">&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">4</span><span class="o">).</span><span class="n">reduce</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="o">)</span>
</span><span class='line'><span class="n">res23</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">10</span>
</span></code></pre></td></tr></table></div></figure>


<p>上述代码的计算过程即<code>((1 + 2) + 3) + 4</code>。</p>

<p>counts.foreach(f)表示遍历RDD中的每条记录，并应用f函数。这里的f函数是一条打印语句（println）。</p>

<h2>打包应用程序</h2>

<p>为了让我们的日志分析程序能够在集群上运行，我们需要创建一个Scala项目。项目的大致结构是：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">spark</span><span class="o">-</span><span class="n">sandbox</span>
</span><span class='line'><span class="o">├──</span> <span class="n">build</span><span class="o">.</span><span class="n">sbt</span>
</span><span class='line'><span class="o">├──</span> <span class="n">project</span>
</span><span class='line'><span class="o">│</span><span class="err">  </span> <span class="o">├──</span> <span class="n">build</span><span class="o">.</span><span class="n">properties</span>
</span><span class='line'><span class="o">│</span><span class="err">  </span> <span class="o">└──</span> <span class="n">plugins</span><span class="o">.</span><span class="n">sbt</span>
</span><span class='line'><span class="o">└──</span> <span class="n">src</span>
</span><span class='line'>    <span class="o">└──</span> <span class="n">main</span>
</span><span class='line'>        <span class="o">└──</span> <span class="n">scala</span>
</span><span class='line'>            <span class="o">└──</span> <span class="nc">LogMining</span><span class="o">.</span><span class="n">scala</span>
</span></code></pre></td></tr></table></div></figure>


<p>你可以直接使用<a href="https://github.com/jizhang/spark-sandbox">这个项目</a>作为模板。下面说明一些关键部分：</p>

<h3>配置依赖</h3>

<p><code>build.sbt</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-core&quot;</span> <span class="o">%</span> <span class="s">&quot;1.1.1&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>程序内容</h3>

<p><code>src/main/scala/LogMining.scala</code></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">LogMining</span> <span class="k">extends</span> <span class="nc">App</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&quot;LogMining&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">inputFile</span> <span class="k">=</span> <span class="n">args</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="n">inputFile</span><span class="o">)</span>
</span><span class='line'>  <span class="c1">// 解析日志</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">logs</span> <span class="k">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;\t&quot;</span><span class="o">))</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">errors</span> <span class="k">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> <span class="o">==</span> <span class="s">&quot;ERROR&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="c1">// 缓存错误日志</span>
</span><span class='line'>  <span class="n">errors</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
</span><span class='line'>  <span class="c1">// 统计错误日志记录数</span>
</span><span class='line'>  <span class="n">println</span><span class="o">(</span><span class="n">errors</span><span class="o">.</span><span class="n">count</span><span class="o">())</span>
</span><span class='line'>  <span class="c1">// 获取前10条MySQL的错误日志</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">mysqlErrors</span> <span class="k">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">==</span> <span class="s">&quot;MySQL&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="n">mysqlErrors</span><span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="n">mkString</span> <span class="s">&quot;\t&quot;</span><span class="o">).</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</span><span class='line'>  <span class="c1">// 统计每个应用的错误日志数</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">errorApps</span> <span class="k">=</span> <span class="n">errors</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>  <span class="n">errorApps</span><span class="o">.</span><span class="n">countByKey</span><span class="o">().</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>打包运行</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="nb">cd </span>spark-sandbox
</span><span class='line'><span class="nv">$ </span>sbt package
</span><span class='line'><span class="nv">$ </span>spark-submit --class LogMining --master <span class="nb">local </span>target/scala-2.10/spark-sandbox_2.10-0.1.0.jar data/logs.txt
</span></code></pre></td></tr></table></div></figure>


<h2>参考资料</h2>

<ul>
<li><a href="http://spark.apache.org/docs/latest/programming-guide.html">Spark Programming Guide</a></li>
<li><a href="http://www.slideshare.net/cloudera/spark-devwebinarslides-final">Introduction to Spark Developer Training</a></li>
<li><a href="http://www.slideshare.net/liancheng/dtcc-14-spark-runtime-internals">Spark Runtime Internals</a></li>
</ul>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Ji ZHANG</span></span>

      








  


<time datetime="2014-12-16T15:59:00+08:00" pubdate data-updated="true">Dec 16<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/big-data/'>Big Data</a>, <a class='category' href='/blog/categories/tutorial/'>Tutorial</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://shzhangji.com/blog/2014/12/16/spark-quick-start/" data-via="zjerryj" data-counturl="http://shzhangji.com/blog/2014/12/16/spark-quick-start/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/11/27/guidetodatamining-5/" title="Previous Post: 数据挖掘指南[5]进一步探索分类">&laquo; 数据挖掘指南[5]进一步探索分类</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/12/22/guidetodatamining-6/" title="Next Post: 数据挖掘指南[6]概率和朴素贝叶斯">数据挖掘指南[6]概率和朴素贝叶斯 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>


</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/12/22/guidetodatamining-6/">数据挖掘指南[6]概率和朴素贝叶斯</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/16/spark-quick-start/">Spark快速入门</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/27/guidetodatamining-5/">数据挖掘指南[5]进一步探索分类</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/11/07/sbt-offline/">离线环境下构建sbt项目</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/10/30/guidetodatamining-4/">数据挖掘指南[4]分类</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/jizhang">@jizhang</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jizhang',
            count: 3,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
<a href="http://stackoverflow.com/users/1030720/jerry">
<img src="http://stackoverflow.com/users/flair/1030720.png?theme=clean" width="208" height="58" alt="profile for Jerry at Stack Overflow, Q&amp;A for professional and enthusiast programmers" title="profile for Jerry at Stack Overflow, Q&amp;A for professional and enthusiast programmers">
</a>
</section>

<section>
  <h1>On Delicious</h1>
  <div id="delicious"></div>
  <script type="text/javascript" src="http://feeds.delicious.com/v2/json/zjerryj?count=3&amp;sort=date&amp;callback=renderDeliciousLinks"></script>
  <p><a href="http://delicious.com/zjerryj">My Delicious Bookmarks &raquo;</a></p>
</section>


<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/zhangji87@gmail.com?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Ji ZHANG -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jizhang';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://shzhangji.com/blog/2014/12/16/spark-quick-start/';
        var disqus_url = 'http://shzhangji.com/blog/2014/12/16/spark-quick-start/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>






<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
