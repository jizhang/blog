<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Generate Auto-increment Id in Map-reduce Job | Ji ZHANG&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="In DBMS world, it’s easy to generate a unique, auto-increment id, using MySQL’s AUTO_INCREMENT attribute on a primary key or MongoDB’s Counters Collection pattern. But when it comes to a distributed,">
<meta property="og:type" content="article">
<meta property="og:title" content="Generate Auto-increment Id in Map-reduce Job">
<meta property="og:url" content="http://shzhangji.com/blog/2013/10/31/generate-auto-increment-id-in-map-reduce-job/index.html">
<meta property="og:site_name" content="Ji ZHANG&#39;s Blog">
<meta property="og:description" content="In DBMS world, it’s easy to generate a unique, auto-increment id, using MySQL’s AUTO_INCREMENT attribute on a primary key or MongoDB’s Counters Collection pattern. But when it comes to a distributed,">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-10-25T02:36:41.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Generate Auto-increment Id in Map-reduce Job">
<meta name="twitter:description" content="In DBMS world, it’s easy to generate a unique, auto-increment id, using MySQL’s AUTO_INCREMENT attribute on a primary key or MongoDB’s Counters Collection pattern. But when it comes to a distributed,">
<meta name="twitter:creator" content="@zjerryj">
<link rel="publisher" href="zhangji87@gmail.com">
  
    <link rel="alternate" href="/atom.xml" title="Ji ZHANG&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link rel="stylesheet" href="/css/source-code-pro.css">
  
  <link rel="stylesheet" href="/css/style.css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-37223379-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ji ZHANG&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">If I rest, I rust.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/categories/Big-Data">Big Data</a>
        
          <a class="main-nav-link" href="/categories/Programming">Programming</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
        <a class="main-nav-link" href="http://shzhangji.com/cnblogs"><img src="/images/cnblogs.png"></a>
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://shzhangji.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-generate-auto-increment-id-in-map-reduce-job" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2013/10/31/generate-auto-increment-id-in-map-reduce-job/" class="article-date">
  <time datetime="2013-10-31T01:35:00.000Z" itemprop="datePublished">2013-10-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Generate Auto-increment Id in Map-reduce Job
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>In DBMS world, it’s easy to generate a unique, auto-increment id, using MySQL’s <a href="http://dev.mysql.com/doc/refman/5.1/en/example-auto-increment.html" target="_blank" rel="noopener">AUTO_INCREMENT attribute</a> on a primary key or MongoDB’s <a href="http://docs.mongodb.org/manual/tutorial/create-an-auto-incrementing-field/" target="_blank" rel="noopener">Counters Collection</a> pattern. But when it comes to a distributed, parallel processing framework, like Hadoop Map-reduce, it is not that straight forward. The best solution to identify every record in such framework is to use UUID. But when an integer id is required, it’ll take some steps.</p>
<h2 id="Solution-A-Single-Reducer"><a href="#Solution-A-Single-Reducer" class="headerlink" title="Solution A: Single Reducer"></a>Solution A: Single Reducer</h2><p>This is the most obvious and simple one, just use the following code to specify reducer numbers to 1:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p>And also obvious, there are several demerits:</p>
<ol>
<li>All mappers output will be copied to one task tracker.</li>
<li>Only one process is working on shuffel &amp; sort.</li>
<li>When producing output, there’s also only one process.</li>
</ol>
<p>The above is not a problem for small data sets, or at least small mapper outputs. And it is also the approach that Pig and Hive use when they need to perform a total sort. But when hitting a certain threshold, the sort and copy phase will become very slow and unacceptable.</p>
<a id="more"></a>
<h2 id="Solution-B-Increment-by-Number-of-Tasks"><a href="#Solution-B-Increment-by-Number-of-Tasks" class="headerlink" title="Solution B: Increment by Number of Tasks"></a>Solution B: Increment by Number of Tasks</h2><p>Inspired by a <a href="http://mail-archives.apache.org/mod_mbox/hadoop-common-user/200904.mbox/%3C49E13557.7090504@domaintools.com%3E" target="_blank" rel="noopener">mailing list</a> that is quite hard to find, which is inspired by MySQL master-master setup (with auto_increment_increment and auto_increment_offset), there’s a brilliant way to generate a globally unique integer id across mappers or reducers. Let’s take mapper for example:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">JobMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> id;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> increment;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">            InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.setup(context);</span><br><span class="line"></span><br><span class="line">        id = context.getTaskAttemptID().getTaskID().getId();</span><br><span class="line">        increment = context.getConfiguration().getInt(<span class="string">"mapred.map.tasks"</span>, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (increment == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"mapred.map.tasks is zero"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        id += increment;</span><br><span class="line">        context.write(<span class="keyword">new</span> LongWritable(id),</span><br><span class="line">                <span class="keyword">new</span> Text(String.format(<span class="string">"%d, %s"</span>, key.get(), value.toString())));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The basic idea is simple:</p>
<ol>
<li>Set the initial id to current tasks’s id.</li>
<li>When mapping each row, increment the id by the number of tasks.</li>
</ol>
<p>It’s also applicable to reducers.</p>
<h2 id="Solution-C-Sorted-Auto-increment-Id"><a href="#Solution-C-Sorted-Auto-increment-Id" class="headerlink" title="Solution C: Sorted Auto-increment Id"></a>Solution C: Sorted Auto-increment Id</h2><p>Here’s a real senario: we have several log files pulled from different machines, and we want to identify each row by an auto-increment id, and they should be in time sequence order.</p>
<p>We know Hadoop has a sort phase, so we can use timestamp as the mapper output key, and the framework will do the trick. But the sorting thing happends in one reducer (partition, in fact), so when using multiple reducer tasks, the result is not in total order. To achieve this, we can use the <a href="http://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/mapred/lib/TotalOrderPartitioner.html" target="_blank" rel="noopener">TotalOrderPartitioner</a>.</p>
<p>How about the incremental id? Even though the outputs are in total order, Solution B is not applicable here. So we take another approach: seperate the job in two phases, use the reducer to do sorting <em>and</em> counting, then use the second mapper to generate the id.</p>
<p>Here’s what we gonna do:</p>
<ol>
<li>Use TotalOrderPartitioner, and generate the partition file.</li>
<li>Parse logs in mapper A, use time as the output key.</li>
<li>Let the framework do partitioning and sorting.</li>
<li>Count records in reducer, write it with <a href="http://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/mapreduce/lib/output/MultipleOutputs.html" target="_blank" rel="noopener">MultipleOutput</a>.</li>
<li>In mapper B, use count as offset, and increment by 1.</li>
</ol>
<p>To simplify the situation, we assume to have the following inputs and outputs:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> Input       Output</span><br><span class="line"></span><br><span class="line">11:00 a     1 11:00 a</span><br><span class="line">12:00 b     2 11:01 aa</span><br><span class="line">13:00 c     3 11:02 aaa</span><br><span class="line"></span><br><span class="line">11:01 aa    4 12:00 b</span><br><span class="line">12:01 bb    5 12:01 bb</span><br><span class="line">13:01 cc    6 12:02 bbb</span><br><span class="line"></span><br><span class="line">11:02 aaa   7 13:00 c</span><br><span class="line">12:02 bbb   8 13:01 cc</span><br><span class="line">13:02 ccc   9 13:02 ccc</span><br></pre></td></tr></table></figure>
<h3 id="Generate-Partition-File"><a href="#Generate-Partition-File" class="headerlink" title="Generate Partition File"></a>Generate Partition File</h3><p>To use TotalOrderpartitioner, we need a partition file (i.e. boundaries) to tell the partitioner how to partition the mapper outputs. Usually we’ll use <a href="https://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/mapreduce/lib/partition/InputSampler.RandomSampler.html" target="_blank" rel="noopener">InputSampler.RandomSampler</a> class, but this time let’s use a manual partition file.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SequenceFile.Writer writer = <span class="keyword">new</span> SequenceFile.Writer(fs, getConf(), partition,</span><br><span class="line">        Text.class, NullWritable.class);</span><br><span class="line">Text key = <span class="keyword">new</span> Text();</span><br><span class="line">NullWritable value = NullWritable.get();</span><br><span class="line">key.set(<span class="string">"12:00"</span>);</span><br><span class="line">writer.append(key, value);</span><br><span class="line">key.set(<span class="string">"13:00"</span>);</span><br><span class="line">writer.append(key, value);</span><br><span class="line">writer.close();</span><br></pre></td></tr></table></figure>
<p>So basically, the partitioner will partition the mapper outputs into three parts, the first part will be less than “12:00”, seceond part [“12:00”, “13:00”), thrid [“13:00”, ).</p>
<p>And then, indicate the job to use this partition file:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(TotalOrderPartitioner.class);</span><br><span class="line">otalOrderPartitioner.setPartitionFile(job.getConfiguration(), partition);</span><br><span class="line"></span><br><span class="line"><span class="comment">// The number of reducers should equal the number of partitions.</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<h3 id="Use-MutipleOutputs"><a href="#Use-MutipleOutputs" class="headerlink" title="Use MutipleOutputs"></a>Use MutipleOutputs</h3><p>In the reducer, we need to note down the row count of this partition, to do that, we’ll need the MultipleOutputs class, which let use output multiple result files apart from the default “part-r-xxxxx”. The reducer’s code is as following:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">JobReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> MultipleOutputs&lt;NullWritable, Text&gt; mos;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> count;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.setup(context);</span><br><span class="line">        mos = <span class="keyword">new</span> MultipleOutputs&lt;NullWritable, Text&gt;(context);</span><br><span class="line">        count = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Text value : values) &#123;</span><br><span class="line">            context.write(NullWritable.get(), value);</span><br><span class="line">            ++count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.cleanup(context);</span><br><span class="line">        mos.write(<span class="string">"count"</span>, NullWritable.get(), <span class="keyword">new</span> LongWritable(count));</span><br><span class="line">        mos.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>There’re several things to pay attention to:</p>
<ol>
<li>MultipleOutputs is declared as class member, defined in Reducer#setup method, and must be closed at Reducer#cleanup (otherwise the file will be empty).</li>
<li>When instantiating MultipleOutputs class, the generic type needs to be the same as reducer’s output key/value class.</li>
<li>In order to use a different output key/value class, additional setup needs to be done at job definition:</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Job job = <span class="keyword">new</span> Job(getConf());</span><br><span class="line">MultipleOutputs.addNamedOutput(job, <span class="string">"count"</span>, SequenceFileOutputFormat.class,</span><br><span class="line">    NullWritable.class, LongWritable.class);</span><br></pre></td></tr></table></figure>
<p>For example, if the output folder is “/tmp/total-sort/“, there’ll be the following files when job is done:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/tmp/total-sort/count-r-00001</span><br><span class="line">/tmp/total-sort/count-r-00002</span><br><span class="line">/tmp/total-sort/count-r-00003</span><br><span class="line">/tmp/total-sort/part-r-00001</span><br><span class="line">/tmp/total-sort/part-r-00002</span><br><span class="line">/tmp/total-sort/part-r-00003</span><br></pre></td></tr></table></figure>
<h3 id="Pass-Start-Ids-to-Mapper"><a href="#Pass-Start-Ids-to-Mapper" class="headerlink" title="Pass Start Ids to Mapper"></a>Pass Start Ids to Mapper</h3><p>When the second mapper processes the inputs, we want them to know the initial id of its partition, which can be calculated from the <code>count-*</code> files we produce before. To pass this information, we can use the job’s Configuration object.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Read and calculate the start id from those row-count files.</span></span><br><span class="line">Map&lt;String, Long&gt; startIds = <span class="keyword">new</span> HashMap&lt;String, Long&gt;();</span><br><span class="line"><span class="keyword">long</span> startId = <span class="number">1</span>;</span><br><span class="line">FileSystem fs = FileSystem.get(getConf());</span><br><span class="line"><span class="keyword">for</span> (FileStatus file : fs.listStatus(countPath)) &#123;</span><br><span class="line"></span><br><span class="line">    Path path = file.getPath();</span><br><span class="line">    String name = path.getName();</span><br><span class="line">    <span class="keyword">if</span> (!name.startsWith(<span class="string">"count-"</span>)) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    startIds.put(name.substring(name.length() - <span class="number">5</span>), startId);</span><br><span class="line"></span><br><span class="line">    SequenceFile.Reader reader = <span class="keyword">new</span> SequenceFile.Reader(fs, path, getConf());</span><br><span class="line">    NullWritable key = NullWritable.get();</span><br><span class="line">    LongWritable value = <span class="keyword">new</span> LongWritable();</span><br><span class="line">    <span class="keyword">if</span> (!reader.next(key, value)) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    startId += value.get();</span><br><span class="line">    reader.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Serialize the map and pass it to Configuration.</span></span><br><span class="line">job.getConfiguration().set(<span class="string">"startIds"</span>, Base64.encodeBase64String(</span><br><span class="line">        SerializationUtils.serialize((Serializable) startIds)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Recieve it in Mapper#setup</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">JobMapperB</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">NullWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Long&gt; startIds;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> startId;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">super</span>.setup(context);</span><br><span class="line">        startIds = (Map&lt;String, Long&gt;) SerializationUtils.deserialize(</span><br><span class="line">                Base64.decodeBase64(context.getConfiguration().get(<span class="string">"startIds"</span>)));</span><br><span class="line">        String name = ((FileSplit) context.getInputSplit()).getPath().getName();</span><br><span class="line">        startId = startIds.get(name.substring(name.length() - <span class="number">5</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(NullWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        context.write(<span class="keyword">new</span> LongWritable(startId++), value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Set-the-Input-Non-splitable"><a href="#Set-the-Input-Non-splitable" class="headerlink" title="Set the Input Non-splitable"></a>Set the Input Non-splitable</h3><p>When the file is bigger than a block or so (depending on some configuration entries), Hadoop will split it, which is not good for us. So let’s define a new InputFormat class to disable the splitting behaviour:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NonSplitableSequence</span> <span class="keyword">extends</span> <span class="title">SequenceFileInputFormat</span>&lt;<span class="title">NullWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">isSplitable</span><span class="params">(JobContext context, Path filename)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// use it</span></span><br><span class="line">job.setInputFormatClass(NonSplitableSequence.class);</span><br></pre></td></tr></table></figure>
<p>And that’s it, we are able to generate a unique, auto-increment id for a sorted collection, with Hadoop’s parallel computing capability. The process is rather complicated, which requires several techniques about Hadoop. It’s worthwhile to dig.</p>
<p>A workable example can be found in my <a href="https://github.com/jizhang/mapred-sandbox/blob/master/src/main/java/com/shzhangji/mapredsandbox/AutoIncrementId2Job.java" target="_blank" rel="noopener">Github repository</a>. If you have some more straight-forward approach, please do let me know.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://shzhangji.com/blog/2013/10/31/generate-auto-increment-id-in-map-reduce-job/" data-id="cjpfba18p0007jyjkndqtw2z1" class="article-share-link">Share</a>
      
        <a href="http://shzhangji.com/blog/2013/10/31/generate-auto-increment-id-in-map-reduce-job/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/blog/2014/05/27/use-webjars-in-scalatra-project/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Use WebJars in Scalatra Project
        
      </div>
    </a>
  
  
    <a href="/blog/2013/04/30/manage-leiningen-project-configuration/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Manage Leiningen Project Configuration</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/analytics/" style="font-size: 15px;">analytics</a> <a href="/tags/apache-beam/" style="font-size: 10px;">apache beam</a> <a href="/tags/canal/" style="font-size: 10px;">canal</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/crossfilter/" style="font-size: 10px;">crossfilter</a> <a href="/tags/dc-js/" style="font-size: 10px;">dc.js</a> <a href="/tags/eclipse/" style="font-size: 10px;">eclipse</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/es6/" style="font-size: 10px;">es6</a> <a href="/tags/eslint/" style="font-size: 10px;">eslint</a> <a href="/tags/etl/" style="font-size: 11.67px;">etl</a> <a href="/tags/flume/" style="font-size: 13.33px;">flume</a> <a href="/tags/frontend/" style="font-size: 15px;">frontend</a> <a href="/tags/functional-programming/" style="font-size: 10px;">functional programming</a> <a href="/tags/hbase/" style="font-size: 10px;">hbase</a> <a href="/tags/hdfs/" style="font-size: 10px;">hdfs</a> <a href="/tags/hive/" style="font-size: 10px;">hive</a> <a href="/tags/java/" style="font-size: 18.33px;">java</a> <a href="/tags/javascript/" style="font-size: 16.67px;">javascript</a> <a href="/tags/kafka/" style="font-size: 10px;">kafka</a> <a href="/tags/lodash/" style="font-size: 11.67px;">lodash</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine learning</a> <a href="/tags/mapreduce/" style="font-size: 10px;">mapreduce</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/ops/" style="font-size: 10px;">ops</a> <a href="/tags/pandas/" style="font-size: 11.67px;">pandas</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/react/" style="font-size: 10px;">react</a> <a href="/tags/restful/" style="font-size: 10px;">restful</a> <a href="/tags/scala/" style="font-size: 11.67px;">scala</a> <a href="/tags/scalatra/" style="font-size: 10px;">scalatra</a> <a href="/tags/source-code/" style="font-size: 10px;">source code</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/spark-streaming/" style="font-size: 10px;">spark streaming</a> <a href="/tags/spring/" style="font-size: 10px;">spring</a> <a href="/tags/sql/" style="font-size: 11.67px;">sql</a> <a href="/tags/stream-processing/" style="font-size: 13.33px;">stream processing</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/thrift/" style="font-size: 10px;">thrift</a> <a href="/tags/vue/" style="font-size: 10px;">vue</a> <a href="/tags/vuex/" style="font-size: 10px;">vuex</a> <a href="/tags/webjars/" style="font-size: 10px;">webjars</a> <a href="/tags/websocket/" style="font-size: 10px;">websocket</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/05/">May 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">October 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">April 2013</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2018/12/08/spark-datasource-api-v2/">Spark DataSource API V2</a>
          </li>
        
          <li>
            <a href="/blog/2018/10/03/flume-source-code-hdfs-sink/">Flume Source Code: HDFS Sink</a>
          </li>
        
          <li>
            <a href="/blog/2018/09/20/how-to-avoid-null-pointer-exception/">How to Avoid NullPointerException</a>
          </li>
        
          <li>
            <a href="/blog/2018/09/13/is-it-necessary-to-apply-eslint-jsx-no-bind-rule/">Is It Necessary to Apply ESLint jsx-no-bind Rule?</a>
          </li>
        
          <li>
            <a href="/blog/2018/05/14/serve-tensorflow-estimator-with-savedmodel/">Serve TensforFlow Estimator with SavedModel</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-nc-sa.svg"></a>
      <br>
      &copy; 2018 Ji ZHANG<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/categories/Big-Data" class="mobile-nav-link">Big Data</a>
  
    <a href="/categories/Programming" class="mobile-nav-link">Programming</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
  <a href="http://shzhangji.com/cnblogs" class="mobile-nav-link">中文</a>
</nav>

    
<script>
  var disqus_shortname = 'jizhang';
  
  var disqus_url = 'http://shzhangji.com/blog/2013/10/31/generate-auto-increment-id-in-map-reduce-job/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="/js/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>