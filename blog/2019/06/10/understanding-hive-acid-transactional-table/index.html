<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Understanding Hive ACID Transactional Table | Ji ZHANG&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Apache Hive introduced transactions since version 0.13 to fully support ACID semantics on Hive table, including INSERT&#x2F;UPDATE&#x2F;DELETE&#x2F;MERGE statements, streaming data ingestion, etc. In">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding Hive ACID Transactional Table">
<meta property="og:url" content="https://shzhangji.com/blog/2019/06/10/understanding-hive-acid-transactional-table/index.html">
<meta property="og:site_name" content="Ji ZHANG&#39;s Blog">
<meta property="og:description" content="Apache Hive introduced transactions since version 0.13 to fully support ACID semantics on Hive table, including INSERT&#x2F;UPDATE&#x2F;DELETE&#x2F;MERGE statements, streaming data ingestion, etc. In">
<meta property="og:locale">
<meta property="og:image" content="https://shzhangji.com/images/hive-acid/parallel-execution.png">
<meta property="og:image" content="https://shzhangji.com/images/hive-acid/transaction-management.png">
<meta property="article:published_time" content="2019-06-10T12:40:55.000Z">
<meta property="article:modified_time" content="2019-06-10T12:40:55.000Z">
<meta property="article:author" content="Ji ZHANG">
<meta property="article:tag" content="hive">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://shzhangji.com/images/hive-acid/parallel-execution.png">
<meta name="twitter:creator" content="@zjerryj">
<link rel="publisher" href="zhangji87@gmail.com">
  
    <link rel="alternate" href="/atom.xml" title="Ji ZHANG&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="/css/source-code-pro.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-XGPVRTV36D"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XGPVRTV36D');
  </script>
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Ji ZHANG&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">If I rest, I rust.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/categories/Big-Data">Big Data</a>
        
          <a class="main-nav-link" href="/categories/Programming">Programming</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="https://shzhangji.com/cnblogs/">中文</a>
        
      </nav>
      <nav id="sub-nav">
        <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/jizhang" title="GitHub"></a>
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://shzhangji.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-understanding-hive-acid-transactional-table" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/blog/2019/06/10/understanding-hive-acid-transactional-table/" class="article-date">
  <time datetime="2019-06-10T12:40:55.000Z" itemprop="datePublished">2019-06-10</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Big-Data/">Big Data</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Understanding Hive ACID Transactional Table
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><a target="_blank" rel="noopener" href="http://hive.apache.org/">Apache Hive</a> introduced transactions since version 0.13 to fully support ACID semantics on Hive table, including INSERT&#x2F;UPDATE&#x2F;DELETE&#x2F;MERGE statements, streaming data ingestion, etc. In Hive 3.0, this feature is further improved by optimizing the underlying data file structure, reducing constraints on table scheme, and supporting predicate push down and vectorized query. Examples and setup can be found on <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions">Hive wiki</a> and other <a target="_blank" rel="noopener" href="https://hortonworks.com/tutorial/using-hive-acid-transactions-to-insert-update-and-delete-data/">tutorials</a>, while this article will focus on how transactional table is saved on HDFS, and take a closer look at the read-write process.</p>
<h2 id="File-Structure"><a href="#File-Structure" class="headerlink" title="File Structure"></a>File Structure</h2><h3 id="Insert-Data"><a href="#Insert-Data" class="headerlink" title="Insert Data"></a>Insert Data</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employee (id <span class="type">int</span>, name string, salary <span class="type">int</span>)</span><br><span class="line">STORED <span class="keyword">AS</span> ORC TBLPROPERTIES (<span class="string">&#x27;transactional&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;true&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> employee <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">&#x27;Jerry&#x27;</span>, <span class="number">5000</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="string">&#x27;Tom&#x27;</span>,   <span class="number">8000</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="string">&#x27;Kate&#x27;</span>,  <span class="number">6000</span>);</span><br></pre></td></tr></table></figure>

<p>An INSERT statement is executed in a single transaction. It will create a <code>delta</code> directory containing information about this transaction and its data.</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/employee/delta_0000001_0000001_0000</span><br><span class="line">/user/hive/warehouse/employee/delta_0000001_0000001_0000/_orc_acid_version</span><br><span class="line">/user/hive/warehouse/employee/delta_0000001_0000001_0000/bucket_00000</span><br></pre></td></tr></table></figure>

<p>The schema of this folder’s name is <code>delta_minWID_maxWID_stmtID</code>, i.e. “delta” prefix, transactional writes’ range (minimum and maximum write ID), and statement ID. In detail:</p>
<ul>
<li>All INSERT statements will create a <code>delta</code> directory. UPDATE statement will also create <code>delta</code> directory right after a <code>delete</code> directory. <code>delete</code> directory is prefixed with “delete_delta”.</li>
<li>Hive will assign a globally unique ID for every transaction, both read and write. For transactional writes like INSERT and DELETE, it will also assign a table-wise unique ID, a.k.a. a write ID. The write ID range will be encoded in the <code>delta</code> and <code>delete</code> directory names.</li>
<li>Statement ID is used when multiple writes into the same table happen in one transaction.</li>
</ul>
<span id="more"></span>

<p>For its content, <code>_orc_acid_version</code> always contains “2”, indicating this directory is in ACID version 2 format. Compared with previous version, the main difference is that UPDATE now uses split-update technique to support predicate push down and other features (<a target="_blank" rel="noopener" href="https://jira.apache.org/jira/browse/HIVE-14035">HIVE-14035</a>). <code>bucket_00000</code> is the inserted records. Since this table is not bucketed, there is only one file, and it is in <a target="_blank" rel="noopener" href="https://orc.apache.org/">ORC</a> format. We can take a look at its content with <a target="_blank" rel="noopener" href="https://orc.apache.org/docs/java-tools.html">orc-tools</a>:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ orc-tools data bucket_00000</span><br><span class="line">&#123;&quot;operation&quot;:0,&quot;originalTransaction&quot;:1,&quot;bucket&quot;:536870912,&quot;rowId&quot;:0,&quot;currentTransaction&quot;:1,&quot;row&quot;:&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;Jerry&quot;,&quot;salary&quot;:5000&#125;&#125;</span><br><span class="line">&#123;&quot;operation&quot;:0,&quot;originalTransaction&quot;:1,&quot;bucket&quot;:536870912,&quot;rowId&quot;:1,&quot;currentTransaction&quot;:1,&quot;row&quot;:&#123;&quot;id&quot;:2,&quot;name&quot;:&quot;Tom&quot;,&quot;salary&quot;:8000&#125;&#125;</span><br><span class="line">&#123;&quot;operation&quot;:0,&quot;originalTransaction&quot;:1,&quot;bucket&quot;:536870912,&quot;rowId&quot;:2,&quot;currentTransaction&quot;:1,&quot;row&quot;:&#123;&quot;id&quot;:3,&quot;name&quot;:&quot;Kate&quot;,&quot;salary&quot;:6000&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>The file content is displayed in JSON, row-wise. We can see the actual data is in <code>row</code>, while other keys work for transaction mechanism:</p>
<ul>
<li><code>operation</code> 0 means INSERT, 1 UPDATE, and 2 DELETE. UPDATE will not appear because of the split-update technique mentioned above.</li>
<li><code>originalTransaction</code> is the previous write ID. For INSERT, it is the same as <code>currentTransaction</code>. For DELETE, it is the write ID when this record is first created.</li>
<li><code>bucket</code> is a 32-bit integer defined by <code>BucketCodec</code> class. Their meanings are:<ul>
<li>bit 1-3: bucket codec version, currently <code>001</code>.</li>
<li>bit 4: reserved for future.</li>
<li>bit 5-16: the bucket ID, 0-based. This ID is determined by CLUSTERED BY columns and number of buckets. It matches the <code>bucket_N</code> prefixed files.</li>
<li>bit 17-20: reserved for future.</li>
<li>bit 21-32: statement ID.</li>
<li>For instance, the binary form of <code>536936448</code> is <code>00100000000000010000000000000000</code>, showing it is a version 1 codec, and bucket ID is 1.</li>
</ul>
</li>
<li><code>rowId</code> is the auto-generated unique ID within the transaction and bucket.</li>
<li><code>currentTransaction</code> is the current write ID.</li>
<li><code>row</code> contains the actual data. For DELETE, <code>row</code> will be null.</li>
</ul>
<p>We can note that the data rows are ordered by (<code>originalTransaction</code>, <code>bucket</code>, <code>rowId</code>), which is essential for the reading process.</p>
<p>These information can also be viewed by the <code>row__id</code> virtual column:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> row__id, id, name, salary <span class="keyword">FROM</span> employee;</span><br></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;writeid&quot;:1,&quot;bucketid&quot;:536870912,&quot;rowid&quot;:0&#125;    1       Jerry   5000</span><br><span class="line">&#123;&quot;writeid&quot;:1,&quot;bucketid&quot;:536870912,&quot;rowid&quot;:1&#125;    2       Tom     8000</span><br><span class="line">&#123;&quot;writeid&quot;:1,&quot;bucketid&quot;:536870912,&quot;rowid&quot;:2&#125;    3       Kate    6000</span><br></pre></td></tr></table></figure>

<h4 id="Streaming-Data-Ingest-V2"><a href="#Streaming-Data-Ingest-V2" class="headerlink" title="Streaming Data Ingest V2"></a>Streaming Data Ingest V2</h4><p>Hive 3.0 also upgrades the former <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest+V2">Streaming API</a>. Now users or third-party tools like Flume can use the ACID feature writing data continuously into Hive table. These operations will also create <code>delta</code> directories. But mutation is no longer supported.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamingConnection</span> <span class="variable">connection</span> <span class="operator">=</span> HiveStreamingConnection.newBuilder().connect();</span><br><span class="line">connection.beginTransaction();</span><br><span class="line">connection.write(<span class="string">&quot;11,val11,Asia,China&quot;</span>.getBytes());</span><br><span class="line">connection.write(<span class="string">&quot;12,val12,Asia,India&quot;</span>.getBytes());</span><br><span class="line">connection.commitTransaction();</span><br><span class="line">connection.close();</span><br></pre></td></tr></table></figure>

<h3 id="Update-Data"><a href="#Update-Data" class="headerlink" title="Update Data"></a>Update Data</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> employee <span class="keyword">SET</span> salary <span class="operator">=</span> <span class="number">7000</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">2</span>;</span><br></pre></td></tr></table></figure>

<p>This statement will first run a query to find out the <code>row__id</code> of the updating records, and then create a <code>delete</code> directory a long with a <code>delta</code> directory:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/employee/delta_0000001_0000001_0000/bucket_00000</span><br><span class="line">/user/hive/warehouse/employee/delete_delta_0000002_0000002_0000/bucket_00000</span><br><span class="line">/user/hive/warehouse/employee/delta_0000002_0000002_0000/bucket_00000</span><br></pre></td></tr></table></figure>

<p>Content of <code>delete_delta_0000002_0000002_0000/bucket_00000</code>:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;operation&quot;:2,&quot;originalTransaction&quot;:1,&quot;bucket&quot;:536870912,&quot;rowId&quot;:1,&quot;currentTransaction&quot;:2,&quot;row&quot;:null&#125;</span><br></pre></td></tr></table></figure>

<p>Content of <code>delta_0000002_0000002_0000/bucket_00000</code>:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;operation&quot;:0,&quot;originalTransaction&quot;:2,&quot;bucket&quot;:536870912,&quot;rowId&quot;:0,&quot;currentTransaction&quot;:2,&quot;row&quot;:&#123;&quot;id&quot;:2,&quot;name&quot;:&quot;Tom&quot;,&quot;salary&quot;:7000&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>DELETE statement works similarly to UPDATE, i.e. find the record but generate only <code>delete</code> directory.</p>
<h3 id="Merge-Statement"><a href="#Merge-Statement" class="headerlink" title="Merge Statement"></a>Merge Statement</h3><p>MERGE is like MySQL’s INSERT ON UPDATE. It can update target table with a source table. For instance:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> employee_update (id <span class="type">int</span>, name string, salary <span class="type">int</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> employee_update <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">2</span>, <span class="string">&#x27;Tom&#x27;</span>,  <span class="number">7000</span>),</span><br><span class="line">(<span class="number">4</span>, <span class="string">&#x27;Mary&#x27;</span>, <span class="number">9000</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> employee <span class="keyword">AS</span> a</span><br><span class="line"><span class="keyword">USING</span> employee_update <span class="keyword">AS</span> b <span class="keyword">ON</span> a.id <span class="operator">=</span> b.id</span><br><span class="line"><span class="keyword">WHEN</span> MATCHED <span class="keyword">THEN</span> <span class="keyword">UPDATE</span> <span class="keyword">SET</span> salary <span class="operator">=</span> b.salary</span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED <span class="keyword">THEN</span> <span class="keyword">INSERT</span> <span class="keyword">VALUES</span> (b.id, b.name, b.salary);</span><br></pre></td></tr></table></figure>

<p>This statement will update the salary of Tom, and insert a new row of Mary. WHENs are considered different statements. The INSERT clause generates <code>delta_0000002_0000002_0000</code>, containing the row of Mary, while UPDATE generates <code>delete_delta_0000002_0000002_0001</code> and <code>delta_0000002_0000002_0001</code>, deleting and inserting the row of Tom.</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/employee/delta_0000001_0000001_0000</span><br><span class="line">/user/hive/warehouse/employee/delta_0000002_0000002_0000</span><br><span class="line">/user/hive/warehouse/employee/delete_delta_0000002_0000002_0001</span><br><span class="line">/user/hive/warehouse/employee/delta_0000002_0000002_0001</span><br></pre></td></tr></table></figure>

<h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><p>As time goes, there will be more and more <code>delta</code> and <code>delete</code> directories in the table, which will affect the read performance, since reading is a process of merging the results of valid transactions. Small files are neither friendly to file systems like HDFS. So Hive uses two kinds of compactors, namely minor and major, to merge these directories while preserving the transaction information.</p>
<p>Minor compaction will merge multiple <code>delta</code> and <code>delete</code> files into one <code>delta</code> and <code>delete</code> file, respectively. The transaction ID will be preserved in folder name as write ID range, as mentioned above, while omitting the statement ID. Compactions will be automatically initiated in Hive metastore process based on some configured thresholds. We can also trigger it manually with the following SQL:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> employee COMPACT <span class="string">&#x27;minor&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>Take the result of MERGE statement for an instance. After minor compaction, the folder structure will become:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/employee/delete_delta_0000001_0000002</span><br><span class="line">/user/hive/warehouse/employee/delta_0000001_0000002</span><br></pre></td></tr></table></figure>

<p>In <code>delta_0000001_0000002/bucket_00000</code>, rows are simply ordered and concatenated, i.e. two rows of Tom will be both included. Minor compact does not delete any data.</p>
<p>Major compaction, on the other hand, will merge and write the current table into a single directory, with the name <code>base_N</code>, where N is the latest write ID. Deleted data will be removed in major compaction. <code>row_id</code> remains untouched.</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/user/hive/warehouse/employee/base_0000002</span><br></pre></td></tr></table></figure>

<p>Note that after minor or major compaction, the original files will not be deleted immediately. Deletion is carried out by a cleaner thread, so there will be multiple files containing the same transaction data simultaneously. Take this into account when understanding the reading process.</p>
<h2 id="Reading-Process"><a href="#Reading-Process" class="headerlink" title="Reading Process"></a>Reading Process</h2><p>Now we see three kinds of files in an ACID table, <code>base</code>, <code>delta</code>, and <code>delete</code>. Each contains data rows that can be identified by <code>row__id</code> and sorted by it, too. Reading data from an ACID table is a process of merging these files, and reflecting the result of the last transaction. This process is written in <code>OrcInputFormat</code> and <code>OrcRawRecordMerger</code> class, and it is basically a merge-sort algorithm.</p>
<p>Take the following files for an instance. This structure can be generated by: insert three rows, do a major compaction, then update two rows. <code>1-0-0-1</code> is short for <code>originalTransaction</code> - <code>bucketId</code> (not encoded) - <code>rowId</code> - <code>currentTransaction</code>.</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+----------+    +----------+    +----------+</span><br><span class="line">| base_1   |    | delete_2 |    | delta_2  |</span><br><span class="line">+----------+    +----------+    +----------+</span><br><span class="line">| 1-0-0-1  |    | 1-0-1-2  |    | 2-0-0-2  |</span><br><span class="line">| 1-0-1-1  |    | 1-0-2-2  |    | 2-0-1-2  |</span><br><span class="line">| 1-0-2-1  |    +----------+    +----------+</span><br><span class="line">+----------+</span><br></pre></td></tr></table></figure>

<p>Merging process:</p>
<ul>
<li>Sort rows from all files by (<code>originalTransaction</code>, <code>bucketId</code>, <code>rowId</code>) ascendingly, (<code>currentTransaction</code>) descendingly. i.e.<ul>
<li><code>1-0-0-1</code></li>
<li><code>1-0-1-2</code></li>
<li><code>1-0-1-1</code></li>
<li>…</li>
<li><code>2-0-1-2</code></li>
</ul>
</li>
<li>Fetch the first record.</li>
<li>If the <code>row__id</code> is the same as previous, skip.</li>
<li>If the operation is DELETE, skip.<ul>
<li>As a result, for <code>1-0-1-2</code> and <code>1-0-1-1</code>, this row will be skipped.</li>
</ul>
</li>
<li>Otherwise, emit the row.</li>
<li>Repeat.</li>
</ul>
<p>The merging is done in a streaming way. Hive will open all the files, read the first record, and construct a <code>ReaderKey</code> class, storing <code>originalTransaction</code>, <code>bucketId</code>, <code>rowId</code>, and <code>currentTransaction</code>. <code>ReaderKey</code> class implements the <code>Comparable</code> interface, so they can be sorted in an customized order.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RecordIdentifier</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;RecordIdentifier&gt; &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> writeId;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> bucketId;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> rowId;</span><br><span class="line">  <span class="keyword">protected</span> <span class="type">int</span> <span class="title function_">compareToInternal</span><span class="params">(RecordIdentifier other)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (other == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (writeId != other.writeId) &#123;</span><br><span class="line">      <span class="keyword">return</span> writeId &lt; other.writeId ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (bucketId != other.bucketId) &#123;</span><br><span class="line">      <span class="keyword">return</span> bucketId &lt; other.bucketId ? - <span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (rowId != other.rowId) &#123;</span><br><span class="line">      <span class="keyword">return</span> rowId &lt; other.rowId ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ReaderKey</span> <span class="keyword">extends</span> <span class="title class_">RecordIdentifier</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> currentWriteId;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">isDeleteEvent</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(RecordIdentifier other)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">sup</span> <span class="operator">=</span> compareToInternal(other);</span><br><span class="line">    <span class="keyword">if</span> (sup == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (other.getClass() == ReaderKey.class) &#123;</span><br><span class="line">        <span class="type">ReaderKey</span> <span class="variable">oth</span> <span class="operator">=</span> (ReaderKey) other;</span><br><span class="line">        <span class="keyword">if</span> (currentWriteId != oth.currentWriteId) &#123;</span><br><span class="line">          <span class="keyword">return</span> currentWriteId &lt; oth.currentWriteId ? +<span class="number">1</span> : -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (isDeleteEvent != oth.isDeleteEvent) &#123;</span><br><span class="line">          <span class="keyword">return</span> isDeleteEvent ? -<span class="number">1</span> : +<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sup;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Then, the <code>ReaderKey</code> and the file handler will be put into a <code>TreeMap</code>, so every time we poll for the first entry, we can get the desired file handler and read data.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrcRawRecordMerger</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> TreeMap&lt;ReaderKey, ReaderPair&gt; readers = <span class="keyword">new</span> <span class="title class_">TreeMap</span>&lt;&gt;();</span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">next</span><span class="params">(RecordIdentifier recordIdentifier, OrcStruct prev)</span> &#123;</span><br><span class="line">    Map.Entry&lt;ReaderKey, ReaderPair&gt; entry = readers.pollFirstEntry();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Select-Files"><a href="#Select-Files" class="headerlink" title="Select Files"></a>Select Files</h3><p>Previously we pointed out that different transaction files may co-exist at the same time, so Hive needs to first select the files that are valid for the latest transaction. For instance, the following directory structure is the result of these operations: two inserts, one minor compact, one major compact, and one delete.</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delta_0000001_0000001_0000</span><br><span class="line">delta_0000002_0000002_0000</span><br><span class="line">delta_0000001_0000002</span><br><span class="line">base_0000002</span><br><span class="line">delete_delta_0000003_0000003_0000</span><br></pre></td></tr></table></figure>

<p>Filtering process:</p>
<ul>
<li>Consult the Hive Metastore to find out the valid write ID list.</li>
<li>Extract transaction information from files names, including file type, write ID range, and statement ID.</li>
<li>Select the <code>base</code> file with the maximum valid write ID.</li>
<li>Sort <code>delta</code> and <code>delete</code> files by write ID range:<ul>
<li>Smaller <code>minWID</code> orders first;</li>
<li>If <code>minWID</code> is the same, larger <code>maxWID</code> orders first;</li>
<li>Otherwise, sort by <code>stmtID</code>; files w&#x2F;o <code>stmtID</code> orders first.</li>
</ul>
</li>
<li>Use the <code>base</code> file’s write ID as the current write ID, then iterate and filter <code>delta</code> files:<ul>
<li>If <code>maxWID</code> is larger than the current write ID, keep it, and update the current write ID;</li>
<li>If write ID range is the same as previous, keep the file, too.</li>
</ul>
</li>
</ul>
<p>There are some special cases in this process, e.g. no <code>base</code> file, multiple statements, contains original data files, even ACID version 1 files. More details can be found in <code>AcidUtils#getAcidState</code>.</p>
<h3 id="Parallel-Execution"><a href="#Parallel-Execution" class="headerlink" title="Parallel Execution"></a>Parallel Execution</h3><p>When executing in parallel environment, such as multiple Hadoop mappers, <code>delta</code> files need to be re-organized. In short, <code>base</code> and <code>delta</code> files can be divided into different splits, while all <code>delete</code> files have to be available to all splits. This ensures deleted records will not be emitted.</p>
<p><img src="/images/hive-acid/parallel-execution.png" alt="Parallel Execution"></p>
<h3 id="Vectorized-Query"><a href="#Vectorized-Query" class="headerlink" title="Vectorized Query"></a>Vectorized Query</h3><p>For <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution">vectoried query</a>, Hive will first try to load all <code>delete</code> files into memory and construct an optimized data structure that can be used to filter out deleted rows when processing row batches. If the <code>delete</code> files are too large, it falls back to sort-merge algorithm.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">VectorizedOrcAcidRowBatchReader</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> DeleteEventRegistry deleteEventRegistry;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">interface</span> <span class="title class_">DeleteEventRegistry</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">findDeletedRecords</span><span class="params">(ColumnVector[] cols, <span class="type">int</span> size, BitSet selectedBitSet)</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ColumnizedDeleteEventRegistry</span> <span class="keyword">implements</span> <span class="title class_">DeleteEventRegistry</span> &#123;&#125;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SortMergedDeleteEventRegistry</span> <span class="keyword">implements</span> <span class="title class_">DeleteEventRegistry</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">next</span><span class="params">(NullWritable key, VectorizedRowBatch value)</span> &#123;</span><br><span class="line">    <span class="type">BitSet</span> <span class="variable">selectedBitSet</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BitSet</span>(vectorizedRowBatchBase.size);</span><br><span class="line">    <span class="built_in">this</span>.deleteEventRegistry.findDeletedRecords(innerRecordIdColumnVector,</span><br><span class="line">        vectorizedRowBatchBase.size, selectedBitSet);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">setBitIndex</span> <span class="operator">=</span> selectedBitSet.nextSetBit(<span class="number">0</span>), selectedItr = <span class="number">0</span>;</span><br><span class="line">        setBitIndex &gt;= <span class="number">0</span>;</span><br><span class="line">        setBitIndex = selectedBitSet.nextSetBit(setBitIndex+<span class="number">1</span>), ++selectedItr) &#123;</span><br><span class="line">      value.selected[selectedItr] = setBitIndex;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Transaction-Management"><a href="#Transaction-Management" class="headerlink" title="Transaction Management"></a>Transaction Management</h2><p>Hive introduced a new lock manager to support transactional tables. <code>DbTxnManager</code> will detect the ACID operations in query plan and contact the Hive Metastore to open and commit new transactions. It also implements the read-write lock mechanism to support normal locking requirements.</p>
<p><img src="/images/hive-acid/transaction-management.png" alt="Transaction Management"></p>
<p>The Hive Metastore is responsible for allocating new transaction IDs. This is done in a database transaction so that multiple Metastore instances will not conflict with each other.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">TxnHandler</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> List&lt;Long&gt; <span class="title function_">openTxns</span><span class="params">(Connection dbConn, Statement stmt, OpenTxnRequest rqst)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> sqlGenerator.addForUpdateClause(<span class="string">&quot;select ntxn_next from NEXT_TXN_ID&quot;</span>);</span><br><span class="line">    s = <span class="string">&quot;update NEXT_TXN_ID set ntxn_next = &quot;</span> + (first + numTxns);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">long</span> <span class="variable">i</span> <span class="operator">=</span> first; i &lt; first + numTxns; i++) &#123;</span><br><span class="line">      txnIds.add(i);</span><br><span class="line">      rows.add(i + <span class="string">&quot;,&quot;</span> + quoteChar(TXN_OPEN) + <span class="string">&quot;,&quot;</span> + now + <span class="string">&quot;,&quot;</span> + now + <span class="string">&quot;,&quot;</span></span><br><span class="line">          + quoteString(rqst.getUser()) + <span class="string">&quot;,&quot;</span> + quoteString(rqst.getHostname()) + <span class="string">&quot;,&quot;</span> + txnType.getValue());</span><br><span class="line">    &#125;</span><br><span class="line">    List&lt;String&gt; queries = sqlGenerator.createInsertValuesStmt(</span><br><span class="line">        <span class="string">&quot;TXNS (txn_id, txn_state, txn_started, txn_last_heartbeat, txn_user, txn_host, txn_type)&quot;</span>, rows);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions">Hive Transactions</a></li>
<li><a target="_blank" rel="noopener" href="https://www.slideshare.net/Hadoop_Summit/transactional-operations-in-apache-hive-present-and-future-102803358">Transactional Operations in Apache Hive</a></li>
<li><a target="_blank" rel="noopener" href="https://orc.apache.org/docs/acid.html">ORCFile ACID Support</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://shzhangji.com/blog/2019/06/10/understanding-hive-acid-transactional-table/" data-id="clcx0u1wl002ac9oz1yrj13un" class="article-share-link">Share</a>
      
        <a href="https://shzhangji.com/blog/2019/06/10/understanding-hive-acid-transactional-table/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/" rel="tag">hadoop</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hive/" rel="tag">hive</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/blog/2019/08/24/deploy-flink-job-cluster-on-kubernetes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Deploy Flink Job Cluster on Kubernetes
        
      </div>
    </a>
  
  
    <a href="/blog/2018/12/23/real-time-exactly-once-etl-with-apache-flink/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Real-time Exactly-once ETL with Apache Flink</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithm/" style="font-size: 10px;">algorithm</a> <a href="/tags/analytics/" style="font-size: 14.29px;">analytics</a> <a href="/tags/apache-beam/" style="font-size: 10px;">apache beam</a> <a href="/tags/bootstrap/" style="font-size: 10px;">bootstrap</a> <a href="/tags/canal/" style="font-size: 10px;">canal</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/connect/" style="font-size: 10px;">connect</a> <a href="/tags/crossfilter/" style="font-size: 10px;">crossfilter</a> <a href="/tags/dc-js/" style="font-size: 10px;">dc.js</a> <a href="/tags/devops/" style="font-size: 10px;">devops</a> <a href="/tags/eclipse/" style="font-size: 10px;">eclipse</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/es6/" style="font-size: 10px;">es6</a> <a href="/tags/eslint/" style="font-size: 11.43px;">eslint</a> <a href="/tags/etl/" style="font-size: 12.86px;">etl</a> <a href="/tags/flask/" style="font-size: 12.86px;">flask</a> <a href="/tags/flink/" style="font-size: 11.43px;">flink</a> <a href="/tags/flume/" style="font-size: 12.86px;">flume</a> <a href="/tags/frontend/" style="font-size: 17.14px;">frontend</a> <a href="/tags/functional-programming/" style="font-size: 10px;">functional programming</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a> <a href="/tags/hbase/" style="font-size: 10px;">hbase</a> <a href="/tags/hdfs/" style="font-size: 11.43px;">hdfs</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/hive/" style="font-size: 11.43px;">hive</a> <a href="/tags/java/" style="font-size: 18.57px;">java</a> <a href="/tags/javascript/" style="font-size: 15.71px;">javascript</a> <a href="/tags/kafka/" style="font-size: 11.43px;">kafka</a> <a href="/tags/kubernetes/" style="font-size: 11.43px;">kubernetes</a> <a href="/tags/lodash/" style="font-size: 11.43px;">lodash</a> <a href="/tags/machine-learning/" style="font-size: 10px;">machine learning</a> <a href="/tags/mapreduce/" style="font-size: 10px;">mapreduce</a> <a href="/tags/mysql/" style="font-size: 10px;">mysql</a> <a href="/tags/openapi/" style="font-size: 10px;">openapi</a> <a href="/tags/ops/" style="font-size: 10px;">ops</a> <a href="/tags/pandas/" style="font-size: 11.43px;">pandas</a> <a href="/tags/parcel/" style="font-size: 10px;">parcel</a> <a href="/tags/pinia/" style="font-size: 10px;">pinia</a> <a href="/tags/prometheus/" style="font-size: 10px;">prometheus</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/react/" style="font-size: 10px;">react</a> <a href="/tags/restful/" style="font-size: 11.43px;">restful</a> <a href="/tags/scala/" style="font-size: 11.43px;">scala</a> <a href="/tags/scalatra/" style="font-size: 10px;">scalatra</a> <a href="/tags/source-code/" style="font-size: 10px;">source code</a> <a href="/tags/spark/" style="font-size: 14.29px;">spark</a> <a href="/tags/spark-streaming/" style="font-size: 10px;">spark streaming</a> <a href="/tags/spring/" style="font-size: 12.86px;">spring</a> <a href="/tags/spring-boot/" style="font-size: 11.43px;">spring boot</a> <a href="/tags/spring-security/" style="font-size: 10px;">spring security</a> <a href="/tags/sql/" style="font-size: 11.43px;">sql</a> <a href="/tags/sqlalchemy/" style="font-size: 11.43px;">sqlalchemy</a> <a href="/tags/stream-processing/" style="font-size: 12.86px;">stream processing</a> <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a> <a href="/tags/thrift/" style="font-size: 10px;">thrift</a> <a href="/tags/typescript/" style="font-size: 12.86px;">typescript</a> <a href="/tags/vite/" style="font-size: 10px;">vite</a> <a href="/tags/vue/" style="font-size: 15.71px;">vue</a> <a href="/tags/vuex/" style="font-size: 10px;">vuex</a> <a href="/tags/webjars/" style="font-size: 10px;">webjars</a> <a href="/tags/webpack/" style="font-size: 10px;">webpack</a> <a href="/tags/websocket/" style="font-size: 10px;">websocket</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/05/">May 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">October 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">April 2013</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/blog/2023/01/15/restful-api-authentication-with-spring-security/">RESTful API Authentication with Spring Security</a>
          </li>
        
          <li>
            <a href="/blog/2023/01/09/mock-api-in-parcel-project/">Mock API in Parcel Project</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/31/configure-git-line-endings-across-oses/">Configure Git Line Endings Across OSes</a>
          </li>
        
          <li>
            <a href="/blog/2022/08/10/configure-logging-for-flask-sqlalchemy-project/">Configure Logging for Flask SQLAlchemy Project</a>
          </li>
        
          <li>
            <a href="/blog/2022/07/31/use-composition-api-and-pinia-in-vue-2-project/">Use Composition API and Pinia in Vue 2 Project</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://mirrors.creativecommons.org/presskit/buttons/80x15/svg/by-nc-sa.svg"></a>
      <br>
      &copy; 2023 Ji ZHANG<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/categories/Big-Data" class="mobile-nav-link">Big Data</a>
  
    <a href="/categories/Programming" class="mobile-nav-link">Programming</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="https://shzhangji.com/cnblogs/" class="mobile-nav-link">中文</a>
  
</nav>

    
<script>
  var disqus_shortname = 'jizhang';
  
  var disqus_url = 'https://shzhangji.com/blog/2019/06/10/understanding-hive-acid-transactional-table/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>



<script src="/js/jquery.min.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


  </div>
</body>
</html>