<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Translation | Ji ZHANG's Blog]]></title>
  <link href="http://shzhangji.com/blog/categories/translation/atom.xml" rel="self"/>
  <link href="http://shzhangji.com/"/>
  <updated>2015-01-15T12:30:37+08:00</updated>
  <id>http://shzhangji.com/</id>
  <author>
    <name><![CDATA[Ji ZHANG]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[数据挖掘指南[8]聚类]]></title>
    <link href="http://shzhangji.com/blog/2015/01/15/guidetodatamining-8/"/>
    <updated>2015-01-15T12:24:00+08:00</updated>
    <id>http://shzhangji.com/blog/2015/01/15/guidetodatamining-8</id>
    <content type="html"><![CDATA[<p>原文：<a href="http://guidetodatamining.com/chapter-8/">http://guidetodatamining.com/chapter-8/</a></p>

<p>前几章我们学习了如何构建分类系统，使用的是已经标记好类别的数据集进行训练：</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-8/chapter-8-1.png" alt="" /></p>

<p>训练完成后我们就可以用来预测了：这个人看起来像是篮球运动员，那个人可能是练体操的；这个人三年内不会患有糖尿病。</p>

<p>可以看到，分类器在训练阶段就已经知道各个类别的名称了。那如果我们不知道呢？如何构建一个能够自动对数据进行分组的系统？比如有1000人，每人有20个特征，我想把这些人分为若干个组。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-8/chapter-8-2.png" alt="" /></p>

<p>这个过程叫做聚类：通过物品特征来计算距离，并自动分类到不同的群集或组中。有两种聚类算法比较常用：</p>

<p><strong>k-means聚类算法</strong></p>

<p>我们会事先告诉这个算法要将数据分成几个组，比如“请把这1000个人分成5个组”，“将这些网页分成15个组”。这种方法就叫k-means，我们会在后面的章节讨论。</p>

<h2>层次聚类法</h2>

<p>对于层次聚类法，我们不需要预先指定分类的数量，这个算方法会将每条数据都当作是一个分类，每次迭代的时候合并距离最近的两个分类，直到剩下一个分类为止。因此聚类的结果是：顶层有一个大分类，这个分类下有两个子分类，每个子分类下又有两个子分类，依此类推，层次聚类也因此得命。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-8/chapter-8-3.png" alt="" /></p>

<p>在合并的时候我们会计算两个分类之间的距离，可以采用不同的方法。如下图中的A、B、C三个分类，我们应该将哪两个分类合并起来呢？</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-8/chapter-8-4.png" alt="" /></p>

<p><a href="https://github.com/jizhang/guidetodatamining/blob/master/chapter-8.md">前往GitHub阅读全文</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据挖掘指南[7]朴素贝叶斯和文本数据]]></title>
    <link href="http://shzhangji.com/blog/2014/12/30/guidetodatamining-7/"/>
    <updated>2014-12-30T11:40:00+08:00</updated>
    <id>http://shzhangji.com/blog/2014/12/30/guidetodatamining-7</id>
    <content type="html"><![CDATA[<p>原文：<a href="http://guidetodatamining.com/chapter-7/">http://guidetodatamining.com/chapter-7/</a></p>

<h2>非结构化文本的分类算法</h2>

<p>在前几个章节中，我们学习了如何使用人们对物品的评价（五星、顶和踩）来进行推荐；还使用了他们的隐式评价——买过什么，点击过什么；我们利用特征来进行分类，如身高、体重、对法案的投票等。这些数据有一个共性——能用表格来展现：</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-7/chapter-7-1.png" alt="" /></p>

<p>因此这类数据我们称为“结构化数据”——数据集中的每条数据（上表中的一行）由多个特征进行描述（上表中的列）。而非结构化的数据指的是诸如电子邮件文本、推特信息、博客、新闻等。这些数据至少第一眼看起来是无法用一张表格来展现的。</p>

<p>举个例子，我们想从推特信息中获取用户对各种电影的评价：</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-7/chapter-7-2.png" alt="" /></p>

<p>可以看到，Andy Gavin喜欢看地心引力，因为他的消息中有“不寒而栗”、“演的太棒了”之类的文本。而Debra Murphy则不太喜欢这部电影，因为她说“还是省下看这部电影的钱吧”。如果有人说“我太想看这部电影了，都兴奋坏了！”，我们可以看出她是喜欢这部电影的，即使信息中有“坏”这个字。</p>

<p>我在逛超市时看到一种叫Chobani的酸奶，名字挺有趣的，但真的好吃吗？于是我掏出iPhone，谷歌了一把，看到一篇名为“女人不能只吃面包”的博客：</p>

<blockquote><p><strong>无糖酸奶品评</strong></p>

<p>你喝过Chobani酸奶吗？如果没有，就赶紧拿起钥匙出门去买吧！虽然它是脱脂原味的，但喝起来和酸奶的口感很像，致使我每次喝都有负罪感，因为这分明就是在喝全脂酸奶啊！原味的感觉很酸很够味，你也可以尝试一下蜂蜜口味的。我承认，虽然我在减肥期间不该吃蜂蜜的，但如果我有一天心情很糟想吃甜食，我就会在原味酸奶里舀一勺蜂蜜，太值得了！至于那些水果味的，应该都有糖分在里面，但其实酸奶本身就已经很美味了，水果只是点缀。如果你家附近没有Chobani，也可以试试Fage，同样好吃。</p>

<p>虽然需要花上一美元不到，而且还会增加20卡路里，但还是很值得的，毕竟我已经一下午没吃东西了！</p>

<p>来源：<a href="http://womandoesnotliveonbreadalone.blogspot.com/2009/03/sugar-free-yogurt-reviews.html">http://womandoesnotliveonbreadalone.blogspot.com/2009/03/sugar-free-yogurt-reviews.html</a></p></blockquote>

<p>这是一篇正面评价吗？从第二句就可以看出，作者非常鼓励我去买。她还用了“够味”、“美味”等词汇，这些都是正面的评价。所以，让我先去吃会儿……</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-7/chapter-7-3.png" alt="" /></p>

<p><a href="https://github.com/jizhang/guidetodatamining/blob/master/chapter-7.md">前往GitHub阅读全文</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据挖掘指南[6]概率和朴素贝叶斯]]></title>
    <link href="http://shzhangji.com/blog/2014/12/22/guidetodatamining-6/"/>
    <updated>2014-12-22T10:33:00+08:00</updated>
    <id>http://shzhangji.com/blog/2014/12/22/guidetodatamining-6</id>
    <content type="html"><![CDATA[<p>原文：<a href="http://guidetodatamining.com/chapter-6">http://guidetodatamining.com/chapter-6</a></p>

<h2>朴素贝叶斯</h2>

<p>还是让我们回到运动员的例子。如果我问你Brittney Griner的运动项目是什么，她有6尺8寸高，207磅重，你会说“篮球”；我再问你对此分类的准确度有多少信心，你会回答“非常有信心”。</p>

<p>我再问你Heather Zurich，6尺1寸高，重176磅，你可能就不能确定地说她是打篮球的了，至少不会像之前判定Brittney那样肯定。因为从Heather的身高体重来看她也有可能是跑马拉松的。</p>

<p>最后，我再问你Yumiko Hara的运动项目，她5尺4寸高，95磅重，你也许会说她是跳体操的，但也不太敢肯定，因为有些马拉松运动员也是类似的身高体重。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-6/chapter-6-1.png" alt="" /></p>

<p>使用近邻算法时，我们很难对分类结果的置信度进行量化。但如果使用的是基于概率的分类算法——贝叶斯算法——那就可以给出分类结果的可能性了：这名运动员有80%的几率是篮球运动员；这位病人有40%的几率患有糖尿病；拉斯克鲁塞斯24小时内有雨的概率是10%。</p>

<p>近邻算法又称为<strong>被动学习</strong>算法。这种算法只是将训练集的数据保存起来，在收到测试数据时才会进行计算。如果我们有10万首音乐，那每进行一次分类，都需要遍历这10万条记录才行。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-6/chapter-6-2.png" alt="" /></p>

<p>贝叶斯算法则是一种<strong>主动学习</strong>算法。它会根据训练集构建起一个模型，并用这个模型来对新的记录进行分类，因此速度会快很多。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-6/chapter-6-3.png" alt="" /></p>

<p>所以说，贝叶斯算法的两个优点即：能够给出分类结果的置信度；以及它是一种主动学习算法。</p>

<p><a href="https://github.com/jizhang/guidetodatamining/blob/master/chapter-6.md">前往GitHub阅读全文</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据挖掘指南[5]进一步探索分类]]></title>
    <link href="http://shzhangji.com/blog/2014/11/27/guidetodatamining-5/"/>
    <updated>2014-11-27T12:00:00+08:00</updated>
    <id>http://shzhangji.com/blog/2014/11/27/guidetodatamining-5</id>
    <content type="html"><![CDATA[<p>原文：<a href="http://guidetodatamining.com/chapter-5">http://guidetodatamining.com/chapter-5</a></p>

<h2>效果评估算法和kNN</h2>

<p>让我们回到上一章中运动项目的例子。</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-5/chapter-5-1.png" alt="" /></p>

<p>在那个例子中，我们编写了一个分类器程序，通过运动员的身高和体重来判断她参与的运动项目——体操、田径、篮球等。</p>

<p>上图中的Marissa Coleman，身高6尺1寸，重160磅，我们的分类器可以正确的进行预测：</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>cl = Classifier(&lsquo;athletesTrainingSet.txt&rsquo;)
cl.classify([73, 160])
&lsquo;Basketball&rsquo;
```</p></blockquote></blockquote></blockquote>

<p>对于身高4尺9寸，90磅重的人：</p>

<p>```python</p>

<blockquote><blockquote><blockquote><p>cl.classify([59, 90])
&lsquo;Gymnastics&rsquo;
```</p></blockquote></blockquote></blockquote>

<p>当我们构建完一个分类器后，应该问以下问题：</p>

<ul>
<li>分类器的准确度如何？</li>
<li>结果理想吗？</li>
<li>如何与其它分类器做比较？</li>
</ul>


<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-5/chapter-5-2.png" alt="" /></p>

<p><a href="https://github.com/jizhang/guidetodatamining/blob/master/chapter-5.md">前往GitHub阅读全文</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据挖掘指南[4]分类]]></title>
    <link href="http://shzhangji.com/blog/2014/10/30/guidetodatamining-4/"/>
    <updated>2014-10-30T12:00:00+08:00</updated>
    <id>http://shzhangji.com/blog/2014/10/30/guidetodatamining-4</id>
    <content type="html"><![CDATA[<p>原文：<a href="http://guidetodatamining.com/chapter-4">http://guidetodatamining.com/chapter-4</a></p>

<p>在上几章中我们使用用户对物品的评价来进行推荐，这一章我们将使用物品本身的特征来进行推荐。这也是潘多拉音乐站所使用的方法。</p>

<p>内容：</p>

<ul>
<li>潘多拉推荐系统简介</li>
<li>特征值选择的重要性</li>
<li>示例：音乐特征值和邻域算法</li>
<li>数据标准化</li>
<li>修正的标准分数</li>
<li>Python代码：音乐，特征，以及简单的邻域算法实现</li>
<li>一个和体育相关的示例</li>
<li>特征值抽取方式一览</li>
</ul>


<h2>根据物品特征进行分类</h2>

<p>前几章我们讨论了如何使用协同过滤来进行推荐，由于使用的是用户产生的各种数据，因此又称为社会化过滤算法。比如你购买了Phoenix专辑，我们网站上其他购买过这张专辑的用户还会去购买Vampire的专辑，因此会把它推荐给你；我在Netflix上观看了Doctor Who，网站会向我推荐Quantum Leap，用的是同样的原理。我们同时也讨论了协同过滤会遇到的种种问题，包括数据的稀疏性和算法的可扩展性。此外，协同过滤算法倾向于推荐那些已经很流行的物品。试想一个极端的例子：一个新乐队发布了专辑，这张专辑还没有被任何用户评价或购买过，那它将永远不会出现在推荐列表中。</p>

<blockquote><p><strong>这类推荐系统会让流行的物品更为流行，冷门的物品更无人问津。</strong></p>

<p>&mdash; Daniel Fleder &amp; Kartik Hosanagar 2009 《推荐系统对商品分类的影响》</p></blockquote>

<p>这一章我们来看另一种推荐方法。以潘多拉音乐站举例，在这个站点上你可以设立各种音乐频道，只需为这个频道添加一个歌手，潘多拉就会播放和这个歌手风格相类似的歌曲。比如我添加了Phoenix乐队，潘多拉便会播放El Ten Eleven的歌曲。它并没有使用协同过滤，而是通过计算得到这两个歌手的音乐风格是相似的。其实在播放界面上可以看到推荐理由：</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-4/chapter-4-1.png" alt="" /></p>

<p>“根据你目前告知的信息，我们播放的这首歌曲有着相似的旋律，使用了声响和电音的组合，即兴的吉他伴奏。”在我的Hiromi音乐站上，潘多拉会播放E.S.T.的歌曲，因为“它有着古典爵士乐风，一段高水准的钢琴独奏，轻盈的打击乐，以及有趣的歌曲结构。”</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-4/chapter-4-2.png" alt="" /></p>

<p>潘多拉网站的推荐系统是基于一个名为音乐基因的项目。他们雇佣了专业的音乐家对歌曲进行分类（提取它们的“基因”）。这些音乐家会接受超过150小时的训练，之后便可用20到30分钟的时间来分析一首歌曲。这些乐曲特征是很专业的：</p>

<p><img src="https://github.com/jizhang/guidetodatamining/raw/master/img/chapter-4/chapter-4-3.png" alt="" /></p>

<p>这些专家要甄别400多种特征，平均每个月会有15000首新歌曲，因此这是一项非常消耗人力的工程。</p>

<blockquote><p>注意：潘多拉的音乐基因项目是商业机密，我不曾了解它的任何信息。下文讲述的是如何构造一个类似的系统。</p></blockquote>

<p><a href="https://github.com/jizhang/guidetodatamining/blob/master/chapter-4.md">前往GitHub阅读全文</a></p>
]]></content>
  </entry>
  
</feed>
