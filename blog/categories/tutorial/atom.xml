<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tutorial | Ji ZHANG's Blog]]></title>
  <link href="http://shzhangji.com/blog/categories/tutorial/atom.xml" rel="self"/>
  <link href="http://shzhangji.com/"/>
  <updated>2013-06-15T23:17:07+08:00</updated>
  <id>http://shzhangji.com/</id>
  <author>
    <name><![CDATA[Ji ZHANG]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Clojure实战(5)：Storm实时计算框架]]></title>
    <link href="http://shzhangji.com/blog/2013/04/22/cia-storm/"/>
    <updated>2013-04-22T12:11:00+08:00</updated>
    <id>http://shzhangji.com/blog/2013/04/22/cia-storm</id>
    <content type="html"><![CDATA[<h2>Storm简介</h2>

<p>上一章介绍的Hadoop工具能够对海量数据进行批量处理，采用分布式的并行计算架构，只需使用其提供的MapReduce API编写脚本即可。但随着人们对数据实时性的要求越来越高，如实时日志分析、实时推荐系统等，Hadoop就无能为力了。</p>

<p>这时，Storm诞生了。它的设计初衷就是提供一套分布式的实时计算框架，实现低延迟、高并发的海量数据处理，被誉为“Realtime Hadoop”。它提供了简单易用的API接口用于编写实时处理脚本；能够和现有各类消息系统整合；提供了HA、容错、事务、RPC等高级特性。</p>

<p>Storm的官网是：<a href="http://storm-project.net/">storm-project.net</a>，它的<a href="https://github.com/nathanmarz/storm/wiki">Wiki</a>上有非常详尽的说明文档。</p>

<h3>Storm与Clojure</h3>

<p>Storm的主要贡献者<a href="https://github.com/nathanmarz">Nathan Marz</a>和<a href="https://github.com/xumingming">徐明明</a>都是活跃的Clojure开发者，因此在Storm框架中也提供了原生的<a href="https://github.com/nathanmarz/storm/wiki/Clojure-DSL">Clojure DSL</a>。本文就将介绍如何使用这套DSL来编写Storm处理脚本。</p>

<p>Storm集群的安装配置这里不会讲述，具体请参考<a href="https://github.com/nathanmarz/storm/wiki/Setting-up-a-Storm-cluster">这篇文档</a>。下文的脚本都运行在“本地模式”之下，因此即使不搭建集群也可以运行和调试。</p>

<!-- more -->


<h2>Storm脚本的组件</h2>

<p><img src="http://storm-project.net/images/topology.png" height="200"></p>

<p>Storm脚本的英文名称叫做“Storm Topology”，直译过来是“拓扑结构”。这个脚本由两大类组建构成，<code>Spout</code>和<code>Bolt</code>，分别可以有任意多个。他们之间以“数据流”的方式连接起来，因此整体看来就像一张拓扑网络，因此得名<code>Topology</code>。</p>

<h3>Spout</h3>

<p>数据源节点，是整个脚本的入口。Storm会不断调用该节点的<code>nextTuple()</code>方法来获取数据，分发给下游<code>Bolt</code>节点。<code>nextTuple()</code>方法中可以用各种方式从外部获取数据，如逐行读取一个文件、从消息队列（ZeroMQ、Kafka）中获取消息等。一个Storm脚本可以包含多个<code>Spout</code>节点，从而将多个数据流汇聚到一起进行处理。</p>

<h3>Bolt</h3>

<p>数据处理节点，它是脚本的核心逻辑。它含有一个<code>execute()</code>方法，当接收到消息时，Storm会调用这个函数，并将消息传递给它。我们可以在<code>execute()</code>中对消息进行过滤（只接收符合条件的数据），或者进行聚合（统计某个条件的数据出现的次数）等。处理完毕后，这个节点可以选择将处理后的消息继续传递下去，或是持久化到数据库中。</p>

<p><code>Bolt</code>同样是可以有多个的，且能够前后组合。<code>Bolt C</code>可以同时收取<code>Bolt A</code>和<code>Bolt B</code>的数据，并将处理结果继续传递给<code>Bolt D</code>。</p>

<p>此外， <em>一个Bolt可以产生多个实例</em> ，如某个<code>Bolt</code>包含复杂耗时的计算，那在运行时可以调高其并发数量（实例的个数），从而达到并行处理的目的。</p>

<h3>Tuple</h3>

<p><code>Tuple</code>是消息传输的基本单元，一条消息即一个<code>Tuple</code>。可以将其看做是一个<code>HashMap</code>对象，它能够包含任何可序列化的数据内容。对于简单的数据类型，如整型、字符串、Map等，Storm提供了内置的序列化支持。而用户自定义的数据类型，可以通过指定序列化/反序列化函数来处理。</p>

<h3>Stream Grouping</h3>

<p>想象一个<code>Spout</code>连接了两个<code>Bolt</code>（或一个<code>Bolt</code>的两个实例），那数据应该如何分发呢？你可以选择轮询（<code>ShuffleGrouping</code>），或是广播（<code>GlobalGrouping</code>）、亦或是按照某一个字段进行哈希分组（<code>FieldGrouping</code>），这些都称作为<a href="https://github.com/nathanmarz/storm/wiki/Concepts#stream-groupings"><code>Stream Grouping</code></a>。</p>

<h2>示例：WordCount</h2>

<p>下面我们就来实现一个实时版的WordCount脚本，它由以下几个组件构成：</p>

<ul>
<li>sentence-spout：从已知的一段文字中随机选取一句话发送出来；</li>
<li>split-bolt：将这句话按空格分割成单词；</li>
<li>count-bolt：统计每个单词出现的次数，每五秒钟打印一次，并清零。</li>
</ul>


<h3>依赖项和配置文件</h3>

<p>首先使用<code>lein new</code>新建一个项目，并修改<code>project.clj</code>文件：</p>

<p>```clojure
(defproject cia-storm "0.1.0-SNAPSHOT"
  ...
  :dependencies [[org.clojure/clojure "1.4.0"]</p>

<pre><code>             [org.clojure/tools.logging "0.2.6"]]
</code></pre>

<p>  :profiles {:dev {:dependencies [[storm "0.8.2"]]}}
  :plugins [[lein2-eclipse "2.0.0"]]
  :aot [cia-storm.wordcount])
```</p>

<p>其中<code>:profiles</code>表示定义不同的用户配置文件。Leiningen有类似于Maven的配置文件体系（profile），每个配置文件中可以定义<code>project.clj</code>所支持的各种属性，执行时会进行合并。<code>lein</code>命令默认调用<code>:dev</code>、<code>:user</code>等配置文件，可以使用<code>lein with-profiles prod run</code>来指定配置文件。具体可以参考<a href="https://github.com/technomancy/leiningen/blob/master/doc/PROFILES.md">这份文档</a>。</p>

<p>这里将<code>[storm "0.8.2"]</code>依赖项定义在了<code>:dev</code>配置下，如果直接定义在外层的<code>:dependencies</code>下，那在使用<code>lein uberjar</code>进行打包时，会将<code>storm.jar</code>包含在最终的Jar包中，提交到Storm集群运行时就会报冲突。而<code>lein uberjar</code>默认会跳过<code>:dev</code>配置，所以才这样定义。</p>

<p><code>:aot</code>表示<code>Ahead Of Time</code>，即预编译。我们在<a href="http://shzhangji.com/blog/2012/12/16/cia-noir-3/">Clojure实战（3）</a>中提过<code>:gen-class</code>这个标识表示为当前<code>.clj</code>文件生成一个<code>.class</code>文件，从而能够作为<code>main</code>函数使用，因此也需要在<code>project.clj</code>中添加<code>:main</code>标识，指向这个<code>.clj</code>文件的命名空间。如果想为其它的命名空间也生成对应的<code>.class</code>文件，就需要用到<code>:aot</code>了。它的另一个用处是加速Clojure程序的启动速度。</p>

<h3>sentence-spout</h3>

<p>```clojure
(ns cia-storm.wordcount
  ...
  (:use [backtype.storm clojure config]))</p>

<p>(defspout sentence-spout ["sentence"]
  [conf context collector]
  (let [sentences ["a little brown dog"</p>

<pre><code>               "the man petted the dog"
               "four score and seven years ago"
               "an apple a day keeps the doctor away"]]
(spout
  (nextTuple []
    (Thread/sleep 1000)
    (emit-spout! collector [(rand-nth sentences)])))))
</code></pre>

<p>```</p>

<p><code>defspout</code>是定义在<code>backtype.storm.clojure</code>命名空间下的宏，可以<a href="https://github.com/nathanmarz/storm/blob/master/storm-core/src/clj/backtype/storm/clojure.clj#L93">点此</a>查看源码。以下是各个部分的说明：</p>

<ul>
<li><code>sentence-spout</code>是该组件的名称。</li>
<li><code>["sentence"]</code>表示该组件输出一个字段，名称为“sentence”。</li>
<li><code>[conf context collector]</code>用于接收Storm框架传入的参数，如配置对象、上下文对象、下游消息收集器等。</li>
<li><code>spout</code>表示开始定义数据源组件需要用到的各类方法。它实质上是生成一个实现了ISpout接口的对象，从而能够被Storm框架调用。</li>
<li><code>nextTuple</code>是ISpout接口必须实现的方法之一，Storm会不断调用这个方法，获取数据。这里使用<code>Thread#sleep</code>函数来控制调用的频率。</li>
<li><code>emit-spout!</code>是一个函数，用于向下游发送消息。</li>
</ul>


<p>ISpout还有open、ack、fail等函数，分别表示初始化、消息处理成功的回调、消息处理失败的回调。这里我们暂不深入讨论。</p>

<h3>split-bolt</h3>

<p>```clojure
(defbolt split-bolt ["word"] {:prepare true}
  [conf context collector]
  (bolt</p>

<pre><code>(execute [tuple]
  (let [words (.split (.getString tuple 0) " ")]
    (doseq [w words]
      (emit-bolt! collector [w])))
  (ack! collector tuple))))
</code></pre>

<p>```</p>

<p><code>defbolt</code>用于定义一个Bolt组件。整段代码的结构和<code>defspout</code>是比较相似的。<code>bolt</code>宏会实现为一个IBolt对象，<code>execute</code>是该接口的方法之一，其它还有<code>prepare</code>和<code>cleanup</code>。<code>execute</code>方法接收一个参数<code>tuple</code>，用于接收上游消息。</p>

<p><code>ack!</code>是<code>execute</code>中必须调用的一个方法。Storm会对每一个组件发送出来的消息进行追踪，上游组件发出的消息需要得到下游组件的“确认”（ACKnowlege），否则会一直堆积在内存中。对于Spout而言，如果消息得到确认，会触发<code>ISpout#ack</code>函数，否则会触发<code>ISpout#fail</code>函数，这时Spout可以选择重发或报错。</p>

<p>代码中比较怪异的是<code>{:prepare true}</code>。<code>defspout</code>和<code>defbolt</code>有两种定义方式，即prepare和非prepare。两者的区别在于：</p>

<ul>
<li>参数不同，prepare方式下接收的参数是<code>[conf context collector]</code>，非prepare方式下，<code>defspout</code>接收的是<code>[collector]</code>，<code>defbolt</code>是[tuple collector]`。</li>
<li>prepare方式下需要调用<code>spout</code>和<code>bolt</code>宏来编写组件代码，而非prepare方式则不需要——<code>defspout</code>会默认生成<code>nextTuple()</code>函数，<code>defbolt</code>默认生成<code>execute(tuple)</code>。</li>
<li>只有prepare方式下才能指定<code>ISpout#open</code>、<code>IBolt#prepare</code>等函数，非prepare不能。</li>
<li><code>defspout</code>默认使用prepare方式，<code>defbolt</code>默认使用非prepare方式。</li>
</ul>


<p>因此，<code>split-bolt</code>可以按如下方式重写：</p>

<p>```clojure
(defbolt split-bolt ["word"]
  [tuple collector]
  (let [words (.split (.getString tuple 0) " ")]</p>

<pre><code>(doseq [w words]
  (emit-bolt! collector [w]))
(ack! collector tuple)))
</code></pre>

<p>```</p>

<p>prepare方式可以用于在组件中保存状态，具体请看下面的计数Bolt。</p>

<h3>count-bolt</h3>

<p>```clojure
(defbolt count-bolt [] {:prepare true}
  [conf context collector]
  (let [counts (atom {})]</p>

<pre><code>(bolt
  (execute [tuple]
    (let [word (.getString tuple 0)]
      (swap! counts (partial merge-with +) {word 1}))
    (ack! collector tuple)))))
</code></pre>

<p>```</p>

<h4>原子（Atom）</h4>

<p><code>atom</code>是我们遇到的第一个可变量（Mutable Variable），其它的有Ref、Agent等。Atom是“原子”的意思，我们很容易想到原子性操作，即同一时刻只有一个线程能够修改Atom的值，因此它是处理并发的一种方式。这里我们使用Atom来保存每个单词出现的数量。以下是Atom的常用操作：</p>

<p><code>clojure
user=&gt; (def cnt (atom 0))
user=&gt; (println @cnt) ; 使用@符号获取Atom中的值。
0
user=&gt; (swap! cnt inc) ; 将cnt中的值置换为(inc @cnt)，并返回该新的值
1
user=&gt; (println @cnt)
1
user=&gt; (swap! cnt + 10) ; 新值为(+ @cnt 10)
11
user=&gt; (reset! cnt 0) ; 归零
0
</code></p>

<p>需要注意的是，<code>(swap! atom f arg ...)</code>中的<code>f</code>函数可能会被执行多次，因此要确保它没有副作用（side-effect，即不会产生其它状态的变化）。</p>

<p>再来解释一下<code>(partial merge-with +)</code>。<code>merge-with</code>函数是对map类型的一种操作，表示将一个或多个map合并起来。和<code>merge</code>不同的是，<code>merge-with</code>多接收一个<code>f</code>函数（<code>merge-with [f &amp; maps]</code>），当键名重复时，会用<code>f</code>函数去合并它们的值，而不是直接替代。</p>

<p><code>partial</code>可以简单理解为给函数设定默认值，如：</p>

<p><code>clojure
user=&gt; (defn add [a b] (+ a b))
user=&gt; (add 5 10)
15
user=&gt; (def add-5 (partial add 5))
user=&gt; (add-5 10)
15
</code></p>

<p>这样一来，<code>(swap! counts (partial merge-with +) {word 1})</code>就可理解为：将<code>counts</code>这个Atom中的值（一个map类型）和<code>{word 1}</code>这个map进行合并，如果单词已存在，则递增1。</p>

<h4>线程（Thread）</h4>

<p>为了输出统计值，我们为count-bolt增加prepare方法：</p>

<p>```clojure
...</p>

<pre><code>(bolt
  (prepare [conf context collector]
    (.start (Thread. (fn []
                       (while (not (Thread/interrupted))
                         (logging/info
                           (clojure.string/join ", "
                             (for [[word count] @counts]
                               (str word ": " count))))
                         (reset! counts {})
                         (Thread/sleep 5000)))))))
</code></pre>

<p>...
```</p>

<p>这段代码的功能是：在Bolt开始处理消息之前启动一个线程，每隔5秒钟将<code>(atom counts)</code>中的单词出现次数打印出来，并对其进行清零操作。</p>

<p>这里我们直接使用了Java的Thread类型。读者可能会觉得好奇，Thread类型的构造函数只接收实现Runnable接口的对象，Clojure的匿名函数直接支持吗？我们做一个简单测试：</p>

<p><code>clojure
user=&gt; (defn greet [name] (println "Hi" name))
user=&gt; (instance? Runnable greet)
true
user=&gt; (instance? Runnable #(+ 1 %))
true
</code></p>

<p><code>logging</code>命名空间对应的依赖是<code>[org.clojure/tools.logging "0.2.6"]</code>，需要将其添加到<code>project.clj</code>中，它是对log4j组件的包装。这里之所以没有使用<code>println</code>输出到标准输出，是为了将该脚本上传到Storm集群中运行时也能查看到日志输出。</p>

<h3>定义和执行Topology</h3>

<p>各个组件已经定义完毕，下面让我们用它们组成一个Topology：</p>

<p>```clojure
(defn mk-topology []
  (topology</p>

<pre><code>{"sentence" (spout-spec sentence-spout)}
{"split" (bolt-spec {"sentence" :shuffle}
                    split-bolt
                    :p 3)
 "count" (bolt-spec {"split" ["word"]}
                     count-bolt
                     :p 2)}))
</code></pre>

<p>```</p>

<p><code>topology</code>同样是Clojure DSL定义的宏，它接收两个map作为参数，一个用于定义使用到的Spout，一个则是Bolt。该map的键是组件的名称，该名称用于确定各组件之间的关系。</p>

<p><code>spout-spec</code>和<code>bolt-spec</code>则定义了组件在Topology中更具体的参数。如"split"使用的是<code>split-bolt</code>这个组件，它的上游是"sentence"，使用shuffleGrouping来对消息进行分配，<code>:p 3</code>表示会启动3个<code>split-bolt</code>实例。</p>

<p>"count"使用<code>count-bolt</code>组件，上游是"split"，但聚合方式采用了fieldGrouping，因此列出了执行哈希运算时使用的消息字段（word）。为何要使用fieldGrouping？因为我们会开启两个<code>count-bolt</code>，如果采用shuffleGrouping，那单词“a”第一次出现的消息会发送给一个<code>count-bolt</code>，第二次出现会发送给另一个<code>count-bolt</code>，这样统计结果就会错乱。如果指定了<code>:p 1</code>，即只开启一个<code>count-bolt</code>实例，就不会有这样的问题。</p>

<h4>本地模式和Cluster模式</h4>

<p>```clojure
(ns cia-storm.wordcount
  (:import [backtype.storm StormSubmitter LocalCluster])
  ...
  (:gen-class))</p>

<p>(defn run-local! []
  (let [cluster (LocalCluster.)]</p>

<pre><code>(.submitTopology cluster
  "wordcount" {} (mk-topology))
(Thread/sleep 30000)
(.shutdown cluster)))
</code></pre>

<p>(defn submit-topology! [name]
  (StormSubmitter/submitTopology</p>

<pre><code>name {TOPOLOGY-WORKERS 3} (mk-topology)))
</code></pre>

<p>(defn -main
  ([]</p>

<pre><code>(run-local!))
</code></pre>

<p>  ([name]</p>

<pre><code>(submit-topology! name)))
</code></pre>

<p>```</p>

<p>我们为WordCount生成一个类，它的<code>main</code>函数在没有命令行参数时会以本地模式执行Topology，若传递了参数（即指定了脚本在Cluster运行时的名称），则提交至Cluster。</p>

<p>这里直接使用了Storm的Java类，对参数有疑惑的可以参考<a href="http://nathanmarz.github.io/storm/doc-0.8.1/">Javadoc</a>。<code>TOPOLOGY-WORKERS</code>是在<code>backtype.storm.config</code>命名空间中定义的，我们在前面的代码中<code>:use</code>过了。Storm这个项目是用Java和Clojure混写的，所以查阅代码时还需仔细一些。</p>

<h4>运行结果</h4>

<p>首先我们直接用<code>lein</code>以本地模式运行该Topology：</p>

<p><code>bash
$ lein run -m cia-storm.wordcount
6996 [Thread-18] INFO  cia-storm.wordcount  - doctor: 17, the: 31, a: 29, an: 17, ago: 13, seven: 13, and: 13
6998 [Thread-21] INFO  cia-storm.wordcount  - four: 13, keeps: 17, away: 17, score: 13, petted: 7, brown: 12, little: 12, years: 13, man: 7, apple: 17, dog: 19, day: 17
11997 [Thread-18] INFO  cia-storm.wordcount  - ago: 6, seven: 6, and: 6, doctor: 7, an: 7, the: 39, a: 28
11998 [Thread-21] INFO  cia-storm.wordcount  - four: 6, keeps: 7, away: 7, score: 6, petted: 16, brown: 21, little: 21, years: 6, man: 16, apple: 7, dog: 37, day: 7
</code></p>

<p>Cluster模式需要搭建本地集群，可以参考<a href="https://github.com/nathanmarz/storm/wiki/Setting-up-a-Storm-cluster">这篇文档</a>。下文使用的<code>storm</code>命令则需要配置<code>~/.storm/storm.yaml</code>文件，具体请参考<a href="https://github.com/nathanmarz/storm/wiki/Setting-up-development-environment#starting-and-stopping-topologies-on-a-remote-cluster">这篇文章</a>。</p>

<p><code>bash
$ lein do clean, compile, uberjar
$ storm jar target/cia-storm-0.1.0-SNAPSHOT-standalone.jar cia_storm.wordcount wordcount
$ cd /path/to/storm/logs
$ tail worker-6700.log
2013-05-11 21:26:15 wordcount [INFO] four: 9, keeps: 15, away: 15, score: 9, petted: 16, brown: 9, little: 9, years: 9, man: 16, apple: 15, dog: 25, day: 15
2013-05-11 21:26:20 wordcount [INFO] four: 10, keeps: 9, away: 9, score: 10, petted: 18, brown: 13, little: 13, years: 10, man: 18, apple: 9, dog: 31, day: 9
$ tail worker-6701.log
2013-05-11 21:27:10 wordcount [INFO] ago: 12, seven: 12, and: 12, doctor: 11, a: 31, an: 11, the: 25
2013-05-11 21:27:15 wordcount [INFO] ago: 14, seven: 14, and: 14, doctor: 11, the: 43, a: 19, an: 11
</code></p>

<h2>小结</h2>

<p>这一章我们简单介绍了Storm的设计初衷，它是如何通过分布式并行运算解决实时数据分析问题的。Storm目前已经十分稳定，且仍处于活跃的开发状态。它的一些高级特性如DRPC、Trident等，还请感兴趣的读者自行研究。</p>

<p>本文使用的WordCount示例代码：<a href="https://github.com/jizhang/cia-storm">https://github.com/jizhang/cia-storm</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perl入门实战：JVM监控脚本（下）]]></title>
    <link href="http://shzhangji.com/blog/2013/03/28/perl-prime-in-action-jvm-monitoring-2/"/>
    <updated>2013-03-28T15:28:00+08:00</updated>
    <id>http://shzhangji.com/blog/2013/03/28/perl-prime-in-action-jvm-monitoring-2</id>
    <content type="html"><![CDATA[<h2>套接字</h2>

<p>使用套接字（Socket）进行网络通信的基本流程是：</p>

<ul>
<li>服务端：监听端口、等待连接、接收请求、发送应答；</li>
<li>客户端：连接服务端、发送请求、接收应答。</li>
</ul>


<p>```perl
use IO::Socket::INET;</p>

<p>my $server = IO::Socket::INET->new(</p>

<pre><code>LocalPort =&gt; 10060,
Type =&gt; SOCK_STREAM,
Reuse =&gt; 1,
Listen =&gt; SOMAXCONN
</code></pre>

<p>) || die "服务创建失败\n";</p>

<p>while (my $client = $server->accept()) {</p>

<pre><code>my $line = &lt;$client&gt;;
chomp($line);

if ($line =~ /^JVMPORT ([0-9]+)$/) {
    print "RECV $1\n";
    print $client "OK\n";
} else {
    print "ERROR $line\n";
    print $client "ERROR\n";
}

close($client);
</code></pre>

<p>}</p>

<p>close($server);
```</p>

<!--more-->


<ul>
<li><code>IO::Socket::INET</code>是一个内置模块，<code>::</code>符号用来分隔命名空间。</li>
<li><code>-&gt;new</code>运算符是用来创建一个类的实例的，这涉及到面向对象编程，我们暂且忽略。</li>
<li><code>(key1 =&gt; value1, key2 =&gt; value2)</code>是用来定义一个哈希表的，也就是键值对。这里是将哈系表作为参数传递给了<code>new</code>函数。请看以下示例。对于哈系表的进一步操作，我们这里暂不详述。</li>
</ul>


<p>```perl
sub hello {</p>

<pre><code>my %params = @_;
print "Hello, $params{'name'}!\n";
</code></pre>

<p>}</p>

<p>hello('name' => 'Jerry'); # 输出 Hello, Jerry!
```</p>

<ul>
<li><code>while (...) {...}</code>是另一种循环结构，当圆括号的表达式为真就会执行大括号中的语句。</li>
<li><code>$server-&gt;accept()</code>表示调用<code>$server</code>对象的<code>accept()</code>函数，用来接受一个连接。执行这个函数时进程会阻塞（进入睡眠），当有连接过来时才会唤醒，并将该连接赋值给<code>$client</code>变量。</li>
<li><code>&lt;...&gt;</code>运算符表示从文件中读取一行，如：</li>
</ul>


<p>```perl
open my $fd, '&lt;', '/proc/diskstats';
while (my $line = &lt;$fd>) {</p>

<pre><code>print $line;
</code></pre>

<p>}
```</p>

<p>由于套接字也可以作为文件来看待，所以就能使用<code>&lt;...&gt;</code>运算符。关于<code>open</code>函数和其他文件操作，读者可参考<a href="http://perl5maven.com/open-and-read-from-files">这篇文章</a>。</p>

<ul>
<li><code>chomp()</code>函数用来将字符串末尾的换行符去掉。它的用法也比较奇特，不是<code>$line = chomp($line)</code>，而是<code>chomp($line)</code>，这里<code>$line</code>是一次引用传递。</li>
<li>细心的读者会发现，第二句<code>print</code>增加了<code>$client</code>，可以猜到它是用来指定<code>print</code>的输出目标。默认情况下是标准输出。</li>
</ul>


<p>我们打开两个终端，一个终端执行服务端，另一个终端直接用Bash去调用。</p>

<p>```bash</p>

<h1>客户端</h1>

<p>$ echo 'JVMPORT 2181' | nc 127.0.0.1 10060
OK
$ echo 'hello' | nc 127.0.0.1 10060
ERROR</p>

<h1>服务端</h1>

<p>$ ./socket-server.pl
RECV 2181
ERROR hello
```</p>

<p>至于客户端，还请读者自行完成，可参考<a href="http://perldoc.perl.org/IO/Socket/INET.html">相关文档</a>。</p>

<h2>子进程</h2>

<p>上述代码中有这样一个问题：当客户端建立了连接，但迟迟没有发送内容，那么服务端就会阻塞在<code>$line = &lt;$client&gt;</code>这条语句，无法接收其他请求。有三种解决方案：</p>

<ol>
<li>服务端读取信息时采用一定的超时机制，如果3秒内还不能读到完整的一行就断开连接。可惜Perl中并没有提供边界的方法来实现这一机制，需要自行使用<code>IO::Select</code>这样的模块来编写，比较麻烦。</li>
<li>接受新的连接后打开一个子进程或线程来处理连接，这样就不会因为一个连接挂起而使整个服务不可用。</li>
<li>使用非阻塞事件机制，当有读写操作时才会去处理。</li>
</ol>


<p>这里我们使用第二种方案，即打开子进程来处理请求。</p>

<p>```perl
use IO::Socket::INET;</p>

<p>sub REAPER {</p>

<pre><code>my $pid;
while (($pid = waitpid(-1, 'WNOHANG')) &gt; 0) {
    print "SIGCHLD $pid\n";
}
</code></pre>

<p>}</p>

<p>my $interrupted = 0;
sub INTERRUPTER {</p>

<pre><code>$interrupted = 1;
</code></pre>

<p>}</p>

<p>$SIG{CHLD} = &amp;REAPER;
$SIG{TERM} = &amp;INTERRUPTER;
$SIG{INT} = &amp;INTERRUPTER;</p>

<p>my $server = ...;</p>

<p>while (!$interrupted) {</p>

<pre><code>if (my $client = $server-&gt;accept()) {

    my $pid = fork();

    if ($pid &gt; 0) {
        close($client);
        print "PID $pid\n";
    } elsif ($pid == 0) {
        close($server);

        my $line = &lt;$client&gt;;
        ...
        close($client);
        exit;

    } else {
        print "fork()调用失败\n";
    }
}
</code></pre>

<p>}</p>

<p>close($server);
```</p>

<p>我们先看下半部分的代码。系统执行<code>fork()</code>函数后，会将当前进程的所有内容拷贝一份，以新的进程号来运行，即子进程。通过<code>fork()</code>的返回值可以知道当前进程是父进程还是子进程：大于0的是父进程；等于0的是子进程。子进程中的代码做了省略，执行完后直接<code>exit</code>。</p>

<p>上半部分的信号处理是做什么用的呢？这就是在多进程模型中需要特别注意的问题：僵尸进程。具体可以参考<a href="http://shzhangji.com/blog/2013/03/27/fork-and-zombie-process/">这篇文章</a>。</p>

<p>而<code>$interrupted</code>变量则是用来控制程序是否继续执行的。当进程收到<code>SIGTERM</code>或<code>SIGINT</code>信号时，该变量就会置为真，使进程自然退出。</p>

<p>为何不直接使用<code>while (my $client = $server-&gt;accept()) {...}</code>呢？因为子进程退出时会向父进程发送<code>SIGCHLD</code>信号，而<code>accept()</code>函数在接收到任何信号后都会中断并返回空，使得<code>while</code>语句退出。</p>

<h2>命令行参数</h2>

<p>这个服务脚本所监听的端口后是固写在脚本中的，如果想通过命令行指定呢？我们可以使用Perl的内置模块<code>Getopt::Long</code>。</p>

<p>```perl
use Getopt::Long;
use Pod::Usage;</p>

<p>my $help = 0;
my $port = 10060;</p>

<p>GetOptions(</p>

<pre><code>'help|?' =&gt; \$help,
'port=i' =&gt; \$port
</code></pre>

<p>) || pod2usage(2);
pod2usage(1) if $help;</p>

<p>print "PORT $port\n";</p>

<p><strong>END</strong></p>

<p>=head1 NAME</p>

<p>getopt</p>

<p>=head1 SYNOPSIS</p>

<p>getopt.pl [options]</p>

<p> Options:
   -help brief help message
   -port bind to tcp port</p>

<p>=cut
```</p>

<p>使用方法是：</p>

<p>```bash
$ ./getopt.pl -h
Usage:</p>

<pre><code>getopt.pl [options]
...
</code></pre>

<p>$ ./getopt.pl
PORT 10060
$ ./getopt.pl -p 12345
PORT 12345
```</p>

<p><code>'port=i' =&gt; \$port</code>表示从命令行中接收名为<code>-port</code>的参数，并将接收到的值转换为整数（<code>i</code>指整数）。<code>\$</code>又是一种引用传递了，这里暂不详述。</p>

<p>至于<code>||</code>运算符，之前在建立<code>$server</code>时也遇到过，它实际上是一种逻辑运算符，表示“或”的关系。这里的作用则是“如果GetOptions返回的值不为真，则程序退出”。</p>

<p><code>pod2usage(1) if $help</code>表示如果<code>$help</code>为真则执行<code>pod2usage(1)</code>。你也可以写为<code>$help &amp;&amp; pod2usage(1)</code>。</p>

<p>我们再来看看<code>__END__</code>之后的代码，它是一种Pod文档（Plain Old Documentation），可以是单独的文件，也可以像这样直接附加到Perl脚本末尾。具体格式可以参考<a href="http://perldoc.perl.org/perlpod.html">perlpod</a>。<code>pod2usage()</code>函数顾名思义是将附加的Pod文档转化成帮助信息显示在控制台上。</p>

<h2>小结</h2>

<p>完整的脚本可以见这个链接<a href="https://github.com/jizhang/zabbix-templates/blob/master/jvm/jvm-service.pl">jvm-service.pl</a>。调用该服务的脚本可以见<a href="https://github.com/jizhang/zabbix-templates/blob/master/jvm/jvm-check.pl">jvm-check.pl</a>。</p>

<p>Perl语言历史悠久，语法丰富，还需多使用、多积累才行。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Perl入门实战：JVM监控脚本（上）]]></title>
    <link href="http://shzhangji.com/blog/2013/03/26/perl-prime-in-action-jvm-monitoring-1/"/>
    <updated>2013-03-26T23:00:00+08:00</updated>
    <id>http://shzhangji.com/blog/2013/03/26/perl-prime-in-action-jvm-monitoring-1</id>
    <content type="html"><![CDATA[<p>由于最近在搭建Zabbix监控服务，需要制作各类监控的模板，如iostat、Nginx、MySQL等，因此会写一些脚本来完成数据采集的工作。又因为近期对Perl语言比较感兴趣，因此决定花些时间学一学，写一个脚本来练练手，于是就有了这样一份笔记。</p>

<h2>需求描述</h2>

<p>我们将编写一个获取JVM虚拟机状态信息的脚本：</p>

<ol>
<li>启动一个服务进程，通过套接字接收形如“JVMPORT 2181”的请求；</li>
<li>执行<code>netstat</code>命令，根据端口获取进程号；</li>
<li>执行<code>jstat</code>命令获取JVM的GC信息；<code>jstack</code>获取线程信息；<code>ps -o pcpu,rss</code>获取CPU和内存使用情况；</li>
<li>将以上信息返回给客户端；</li>
</ol>


<p>之所以需要这样一个服务是因为Zabbix Agent会运行在zabbix用户下，无法获取运行在其他用户下的JVM信息。</p>

<p>此外，Zabbix Agent也需要编写一个脚本来调用上述服务，这个在文章末尾会给出范例代码。</p>

<!-- more -->


<h2>Hello, world!</h2>

<p>还是要不免俗套地来一个helloworld，不过我们的版本会稍稍丰富些：</p>

<p>```perl</p>

<h1>!/usr/bin/perl</h1>

<p>use strict;
my $name = 'Jerry';
print "Hello, $name!\n"; # 输出 Hello, Jerry!
```</p>

<p>将该文件保存为<code>hello.pl</code>，可以用两种方式执行：</p>

<p><code>bash
$ perl hello.pl
Hello, Jerry!
$ chmod 755 hello.pl
$ ./hello.pl
Hello, Jerry!
</code></p>

<ul>
<li>所有的语句都以分号结尾，因此一行中可以有多条语句，但并不提倡这样做。</li>
<li><code>use</code>表示加载某个模块，加载<a href="http://search.cpan.org/~rjbs/perl-5.16.3/lib/strict.pm"><code>strict</code>模块</a>表示会对当前文件的语法做出一些规范和约束。比如将<code>my $name ...</code>前的<code>my</code>去掉，执行后Perl解释器会报错。建议坚持使用该模块。</li>
<li><code>$name</code>，一个Perl变量。<code>$</code>表示该变量是一个标量，可以存放数值、字符串等基本类型。其它符号有<code>@</code>和<code>%</code>，分别对应数组和哈希表。</li>
<li><code>my</code>表示声明一个变量，类似的有<code>our</code>、<code>local</code>等，将来接触到变量作用域时会了解。</li>
<li>字符串可以用单引号或双引号括起来，区别是双引号中的变量会被替换成实际值以及进行转移，单引号则不会。如<code>'Hello, $name!\n'</code>中的<code>$name</code>和<code>\n</code>会按原样输出，而不是替换为“Jerry”和换行符。</li>
<li><code>print</code>语句用于将字符串输出到标准输出上。</li>
<li><code>#</code>表示注释。</li>
</ul>


<h2>正则表达式</h2>

<p>我们第一个任务是从“JVMPORT 2181”这样的字符串中提取“2181”这个端口号。解决方案当然是使用正则，而且Perl的强项之一正是文本处理：</p>

<p>```perl
my $line = 'JVMPORT 2181';
if ($line =~ /<sup>JVMPORT</sup> ([0-9]+)$/) {</p>

<pre><code>print $1, "\n"; # 输出 2181
</code></pre>

<p>} else {</p>

<pre><code>print '匹配失败', "\n";
</code></pre>

<p>}
```</p>

<p>这里假设你知道如何使用正则表达式。</p>

<ul>
<li><code>=~</code>运算符表示将变量和正则表达式进行匹配，如果匹配成功则返回真，失败则返回假。</li>
<li>匹配成功后，Perl会对全局魔术变量——<code>$0</code>至<code>$9</code>进行赋值，分别表示正则表达式完全匹配到的字符串、第一个子模式匹配到的字符串、第二个子模式，依此类推。</li>
<li><code>if...else...</code>是条件控制语句，其中<code>...} else if (...</code>可以简写为<code>...} elsif (...</code>。</li>
</ul>


<h2>调用命令行</h2>

<p>使用反引号（即大键盘数字1左边的按键）：</p>

<p><code>perl
my $uname = `uname`;
print $uname; # 输出 Linux
my $pid = '1234';
$line = `ps -ef | grep $pid`; # 支持管道符和变量替换
</code></p>

<p>对于返回多行结果的命令，我们需要对每一行的内容进行遍历，因此会使用数组和<code>foreach</code>语句：</p>

<p><code>``perl
my $pid;
my $jvmport = '2181';
my @netstat =</code>netstat -lntp 2>/dev/null`;
foreach my $line (@netstat) {</p>

<pre><code>if ($line =~ /.*?:$jvmport\s.*?([0-9]+)\/java\s*$/) {
    $pid = $1;
    last;
}
</code></pre>

<p>}
if ($pid) {</p>

<pre><code>print $pid, "\n";
</code></pre>

<p>} else {</p>

<pre><code>print '端口不存在', "\n";
</code></pre>

<p>}
```</p>

<ul>
<li><code>$pid</code>变量的结果是2181端口对应的进程号。</li>
<li>这个正则可能稍难理解，但对照<code>netstat</code>的输出结果来看就可以了。</li>
<li><code>foreach</code>是循环语句的一种，用来遍历一个数组的元素，这里则是遍历<code>netstat</code>命令每一行的内容。注意，<code>foreach</code>可以直接用<code>for</code>代替，即<code>for my $line (@netstat) { ... }</code>。</li>
<li><code>last</code>表示退出循环。如果要进入下一次循环，可使用<code>next</code>语句。</li>
</ul>


<h2>数组</h2>

<p>下面我们要根据进程号来获取JVM的GC信息：（“2017”为上文获取到的进程号）</p>

<p><code>bash
$ jstat -gc 2017
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT   
192.0  192.0   0.0    50.1   1792.0   682.8     4480.0     556.3    21248.0 9483.2      3    0.008   0      0.000    0.008
</code></p>

<p>如何将以上输出结果转换为以下形式？</p>

<p><code>
s0c 192.0
s1c 192.0
...
</code></p>

<p>这时我们就需要更多地使用数组这一数据结构：</p>

<p><code>``perl
my $pid = 2017;
my @jstat =</code>jstat -gc $pid`;</p>

<p>$jstat[0] =~ s/<sup>\s+|\s+$//;</sup>
$jstat[1] =~ s/<sup>\s+|\s+$//;</sup></p>

<p>my @kv_keys = split(/\s+/, $jstat[0]);
my @kv_vals = split(/\s+/, $jstat[1]);</p>

<p>my $result = '';
for my $i (0 .. $#kv_keys) {</p>

<pre><code>$result .= "$kv_keys[$i] $kv_vals[$i]\n";
</code></pre>

<p>}</p>

<p>print $result;
```</p>

<ul>
<li>使用<code>$jstat[0]</code>获取数组的第一个元素，数组的下标从0开始，注意这里的<code>$</code>符号，而非<code>@</code>。</li>
<li><code>$#kv_keys</code>返回的是数组最大的下标，而非数组的长度。</li>
<li><code>for my $i (0 .. 10) {}</code>则是另一种循环结构，<code>$i</code>的值从0到10（含0和10）。</li>
</ul>


<p>对于正则表达式，这里也出现了两个新的用法：</p>

<ul>
<li><code>s/A/B/</code>表示将A的值替换为B，上述代码中是将首尾的空格去除；</li>
<li><code>split(A, B)</code>函数表示将字符串B按照正则A进行分割，并返回一个数组。</li>
</ul>


<p>另外在学习过程中还发现了这样一种写法：</p>

<p>```perl
my @jstat;</p>

<p>$jstat[0] =~ s/<sup>\s+|\s+$//;</sup>
$jstat[1] =~ s/<sup>\s+|\s+$//;</sup></p>

<p>map { s/<sup>\s+|\s+$//</sup> } @jstat;
```</p>

<p><code>map</code>函数会对数组中的每个元素应用第一个参数指向的函数（这里是一个匿名函数），当需要处理的数组元素很多时，这种是首选做法。具体内容读者可以自己去了解。</p>

<h2>函数</h2>

<p>我们可以用以下命令来获取指定进程的CPU和内存使用率：</p>

<p><code>bash
$ ps -o pcpu,rss -p 2017
%CPU   RSS
 0.1 21632
</code></p>

<p>格式和<code>jstat</code>是一样的，为了不再写一遍上文中的代码，我们可以将其封装为函数。</p>

<p>```perl
sub kv_parse {</p>

<pre><code>my @kv_data = @_;

map { s/^\s+|\s+$// } @kv_data;

my @kv_keys = split(/\s+/, $kv_data[0]);
my @kv_vals = split(/\s+/, $kv_data[1]);

my $result = '';
for my $i (0 .. $#kv_keys) {
    $result .= "$kv_keys[$i] $kv_vals[$i]\n";
}

return $result;
</code></pre>

<p>}</p>

<p>my $pid = 2017;
my @jstat = <code>jstat -gc $pid</code>;
my @ps = <code>ps -o pcpu,rss -p $pid</code>;</p>

<p>print kv_parse(@jstat);
print kv_parse(@ps);
```</p>

<p><code>sub</code>表示定义一个函数（subroutine），和其他语言不同的是，它没有参数列表，获取参数使用的是魔术变量<code>@_</code>：</p>

<p>```perl
sub hello {</p>

<pre><code>my $name1 = $_[0];
$name1 = shift @_;
my $name2 = shift(@_);
my $name3 = shift;
</code></pre>

<p>}</p>

<p>hello('111', '222', '333');
hello '111', '222', '333';
&amp;hello('111', '222', '333');
```</p>

<ul>
<li><code>$_[0]</code>和<code>shift @_</code>返回的都是第一参数。不同的是，<code>shift</code>函数会将这个参数从<code>@_</code>数组中移除；</li>
<li><code>shift @_</code>和<code>shift(@_)</code>是等价的，因为调用函数时参数列表可以不加括号；</li>
<li><code>shift @_</code>和只写<code>shift</code>也是等价的，该函数若不指定参数，则默认使用<code>@_</code>数组。</li>
<li><code>&amp;</code>符号也是比较特别的，主要作用有两个：一是告诉Perl解释器<code>hello</code>将是一个用户定义的函数，这样就不会和Perl原生关键字冲突；二是忽略函数原型（prototype）。具体可以参考这篇文章：<a href="https://www.socialtext.net/perl5/subroutines_called_with_the_ampersand">Subroutines Called With The Ampersand</a>。</li>
</ul>


<p>当传递一个数组给函数时，该数组不会被作为<code>@_</code>的第一个元素，而是作为<code>@_</code>本身。这也是很特别的地方。当传递多个数组，Perl会将这些数组进行拼接：</p>

<p>```perl
sub hello {</p>

<pre><code>for my $i (@_) {
    print $i;
}
</code></pre>

<p>}</p>

<p>my @arr1 = (1, 2); # 使用圆括号定义一个数组，元素以逗号分隔。
my @arr2 = (3, 4);</p>

<p>hello @arr1, @arr2; # 输出 1234
```</p>

<h2>小结</h2>

<p>对于初学者来讲，本文的信息量可能有些大了。但如果你已经有一定的编程经验（包括Bash），应该可以理解这些内容。</p>

<p>Perl文化的特色是“不只一种做法来完成一件事情”，所以我们可以看到很多不同的写法。但也有一些是大家普遍接受的写法，所以也算是一种规范吧。</p>

<p>下一章我们会继续完成这个监控脚本。</p>

<p>PS：本文的示例代码可以从<a href="https://github.com/jizhang/perl-jvm-monitoring-example">Github</a>中下载。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure实战(4)：编写Hadoop MapReduce脚本]]></title>
    <link href="http://shzhangji.com/blog/2013/02/09/cia-hadoop/"/>
    <updated>2013-02-09T16:43:00+08:00</updated>
    <id>http://shzhangji.com/blog/2013/02/09/cia-hadoop</id>
    <content type="html"><![CDATA[<h2>Hadoop简介</h2>

<p>众所周知，我们已经进入了大数据时代，每天都有PB级的数据需要处理、分析，从中提取出有用的信息。Hadoop就是这一时代背景下的产物。它是Apache基金会下的开源项目，受<a href="http://en.wikipedia.org/wiki/Apache_Hadoop#Papers">Google两篇论文</a>的启发，采用分布式的文件系统HDFS，以及通用的MapReduce解决方案，能够在数千台物理节点上进行分布式并行计算。</p>

<p>对于Hadoop的介绍这里不再赘述，读者可以<a href="http://hadoop.apache.org/">访问其官网</a>，或阅读<a href="http://product.dangdang.com/main/product.aspx?product_id=21127813">Hadoop权威指南</a>。</p>

<p>Hadoop项目是由Java语言编写的，运行在JVM之上，因此我们可以直接使用Clojure来编写MapReduce脚本，这也是本文的主题。Hadoop集群的搭建不在本文讨论范围内，而且运行MapReduce脚本也无需搭建测试环境。</p>

<!-- more -->


<h2>clojure-hadoop类库</h2>

<p>Hadoop提供的API是面向Java语言的，如果不想在Clojure中过多地操作Java对象，那就需要对API进行包装（wrapper），好在已经有人为我们写好了，它就是<a href="https://github.com/alexott/clojure-hadoop">clojure-hadoop</a>。</p>

<p>从clojure-hadoop的项目介绍中可以看到，它提供了不同级别的包装，你可以选择完全规避对Hadoop类型和对象的操作，使用纯Clojure语言来编写脚本；也可以部分使用Hadoop对象，以提升性能（因为省去了类型转换过程）。这里我们选择前一种，即完全使用Clojure语言。</p>

<h2>示例1：Wordcount</h2>

<p>Wordcount，统计文本文件中每个单词出现的数量，可以说是数据处理领域的“Hello, world!”。这一节我们就通过它来学习如何编写MapReduce脚本。</p>

<h3>Leiningen 2</h3>

<p>前几章我们使用的项目管理工具<code>lein</code>是1.7版的，而前不久Leiningen 2已经正式发布了，因此从本章开始我们的示例都会基于新版本。新版<code>lein</code>的安装过程也很简单：</p>

<p><code>bash
$ cd ~/bin
$ wget https://raw.github.com/technomancy/leiningen/stable/bin/lein
$ chmod 755 lein
$ lein repl
user=&gt;
</code></p>

<p>其中，<code>lein repl</code>这一步会下载<code>lein</code>运行时需要的文件，包括Clojure 1.4。</p>

<h3>新建项目</h3>

<p><code>bash
$ lein new cia-hadoop
</code></p>

<p>编辑<code>project.clj</code>文件，添加依赖项<code>clojure-hadoop "1.4.1"</code>，尔后执行<code>lein deps</code>。</p>

<h3>Map和Reduce</h3>

<p>MapReduce，简称mapred，是Hadoop的核心概念之一。可以将其理解为处理问题的一种方式，即将大问题拆分成多个小问题来分析和解决，最终合并成一个结果。其中拆分的过程就是Map，合并的过程就是Reduce。</p>

<p>以Wordcount为例，将一段文字划分成一个个单词的过程就是Map。这个过程是可以并行执行的，即将文章拆分成多个段落，每个段落分别在不同的节点上执行划分单词的操作。这个过程结束后，我们便可以统计各个单词出现的次数，这也就是Reduce的过程。同样，Reduce也是可以并发执行的。整个过程如下图所示：</p>

<p><img src="/images/cia-hadoop/wordcount.png" alt="Wordcount" /></p>

<p>中间Shuffle部分的功能是将Map输出的数据按键排序，交由Reduce处理。整个过程全部由Hadoop把控，开发者只需编写<code>Map</code>和<code>Reduce</code>函数，这也是Hadoop强大之处。</p>

<h4>编写Map函数</h4>

<p>在本示例中，我们处理的原始数据是文本文件，Hadoop会逐行读取并调用Map函数。Map函数会接收到两个参数：<code>key</code>是一个长整型，表示该行在整个文件中的偏移量，很少使用；<code>value</code>则是该行的内容。以下是将一行文字拆分成单词的Map函数：</p>

<p>```clojure
;; src/cia_hadoop/wordcount.clj</p>

<p>(ns cia-hadoop.wordcount
  (:require [clojure-hadoop.wrap :as wrap]</p>

<pre><code>        [clojure-hadoop.defjob :as defjob])
</code></pre>

<p>  (:import [java.util StringTokenizer])
  (:use clojure-hadoop.job))</p>

<p>(defn my-map [key value]
  (map (fn [token] [token 1])</p>

<pre><code>   (enumeration-seq (StringTokenizer. value))))
</code></pre>

<p>```</p>

<p>可以看到，这是一个纯粹的Clojure函数，并没有调用Hadoop的API。函数体虽然只有两行，但还是包含了很多知识点的：</p>

<p><code>(map f coll)</code>函数的作用是将函数<code>f</code>应用到序列<code>coll</code>的每个元素上，并返回一个新的序列。如<code>(map inc [1 2 3])</code>会对每个元素做加1操作（参考<code>(doc inc)</code>），返回<code>[2 3 4]</code>。值得一提的是，<code>map</code>函数返回的是一个惰性序列（lazy sequence），即序列元素不会一次性完全生成，而是在遍历过程中逐个生成，这在处理元素较多的序列时很有优势。</p>

<p><code>map</code>函数接收的参数自然不会只限于Clojure内部函数，我们可以将自己定义的函数传递给它：</p>

<p>```clojure
(defn my-inc [x]
  (+ x 1))</p>

<p>(map my-inc [1 2 3]) ; -> [2 3 4]
```</p>

<p>我们更可以传递一个匿名函数给<code>map</code>。上一章提过，定义匿名函数的方式是使用<code>fn</code>，另外还可使用<code>#(...)</code>简写：</p>

<p><code>clojure
(map (fn [x] (+ x 1)) [1 2 3])
(map #(+ % 1) [1 2 3])
</code></p>

<p>对于含有多个参数的情况：</p>

<p><code>clojure
((fn [x y] (+ x y)) 1 2) ; -&gt; 3
(#(+ %1 %2) 1 2) ; -&gt; 3
</code></p>

<p><code>my-map</code>中的<code>(fn [token] [token 1])</code>即表示接收参数<code>token</code>，返回一个向量<code>[token 1]</code>，其作用等价于<code>#(vector % 1)</code>。为何是<code>[token 1]</code>，是因为Hadoop的数据传输都是以键值对的形式进行的，如<code>["apple" 1]</code>即表示“apple”这个单词出现一次。</p>

<p><a href="http://docs.oracle.com/javase/6/docs/api/java/util/StringTokenizer.html">StringTokenizer</a>则是用来将一行文字按空格拆分成单词的。他的返回值是<code>Enumeration</code>类型，Clojure提供了<code>enumeration-seq</code>函数，可以将其转换成序列进行操作。</p>

<p>所以最终<code>my-map</code>函数的作用就是：将一行文字按空格拆分成单词，返回一个形如<code>[["apple" 1] ["orange" 1] ...]</code>的序列。</p>

<h4>编写Reduce函数</h4>

<p>从上文的图表中可以看到，Map函数处理完成后，Hadoop会对结果按照键进行排序，并使用<code>key, [value1 value2 ...]</code>的形式调用Reduce函数。在clojure-hadoop中，Reduce函数的第二个参数是一个函数，其返回结果才是值的序列：</p>

<p><code>clojure
(defn my-reduce [key values-fn]
  [[key (reduce + (values-fn))]])
</code></p>

<p>和Map函数相同，Reduce函数的返回值也是一个序列，其元素是一个个<code>[key value]</code>。注意，函数体中的<code>(reduce f coll)</code>是Clojure的内置函数，其作用是：取<code>coll</code>序列的第1、2个元素作为参数执行函数<code>f</code>，将结果和<code>coll</code>序列的第3个元素作为参数执行函数<code>f</code>，依次类推。因此<code>(reduce + [1 2 3])</code>等价于<code>(+ (+ 1 2) 3)</code>。</p>

<h4>定义脚本</h4>

<p>有了Map和Reduce函数，我们就可以定义一个完整的脚本了：</p>

<p><code>clojure
(defjob/defjob job
  :map my-map
  :map-reader wrap/int-string-map-reader
  :reduce my-reduce
  :input-format :text
  :output-format :text
  :compress-output false
  :replace true
  :input "README.md"
  :output "out-wordcount")
</code></p>

<p>简单说明一下这些配置参数：<code>:map</code>和<code>:reduce</code>分别指定Map和Reduce函数；<code>map-reader</code>表示读取数据文件时采用键为<code>int</code>、值为<code>string</code>的形式；<code>:input-format</code>至<code>compress-output</code>指定了输入输出的文件格式，这里采用非压缩的文本形式，方便阅览；<code>:replace</code>表示每次执行时覆盖上一次的结果；<code>:input</code>和<code>:output</code>则是输入的文件和输出的目录。</p>

<h4>执行脚本</h4>

<p>我们可以采用Clojure的测试功能来执行脚本：</p>

<p>```clojure
;; test/cia_hadoop/wordcount_test.clj</p>

<p>(ns cia-hadoop.wordcount-test
  (:use clojure.test</p>

<pre><code>    clojure-hadoop.job
    cia-hadoop.wordcount))
</code></pre>

<p>(deftest test-wordcount
  (is (run job)))
```</p>

<p>尔后执行：</p>

<p><code>bash
$ lein test cia-hadoop.wordcount-test
...
13/02/14 00:25:52 INFO mapred.JobClient:  map 0% reduce 0%
..
13/02/14 00:25:58 INFO mapred.JobClient:  map 100% reduce 100%
...
$ cat out-wordcount/part-r-00000
...
"java"  1
"lein"  3
"locally"   2
"on"    1
...
</code></p>

<p>如果想要将MapReduce脚本放到Hadoop集群中执行，可以采用以下命令：</p>

<p><code>bash
$ lein uberjar
$ hadoop jar target/cia-hadoop-0.1.0-SNAPSHOT-standalone.jar clojure_hadoop.job -job cia-hadoop.wordcount/job
</code></p>

<h2>示例2：统计浏览器类型</h2>

<p>下面我们再来看一个更为实际的示例：从用户的访问日志中统计浏览器类型。</p>

<h3>需求概述</h3>

<p>用户访问网站时，页面中会有段JS请求，将用户的IP、User-Agent等信息发送回服务器，并记录成文本文件的形式：</p>

<p><code>text
{"stamp": "1346376858286", "ip": "58.22.113.189", "agent": "Mozilla/5.0 (iPad; CPU OS 5_0_1 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A405 Safari/7534.48.3"}
{"stamp": "1346376858354", "ip": "116.233.51.2", "agent": "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)"}
{"stamp": "1346376858365", "ip": "222.143.28.2", "agent": "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)"}
{"stamp": "1346376858423", "ip": "123.151.144.40", "agent": "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"}
</code></p>

<p>我们要做的是从User-Agent中统计用户使用的浏览器类型所占比例，包括IE、Firefox、Chrome、Opera、Safari、以及其它。</p>

<h3>User-Agent中的浏览器类型</h3>

<p>由于一些<a href="http://webaim.org/blog/user-agent-string-history/">历史原因</a>，User-Agent中的信息是比较凌乱的，浏览器厂商会随意添加信息，甚至仿造其它浏览器的内容。因此在过滤时，我们需要做些额外的处理。Mozilla的<a href="https://developer.mozilla.org/en-US/docs/Browser_detection_using_the_user_agent">这篇文章</a>很好地概括了如何从User-Agent中获取浏览器类型，大致如下：</p>

<ul>
<li>IE: MSIE xyz</li>
<li>Firefox: Firefox/xyz</li>
<li>Chrome: Chrome/xyz</li>
<li>Opera: Opera/xyz</li>
<li>Safari: Safari/xyz, 且不包含 Chrome/xyz 和 Chromium/xyz</li>
</ul>


<h3>解析JSON字符串</h3>

<p>Clojure除了内置函数之外，周边还有一个名为<code>clojure.contrib</code>的类库，其中囊括了各类常用功能，包括JSON处理。目前<code>clojure.contrib</code>中的各个组件已经分开发行，读者可以到 https://github.com/clojure 中浏览。</p>

<p>处理JSON字符串时，首先在项目声明文件中添加依赖项<code>[org.clojure/data.json "0.2.1"]</code>，然后就能使用了：</p>

<p><code>clojure
user=&gt; (require '[clojure.data.json :as json])
user=&gt; (json/read-str "{\"a\":1,\"b\":2}")
{"a" 1, "b" 2}
user=&gt; (json/write-str [1 2 3])
"[1,2,3]"
</code></p>

<h3>正则表达式</h3>

<p>Clojure提供了一系列的内置函数来使用正则表达式，其实质上是对<code>java.util.regex</code>命名空间的包装。</p>

<p><code>clojure
user=&gt; (def ptrn #"[0-9]+") ; #"..."是定义正则表达式对象的简写形式
user=&gt; (def ptrn (re-pattern "[0-9]+")) ; 和上式等价
user=&gt; (re-matches ptrn "123") ; 完全匹配
"123"
user=&gt; (re-find ptrn "a123") ; 返回第一个匹配项
"123"
user=&gt; (re-seq ptrn "a123b456") ; 返回匹配项序列（惰性序列）
("123" "456")
user=&gt; (re-find #"([a-z]+)/([0-9]+)" "a/1") ; 子模式
["a/1" "a" "1"]
user=&gt; (def m (re-matcher #"([a-z]+)/([0-9]+)" "a/1 b/2")) ; 返回一个Matcher对象
user=&gt; (re-find m) ; 返回第一个匹配
["a/1" "a" "1"]
user=&gt; (re-groups m) ; 获取当前匹配
["a/1" "a" "1"]
user=&gt; (re-find m) ; 返回下一个匹配，或nil
["b/2" "b" "2"]
</code></p>

<h3>Map函数</h3>

<p>```clojure
(defn json-decode [s]
  (try</p>

<pre><code>(json/read-str s)
(catch Exception e)))
</code></pre>

<p>(def rule-set {"ie" (partial re-find #"(?i)MSIE [0-9]+")</p>

<pre><code>           "chrome" (partial re-find #"(?i)Chrome/[0-9]+")
           "firefox" (partial re-find #"(?i)Firefox/[0-9]+")
           "opera" (partial re-find #"(?i)Opera/[0-9]+")
           "safari" #(and (re-find #"(?i)Safari/[0-9]+" %)
                          (not (re-find #"(?i)Chrom(e|ium)/[0-9]+" %)))
           })
</code></pre>

<p>(defn get-type [ua]
  (if-let [rule (first (filter #((second %) ua) rule-set))]</p>

<pre><code>(first rule)
"other"))
</code></pre>

<p>(defn my-map [key value]
  (when-let [ua (get (json-decode value) "agent")]</p>

<pre><code>[[(get-type ua) 1]]))
</code></pre>

<p>```</p>

<p><code>json-decode</code>函数是对<code>json/read-str</code>的包装，当JSON字符串无法正确解析时返回<code>nil</code>，而非异常终止。</p>

<p><code>rule-set</code>是一个<code>map</code>类型，键是浏览器名称，值是一个函数，这里都是匿名函数。<code>partial</code>用于构造新的函数，<code>(partial + 1)</code>和<code>#(+ 1 %)</code>、<code>(fn [x] (+ 1 x))</code>是等价的，可以将其看做是为函数<code>+</code>的第一个参数定义了默认值。正则表达式中的<code>(?i)</code>表示匹配时不区分大小写。</p>

<p><code>get-type</code>函数中，<code>(filter #((second %) ua) rule-set)</code>会用<code>rule-set</code>中的正则表达式逐一去和User-Agent字符串进行匹配，并返回第一个匹配项，也就是浏览器类型；没有匹配到的则返回<code>other</code>。</p>

<h3>单元测试</h3>

<p>我们可以编写一组单元测试来检验上述<code>my-map</code>函数是否正确：</p>

<p>```clojure
;; test/cia_hadoop/browser_test.clj</p>

<p>(ns cia-hadoop.browser-test
  (:use clojure.test</p>

<pre><code>    clojure-hadoop.job
    cia-hadoop.browser))
</code></pre>

<p>(deftest test-my-map
  (is (= [["ie" 1]] (my-map 0 "{\"agent\":\"MSIE 6.0\"}")))
  (is (= [["chrome" 1]] (my-map 0 "{\"agent\":\"Chrome/20.0 Safari/6533.2\"}")))
  (is (= [["other" 1]] (my-map 0 "{\"agent\":\"abc\"}")))
  (is (nil? (my-map 0 "{"))))</p>

<p>(deftest test-browser
  (is (run job)))
```</p>

<p>其中<code>deftest</code>和<code>is</code>都是<code>clojure.test</code>命名空间下定义的。</p>

<p><code>bash
$ lein test cia-hadoop.browser-test
</code></p>

<h2>小结</h2>

<p>本章我们简单介绍了Hadoop这一用于大数据处理的开源项目，以及如何借助clojure-hadoop类库编写MapReduce脚本，并在本地和集群上运行。Hadoop已经将大数据处理背后的种种细节都包装了起来，用户只需编写Map和Reduce函数，而借助Clojure语言，这一步也变的更为轻松和高效。Apache Hadoop是一个生态圈，其周边有很多开源项目，像Hive、HBase等，这里再推荐一个使用Clojure语言在Hadoop上执行查询的工具：<a href="https://github.com/nathanmarz/cascalog">cascalog</a>。它的作者是<a href="http://nathanmarz.com/">Nathan Marz</a>，也是我们下一章的主题——Storm实时计算框架——的作者。</p>

<p>本文涉及到的源码可以到 https://github.com/jizhang/cia-hadoop 中查看。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clojure实战(3)：使用Noir框架开发博客(下)]]></title>
    <link href="http://shzhangji.com/blog/2012/12/16/cia-noir-3/"/>
    <updated>2012-12-16T20:20:00+08:00</updated>
    <id>http://shzhangji.com/blog/2012/12/16/cia-noir-3</id>
    <content type="html"><![CDATA[<h2>Session和Cookie</h2>

<p>做网络编程的人肯定对这两个概念不陌生，因此这里就不介绍它们的定义和作用了。我们要实现的需求也很简单：用户通过一个表单登录，在当前窗口中保持登录状态，并可以选择“记住我”来免去关闭并新开窗口之后的重登录。显然，前者使用Session，后者使用Cookie。下面我们就来看Noir对这两者的支持。</p>

<h3>Session</h3>

<p><code>clojure
(require 'noir.session)
(noir.session/put! :username "john")
(noir.session/get :username "nobody")
(noir.session/clear!)
</code></p>

<p>很简单的API。注意<code>put!</code>函数中的<code>!</code>，和之前遇到的<code>?</code>一样，这种特殊字符是合法的函数名，但<code>!</code>习惯用来表示该方法会改变某个对象的状态，这里<code>put!</code>就表示会改变Session的状态。</p>

<p>Noir还提供了一种“闪信（Flash）”机制，主要用于在页面跳转之间暂存消息。如用户登录后会跳转到首页，如果想在首页显示“登录成功”的信息，就需要用到闪信了。闪信的API也放置在<code>noir.session</code>命名空间下：</p>

<p><code>clojure
(noir.session/flash-put! "登录成功")
(noir.session/flash-get)
</code></p>

<p>闪信的生命周期是一次请求，即在设置了闪信后的下一个请求中，可以多次<code>flash-get</code>，但再下一次请求就获取不到值了。</p>

<!-- more -->


<h3>Cookie</h3>

<p>Cookie的API示例如下：</p>

<p><code>clojure
(require 'noir.cookies)
(noir.cookies/put! :user_id (str 1))
(noir.cookies/get :user_id)
(noir.cookies/put! :tracker {:value (str 29649) :path "/" :max-age 3600})
</code></p>

<p>需要注意的是，<code>put!</code>函数只支持字符串类型；对于Cookie超时时间的设置，一种是上面所写的多少秒过期，另一种是传入一个DateTime对象。对于时间日期的处理，Java自带的类库可能不太好用，这里推荐<a href="http://joda-time.sourceforge.net/">Joda Time</a>，它有更丰富的功能和更友善的API。</p>

<h2>登录页面</h2>

<p>这里我们跳过注册页面，因为它实现的功能和新建一篇文章很相近，所以读者可以自己完成。我们假定用户信息表的格式如下：</p>

<p><code>sql
CREATE TABLE `user` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `username` varchar(255) NOT NULL,
  `password` varchar(32) NOT NULL,
  PRIMARY KEY (`id`)
)
</code></p>

<p>其中password字段保存的是密码的MD5值（32位16进制字符串）。Clojure中没有提供专门的类库，因此需要调用Java来实现。下文会贴出它的实现代码。</p>

<p>我们重点来看对登录页面表单的处理。新建<code>src/blog/views/login.clj</code>文件，添加对<code>/login</code>的路由，显示一个包含用户名、密码、以及“记住我”复选框的表单。用户提交后，若验证成功，会跳转至<code>/whoami</code>页面，用来显示保存在session或者cookie中的信息。以下是关键代码：</p>

<p>```clojure
(defpage [:post "/login"] {:as forms}
  (let [userid (model-user/get-id (:username forms) (:password forms))]</p>

<pre><code>(if userid
  (do (session/put! :userid userid)
      (session/put! :username (:username forms))
      (when (= (:remember-me forms) "1") ; “记住我”复选框
        (cookies/put! :userid {:value (str userid) :max-age 86400}) ; 保存登录状态，时限1天。
        (cookies/put! :username {:value (:username forms) :max-age 86400}))
      (response/redirect "/whoami")) ; noir.response/redirect 302跳转
  (render "/login" forms))))
</code></pre>

<p>(defpage "/whoami" [] ; 先检测Session，再检测Cookie。
  (if-let [userid (session/get :userid)]</p>

<pre><code>(session/get :username)
(if-let [userid (cookies/get :userid)]
  (do
    (session/put! :userid userid)
    (let [username (cookies/get :username)]
      (session/put! :username username)
      username))
  "unknown")))
</code></pre>

<p>```</p>

<p>其中<code>if-let</code>和以下代码是等价的，类似的有<code>when-let</code>。</p>

<p>```clojure
(let [userid (session/get :userid)]
  (if userid</p>

<pre><code>(do ...)
"unkown"))
</code></pre>

<p>```</p>

<p>对用户表的操作我们放到<code>src/blog/models/user.clj</code>文件中：</p>

<p>```clojure
(ns blog.models.user
  (:require [clojure.java.jdbc :as sql]</p>

<pre><code>        [blog.util :as util])
</code></pre>

<p>  (:use [blog.database :only [db-spec]]))</p>

<p>(defn get-id [username password]
  (let [password-md5 (util/md5 password)]</p>

<pre><code>(sql/with-connection db-spec
  (sql/with-query-results rows
    ["SELECT `id` FROM `user` WHERE `username` = ? AND `password` = ?"
     username password-md5] ; 不要采用直接拼接字符串的方式，有SQL注入的危险。
    (:id (first rows))))))
</code></pre>

<p>```</p>

<p>最后，我们将MD5加密这类的函数放到<code>src/blog/util.clj</code>文件中：</p>

<p>```clojure
(ns blog.util
  (:import java.security.MessageDigest</p>

<pre><code>       java.math.BigInteger))
</code></pre>

<p>(defn md5 [s]
  (let [algorithm (MessageDigest/getInstance "MD5")</p>

<pre><code>    size (* 2 (.getDigestLength algorithm))
    raw (.digest algorithm (.getBytes s))
    sig (.toString (BigInteger. 1 raw) 16)
    padding (apply str (repeat (- size (count sig)) "0"))]
(str padding sig)))
</code></pre>

<p>```</p>

<p><code>padding</code>的作用是当计算得到的MD5字符串不足32位时做补零的操作。如何得到一个包含N个"0"的字符串？这就是<code>(apply...)</code>那串代码做的工作。简单来说，<code>(repeat n x)</code>函数会返回一个包含<code>n</code>个<code>x</code>元素的序列；<code>(apply f coll)</code>函数则是将<code>coll</code>序列所包含的元素作为参数传递给<code>f</code>函数，即<code>(apply str ["0" "0" "0"])</code>等价于<code>(str "0" "0" "0")</code>。<code>clojure.string/join</code>提供了将序列连接为字符串的功能，用法是<code>(clojure.string/join (repeat ...))</code>，查看它的源码<code>(source clojure.string/join)</code>可以发现，它实质上也是采用了<code>apply</code>函数。</p>

<p>序列是Clojure的一个很重要的数据结构，有多种函数和惯用法，需要逐步积累这些知识。</p>

<h2>中间件</h2>

<p>如果需要在程序的多个地方获取用户的登录状态，可以将上述<code>/whoami</code>中的方法封装成函数，但是每次都要执行一次似乎有些冗余，因此我们可以将它放到中间件（Middleware）中。</p>

<p>中间件是<a href="http://en.wikipedia.org/wiki/Web_Server_Gateway_Interface">WSGI</a>类的网站程序中很重要的特性。如果将用户的一次访问分解成<code>请求-&gt;处理1-&gt;处理2-&gt;应答</code>，那么中间件就是其中的“处理”部分，可以增加任意多个。Noir的很多功能，像路由、Session等，都是通过中间件的形式进行组织的。</p>

<p>以下是一个空的中间件代码：</p>

<p>```clojure
(ns ...</p>

<pre><code>(:require [noir.server :as server]))
</code></pre>

<p>(defn my-middleware [handler]
  (fn [request]</p>

<pre><code>(handler request)))
</code></pre>

<p>(erver/add-middleware my-middleware)
```</p>

<p>上述代码添加到<code>src/blog/server.clj</code>中可以直接运行，只是这个中间件没有做任何工作。中间件是一个函数，返回值是一个匿名函数（<code>defn</code>是基于<code>fn</code>的，详情可见<code>(doc defn)</code>）。<code>handler</code>参数则是前一个中间件返回的匿名函数，<code>request</code>是用户发送过来的请求（map形式）。这些中间件组合起来就成为了一条处理链。<code>add-middleware</code>则是Noir定义的函数，将用户自定义的中间件添加到处理链中。</p>

<p>下面我们就写这样一个中间件，每次请求时都去检测Session和Cookie中是否包含用户的登录信息，并将该信息放到<code>request</code>的map中：</p>

<p>```clojure
(defn authenticate [handler]
  (fn [request]</p>

<pre><code>(let [user (if-let [userid (session/get :userid)]
            [userid (session/get :username)]
            (when-let [userid (cookies/get :userid)]
              (let [username (cookies/get :username)]
                (do
                  (session/put! :userid userid)
                  (session/put! :username username)
                  [userid username]))))
      req (if user
            (assoc request :user (zipmap [:userid :username] user))
            request)]
  (handler req))))
</code></pre>

<p>```</p>

<p>这段代码中对于session和cookies的调用和上面没有差异，比较陌生的可能是<code>assoc</code>和<code>zipmap</code>方法，他们都是用来操作map数据类型的：前者会向一个map对象添加键值，并返回一个新的map；后者则会接收两个序列作为参数，两两组合成一个map并返回。</p>

<p>这样我们就能将<code>/whoami</code>的代码修改为：</p>

<p>```clojure
(ns ...</p>

<pre><code>(:require [noir.request :as request]))
</code></pre>

<p>(defpage "/whoami" []</p>

<pre><code>     (if-let [user (:user (request/ring-request))]
       (:username user)
       "unkown"))
</code></pre>

<p>```</p>

<p>其中，<code>ring-request</code>用来获得用户的<code>request</code>map对象。</p>

<h2>程序发布</h2>

<p>这里介绍三种Web应用程序的发布方式。</p>

<h3>直接使用Leiningen</h3>

<p>如果服务器上安装有<code>lein</code>环境，则可以直接调用它来启动程序。只有一点需要注意，因为在默认情况下，<code>lein run</code>启动的程序会被包装在Leiningen的JVM中，这样会占用一些额外的内存，同时引起一些<code>stdin</code>方面的问题。解决方法是使用<code>lein trampoline run</code>命令来启动程序，这样Leiningen为程序启动一个独立的JVM，并退出自己的JVM。</p>

<h3>编译为独立Jar包</h3>

<p><code>lein uberjar</code>命令可以将项目编译后的代码及其所有的依赖包打入一个Jar文件中，和Maven的assembly插件类似。需要注意的是，Clojure文件在默认情况下是不会生成类文件的，而是在运行时进行解析。这样一来，当使用<code>java -jar</code>命令执行时会提示找不到类定义的错误。解决方法是为包含入口函数的模块生成类文件，需要在<code>src/blog/server.clj</code>的<code>ns</code>声明中添加<code>gen-class</code>标识：</p>

<p>```clojure
(ns blog.server</p>

<pre><code>...
(:gen-class))
</code></pre>

<p>```</p>

<p>然后就能打包运行了：</p>

<p><code>bash
$ lein uberjar
$ java -jar blog-0.1.0-SNAPSHOT-standalone.jar
2012-12-23 00:07:47.417:INFO::jetty-6.1.x
2012-12-23 00:07:47.430:INFO::Started SocketConnector@0.0.0.0:8080
</code></p>

<p>可以在程序前部署一个Nginx代理做转发，配置方法就不在这里赘述了。</p>

<h3>使用Tomcat</h3>

<p>以上两种方法使用的都是Jetty这个Web容器，虽然比较方便，但在生产环境中我们更倾向于使用Tomcat。</p>

<p>对于Tomcat的安装这里不做讲解，读者可以到<a href="http://tomcat.apache.org/">Tomcat官网</a>查阅。</p>

<p>Clojure代码也需要做一些修改，我们需要提供一个接口供Tomcat调用，也就是<code>Handler</code>。在<code>src/blog/server.clj</code>中添加以下代码：</p>

<p>```clojure
(def handler (server/gen-handler</p>

<pre><code>           {:mode :prod,
            :ns 'blog}))
</code></pre>

<p>```</p>

<p><code>gen-handler</code>是Noir的函数，用来生成一个<code>Handler</code>。<code>'blog</code>前的单引号大家应该还有印象，它表示命名空间。</p>

<p><code>server.clj</code>还有一项内容需要修改：删除<code>load-views</code>，改为显式的<code>require</code>，这样才能保证在编译期间就加载路由配置，Tomcat才会认可。代码如下：</p>

<p>```clojure
(ns ...</p>

<pre><code>(:require [blog.views welcome article]))
</code></pre>

<p>; (server/load-views "src/blog/views")
```</p>

<p>和<code>uberjar</code>类似，我们需要使用<code>uberwar</code>来打包成一个包含所有依赖项的war包。不过这个工具是由一个Leiningen插件提供的：<code>lein-ring</code>，安装过程和<code>lein-noir</code>类似，首先在<code>project.clj</code>添加dev依赖，然后执行<code>lein deps</code>安装。要使上述<code>handler</code>生效，<code>project.clj</code>中还需要增加一项名为<code>:ring</code>的配置：</p>

<p>```clojure
(defproject blog ...</p>

<pre><code>        ...
        :dev-dependencies [...
                           [lein-ring "0.7.5"]]
        :ring {:handler blog.server/handler})
</code></pre>

<p>```</p>

<p>执行<code>lein ring uberwar</code>命令，将生成的war包放置到Tomcat的webapps目录中，命名为ROOT.war，也可以设置<a href="http://tomcat.apache.org/tomcat-7.0-doc/virtual-hosting-howto.html">Virtual Hosting</a>。片刻后，Tomcat会应用这个新的程序，我们就能在浏览器中访问了。</p>

<h2>发布至云端Heroku</h2>

<p>最后，我们来尝试将这个博客程序部署到线上环境中。如今云计算已经非常流行，有许多优秀的<a href="http://en.wikipedia.org/wiki/Platform_as_a_service">PaaS</a>平台，<a href="http://www.heroku.com">Heroku</a>就是其中之一。在Heroku上部署一个小型的应用是完全免费的，这里我们简述一下步骤，更详细的操作方法可以参考它的<a href="https://devcenter.heroku.com/articles/clojure">帮助文档</a>。</p>

<ul>
<li>登录Heroku网站并注册账号；</li>
<li>安装<a href="https://toolbelt.heroku.com/">Toolbelt</a>，从而能在命令行中使用<code>heroku</code>命令；</li>
<li>执行<code>heroku login</code>命令，输入账号密码，完成验证；</li>
<li>新建<code>src/Procfile</code>文件，输入<code>web: lein trampoline run blog.server</code>；</li>
<li>执行<code>foreman start</code>命令，可以在本地测试程序；</li>
<li>执行<code>heroku create</code>，Heroku会为你分配一个空间；</li>
<li>执行<code>git push heroku master</code>，将本地代码推送至云端，可以看到编译信息，并得到一个URL，通过它就能访问我们的应用程序了。</li>
</ul>


<p>以上步骤省略了数据库的配置，读者可以自行到<a href="https://addons.heroku.com/cleardb">Heroku ClearDB</a>页面查看配置方法。</p>

<h2>小结</h2>

<p>至此我们完成了对Noir网站开发框架的简介，也完成了对Clojure这门语言的入门介绍。不过《Clojure实战》系列还远没有结束，下一章开始我们会进入Clojure语言更擅长的领域——计算。我们会陆续介绍如何使用Clojure编写<a href="http://hadoop.apache.org">Hadoop</a> MapReduce脚本、编写<a href="http://www.storm-project.net">Storm</a> Topology、以及如何使用<a href="http://incanter.org/">Incanter</a>进行可视化数据分析。不过在此之前，我强烈建议读者能够回头看看第一章中提到的几个Clojure教程，这样能对Clojure语言的整体架构有一个印象，接下来的学习才会更为顺畅。</p>

<h3>PS</h3>

<p>在撰写这份Noir框架教程时，Noir作者宣布停止对Noir的开发和维护，鼓励开发者转而使用Ring+Compojure+lib-noir的方式进行开发。这对我们并无太大影响，毕竟我们只是利用Noir来学习Clojure，而且前文提过Noir本身就是基于Ring和Compojure这两个类库的，迁移起来非常方便，我会为此再写一篇博客的。</p>
]]></content>
  </entry>
  
</feed>
