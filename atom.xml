<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ji ZHANG&#39;s Blog</title>
  
  <subtitle>If I rest, I rust.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://shzhangji.com/"/>
  <updated>2018-09-13T00:36:57.000Z</updated>
  <id>http://shzhangji.com/</id>
  
  <author>
    <name>Ji ZHANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Is It Necessary to Apply ESLint jsx-no-bind Rule?</title>
    <link href="http://shzhangji.com/blog/2018/09/13/is-it-necessary-to-apply-eslint-jsx-no-bind-rule/"/>
    <id>http://shzhangji.com/blog/2018/09/13/is-it-necessary-to-apply-eslint-jsx-no-bind-rule/</id>
    <published>2018-09-13T00:24:00.000Z</published>
    <updated>2018-09-13T00:36:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>When using <a href="https://github.com/yannickcr/eslint-plugin-react" target="_blank" rel="noopener">ESLint React plugin</a>, you may find a rule called <a href="https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md" target="_blank" rel="noopener"><code>jsx-no-bind</code></a>. It prevents you from using <code>.bind</code> or arrow function in a JSX prop. For instance, ESLint will complain about the arrow function in the <code>onClick</code> prop.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListArrow</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;ul&gt;</span><br><span class="line">        &#123;<span class="keyword">this</span>.state.items.map(<span class="function"><span class="params">item</span> =&gt;</span> (</span><br><span class="line">          &lt;li key=&#123;item.id&#125; onClick=&#123;() =&gt; &#123; alert(item.id) &#125;&#125;&gt;&#123;item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">        ))&#125;</span></span><br><span class="line"><span class="regexp">      &lt;/u</span>l&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There’re two reasons why this rule is introduced. First, a new function will be created on every <code>render</code> call, which may increase the frequency of garbage collection. Second, it will disable the pure rendering process, i.e. when you’re using a <code>PureComponent</code>, or implement the <code>shouldComponentUpdate</code> method by yourself with identity comparison, a new function object in the props will cause unnecessary re-render of the component.</p><p>But some people argue that these two reasons are not solid enough to enforce this rule on all projects, especially when the solutions will introduce more codes and decrease readability. In <a href="https://github.com/airbnb/javascript/blob/eslint-config-airbnb-v17.1.0/packages/eslint-config-airbnb/rules/react.js#L93" target="_blank" rel="noopener">Airbnb ESLint preset</a>, the team only bans the usage of <code>.bind</code>, but allows arrow function in both props and refs. I did some googling, and was convinced that this rule is not quite necessary. Someone says it’s premature optimization, and you should measure before you optimize. I agree with that. In the following sections, I will illustrate how arrow function would affect the pure component, what solutions we can use, and talk a little bit about React rendering internals.</p><a id="more"></a><h2 id="Different-Types-of-React-Component"><a href="#Different-Types-of-React-Component" class="headerlink" title="Different Types of React Component"></a>Different Types of React Component</h2><p>The regular way to create a React component is to extend the <code>React.Component</code> class and implement the <code>render</code> method. There is also a built-in <code>React.PureComponent</code>, which implements the life-cycle method <code>shouldComponentUpdate</code> for you. In regular component, this method will always return <code>true</code>, indicating that React should call <code>render</code> whenever the props or states change. <code>PureComponent</code>, on the other hand, does a shallow identity comparison for the props and states to see whether this component should be re-rendered. The following two components behave the same:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PureChild</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">PureComponent</span> </span>&#123;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;div&gt;&#123;<span class="keyword">this</span>.props.message&#125;&lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">class RegularChild extends React.Component &#123;</span></span><br><span class="line"><span class="regexp">  shouldComponentUpdate(nextProps, nextStates) &#123;</span></span><br><span class="line"><span class="regexp">    return this.props.message !== nextProps.message</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">  render() &#123;</span></span><br><span class="line"><span class="regexp">    return (</span></span><br><span class="line"><span class="regexp">      &lt;div&gt;&#123;this.props.message&#125;&lt;/</span>div&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When their parent component is re-rendering, they will both check the message content in props and decide whether they should render again. The comparison rule is quite simple in pure component, it iterates the props and states object, compare each others’ members with <code>===</code> equality check. In JavaScript, only primitive types and the very same object will pass this test, for example:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> === <span class="number">1</span></span><br><span class="line"><span class="string">'hello world'</span> === <span class="string">'hello world'</span></span><br><span class="line">[] !== []</span><br><span class="line">(<span class="function"><span class="params">()</span> =&gt;</span> &#123;&#125;) !== <span class="function">(<span class="params">(</span>) =&gt;</span> &#123;&#125;)</span><br></pre></td></tr></table></figure><p>Clearly, arrow functions will fail the test and cause pure component to re-render every time its parent is re-rendered. On the other side, if you do not use pure component, or do props and states check on your own, enabling the <code>jsx-no-bind</code> rule is plain unnecessary.</p><p>Recently another kind of component has become popular, the stateless functional component (SFC). These components’ render results solely depend on their props, so they are like functions that take inputs and produce steady outputs. But under the hood, they are just regular components, i.e. they do not implement <code>shouldComponentUpdate</code>, and you can not implement by yourself either.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> StatelessChild = <span class="function">(<span class="params">props</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> (</span><br><span class="line">    &lt;div&gt;&#123;props.message&#125;&lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">  )</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="How-to-Fix-jsx-no-bind-Error"><a href="#How-to-Fix-jsx-no-bind-Error" class="headerlink" title="How to Fix jsx-no-bind Error"></a>How to Fix <code>jsx-no-bind</code> Error</h2><p>Arrow functions are usually used in event handlers. If we use normal functions or class methods, <code>this</code> keyword is not bound to the current instance, it is <code>undefined</code>. By using <code>.bind</code> or arrow function, we can access other class methods through <code>this</code>. To fix the <code>jsx-no-bind</code> error while still keeping the handler function bound, we can either bind it in constructor, or use the experimental class property syntax, which can be transformed by <a href="https://babeljs.io/docs/plugins/transform-class-properties/" target="_blank" rel="noopener">Babel</a>. More information can be found in React <a href="https://reactjs.org/docs/handling-events.html" target="_blank" rel="noopener">official document</a>, and here is the <a href="https://github.com/jizhang/jsx-no-bind/blob/master/src/components/NoArgument.js" target="_blank" rel="noopener">gist</a> of different solutions.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="class"><span class="keyword">class</span> <span class="title">NoArgument</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constructor</span>() &#123;</span><br><span class="line">    <span class="keyword">this</span>.handleClickBoundA = <span class="keyword">this</span>.handleClickUnbound.bind(<span class="keyword">this</span>)</span><br><span class="line">    <span class="keyword">this</span>.handleClickBoundC = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.setState() &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  handleClickUnbound() &#123; <span class="comment">/* "this" is undefined */</span> &#125;</span><br><span class="line">  handleClickBoundB = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.setState() &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;div&gt;</span><br><span class="line">        <span class="built_in">Error</span>: jsx-no-bind</span><br><span class="line">        &lt;button onClick=&#123;() =&gt; &#123; <span class="keyword">this</span>.setState() &#125;&#125;&gt;ArrowA&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;() =&gt; &#123; this.handleClickUnbound() &#125;&#125;&gt;ArrowB&lt;/</span>button&gt;</span><br><span class="line">        &lt;button onClick=&#123;<span class="keyword">this</span>.handleClickUnbound.bind(<span class="keyword">this</span>)&#125;&gt;Bind&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        No error:</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;this.handleClickBoundA&#125;&gt;BoundA&lt;/</span>button&gt;</span><br><span class="line">        &lt;button onClick=&#123;<span class="keyword">this</span>.handleClickBoundB&#125;&gt;BoundB&lt;<span class="regexp">/button&gt;</span></span><br><span class="line"><span class="regexp">        &lt;button onClick=&#123;this.handleClickBoundC&#125;&gt;BoundC&lt;/</span>button&gt;</span><br><span class="line">      &lt;<span class="regexp">/div&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><p>For handlers that require extra arguments, e.g. a list of clickable items, things will be a little tricky. There’re two possible solutions, one is to create separate component for the item, and pass handler function and argument as props.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Item</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">PureComponent</span> </span>&#123;</span><br><span class="line">  handleClick = <span class="function"><span class="params">()</span> =&gt;</span> &#123; <span class="keyword">this</span>.props.onClick(<span class="keyword">this</span>.props.item.id) &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;li onClick=&#123;<span class="keyword">this</span>.handleClick&#125;&gt;&#123;<span class="keyword">this</span>.props.item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">export default class ListSeparate extends React.Component &#123;</span></span><br><span class="line"><span class="regexp">  handleClick = (itemId) =&gt; &#123; alert(itemId) &#125;</span></span><br><span class="line"><span class="regexp">  render() &#123;</span></span><br><span class="line"><span class="regexp">    return (</span></span><br><span class="line"><span class="regexp">      &lt;ul&gt;</span></span><br><span class="line"><span class="regexp">        &#123;this.props.items.map(item =&gt; (</span></span><br><span class="line"><span class="regexp">          &lt;Item key=&#123;item.id&#125; item=&#123;item&#125; onClick=&#123;this.handleClick&#125; /</span>&gt;</span><br><span class="line">        ))&#125;</span><br><span class="line">      &lt;<span class="regexp">/ul&gt;</span></span><br><span class="line"><span class="regexp">    )</span></span><br><span class="line"><span class="regexp">  &#125;</span></span><br><span class="line"><span class="regexp">&#125;</span></span><br></pre></td></tr></table></figure><p>This is a practice of separation of concerns, because now <code>List</code> only iterates the items, while <code>Item</code> takes care of rendering them. But this also adds a lot of codes, and make them hard to understand. We need to go through several handler functions to see what they actually do, while in the arrow function example, event handlers are co-located with the component, which is encouraged by React community.</p><p>Another approach is to use DOM <a href="https://developer.mozilla.org/en/docs/Web/API/HTMLElement/dataset" target="_blank" rel="noopener"><code>dataset</code></a> property, i.e. store argument in HTML <code>data-*</code> attribute, and retrieve it with <code>event</code> argument in handler functions.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="class"><span class="keyword">class</span> <span class="title">ListDataset</span> <span class="keyword">extends</span> <span class="title">React</span>.<span class="title">Component</span> </span>&#123;</span><br><span class="line">  handleClick = <span class="function">(<span class="params">event</span>) =&gt;</span> &#123; alert(event.target.dataset.itemId) &#125;</span><br><span class="line">  render() &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      &lt;ul&gt;</span><br><span class="line">        &#123;<span class="keyword">this</span>.props.items.map(<span class="function"><span class="params">item</span> =&gt;</span> (</span><br><span class="line">          &lt;li key=&#123;item.id&#125; data-item-id=&#123;item.id&#125; onClick=&#123;<span class="keyword">this</span>.handleClick&#125;&gt;&#123;item.text&#125;&lt;<span class="regexp">/li&gt;</span></span><br><span class="line"><span class="regexp">        ))&#125;</span></span><br><span class="line"><span class="regexp">      &lt;/u</span>l&gt;</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Virtual-DOM-and-Reconciliation"><a href="#Virtual-DOM-and-Reconciliation" class="headerlink" title="Virtual DOM and Reconciliation"></a>Virtual DOM and Reconciliation</h2><p>Arrow function will cause pure components unnecessary re-rendering, actually this statement is partly true. React rendering process has several steps. First, call <code>render</code> function that returns a tree of React elements; compare them with the virtual DOM; and then, apply the difference to the real DOM. The latter process is also called <a href="https://reactjs.org/docs/reconciliation.html" target="_blank" rel="noopener">reconciliation</a>. So even if the <code>render</code> function is called multiple times, the resulting tree of elements may not change at all, so there is no DOM manipulation, and that usually costs more time than pure JavaScript code. For components that constantly change, making them pure just adds one more time of unnecessary comparison.</p><p><img src="/images/jsx-no-bind/should-component-update.png" alt="shouldComponentUpdate"></p><p><a href="https://reactjs.org/docs/optimizing-performance.html#shouldcomponentupdate-in-action" target="_blank" rel="noopener">Source</a></p><p>Besides, change of event handlers will probably not cause re-rendering of the real DOM, because React only listens event on the <code>document</code> level. When the <code>onClick</code> event is triggered on the <code>li</code> element, it will bubble up to the top level and get processed by React event management system.</p><p><img src="/images/jsx-no-bind/top-level-delegation.jpg" alt="Top-level Delegation"></p><p><a href="https://levelup.gitconnected.com/how-exactly-does-react-handles-events-71e8b5e359f2" target="_blank" rel="noopener">Source</a></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>To fix <code>jsx-no-bind</code> we need to trade off readability, and yet the performance may not improve as much as we thought. So instead of guessing what may cause performance problem, why not program in a natural way at first, and when there occurs some noticeable performance issues, take measures, and fix them with appropriate techniques.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md" target="_blank" rel="noopener">https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md</a></li><li><a href="https://cdb.reacttraining.com/react-inline-functions-and-performance-bdff784f5578" target="_blank" rel="noopener">https://cdb.reacttraining.com/react-inline-functions-and-performance-bdff784f5578</a></li><li><a href="https://maarten.mulders.it/blog/2017/07/no-bind-or-arrow-in-jsx-props-why-how.html" target="_blank" rel="noopener">https://maarten.mulders.it/blog/2017/07/no-bind-or-arrow-in-jsx-props-why-how.html</a></li><li><a href="https://reactjs.org/docs/faq-functions.html#example-passing-params-using-data-attributes" target="_blank" rel="noopener">https://reactjs.org/docs/faq-functions.html#example-passing-params-using-data-attributes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When using &lt;a href=&quot;https://github.com/yannickcr/eslint-plugin-react&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ESLint React plugin&lt;/a&gt;, you may find a rule called &lt;a href=&quot;https://github.com/yannickcr/eslint-plugin-react/blob/master/docs/rules/jsx-no-bind.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;jsx-no-bind&lt;/code&gt;&lt;/a&gt;. It prevents you from using &lt;code&gt;.bind&lt;/code&gt; or arrow function in a JSX prop. For instance, ESLint will complain about the arrow function in the &lt;code&gt;onClick&lt;/code&gt; prop.&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ListArrow&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;React&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Component&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  render() &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;lt;ul&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &amp;#123;&lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;.state.items.map(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;params&quot;&gt;item&lt;/span&gt; =&amp;gt;&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;          &amp;lt;li key=&amp;#123;item.id&amp;#125; onClick=&amp;#123;() =&amp;gt; &amp;#123; alert(item.id) &amp;#125;&amp;#125;&amp;gt;&amp;#123;item.text&amp;#125;&amp;lt;&lt;span class=&quot;regexp&quot;&gt;/li&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;regexp&quot;&gt;        ))&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;regexp&quot;&gt;      &amp;lt;/u&lt;/span&gt;l&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;There’re two reasons why this rule is introduced. First, a new function will be created on every &lt;code&gt;render&lt;/code&gt; call, which may increase the frequency of garbage collection. Second, it will disable the pure rendering process, i.e. when you’re using a &lt;code&gt;PureComponent&lt;/code&gt;, or implement the &lt;code&gt;shouldComponentUpdate&lt;/code&gt; method by yourself with identity comparison, a new function object in the props will cause unnecessary re-render of the component.&lt;/p&gt;
&lt;p&gt;But some people argue that these two reasons are not solid enough to enforce this rule on all projects, especially when the solutions will introduce more codes and decrease readability. In &lt;a href=&quot;https://github.com/airbnb/javascript/blob/eslint-config-airbnb-v17.1.0/packages/eslint-config-airbnb/rules/react.js#L93&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Airbnb ESLint preset&lt;/a&gt;, the team only bans the usage of &lt;code&gt;.bind&lt;/code&gt;, but allows arrow function in both props and refs. I did some googling, and was convinced that this rule is not quite necessary. Someone says it’s premature optimization, and you should measure before you optimize. I agree with that. In the following sections, I will illustrate how arrow function would affect the pure component, what solutions we can use, and talk a little bit about React rendering internals.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="javascript" scheme="http://shzhangji.com/tags/javascript/"/>
    
      <category term="react" scheme="http://shzhangji.com/tags/react/"/>
    
      <category term="eslint" scheme="http://shzhangji.com/tags/eslint/"/>
    
  </entry>
  
  <entry>
    <title>Serve TensforFlow Estimator with SavedModel</title>
    <link href="http://shzhangji.com/blog/2018/05/14/serve-tensorflow-estimator-with-savedmodel/"/>
    <id>http://shzhangji.com/blog/2018/05/14/serve-tensorflow-estimator-with-savedmodel/</id>
    <published>2018-05-14T01:43:14.000Z</published>
    <updated>2018-05-14T01:46:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.tensorflow.org/" target="_blank" rel="noopener">TensorFlow</a> is one of the most popular machine learning frameworks that allow us to build various models with minor efforts. There are several ways to utilize these models in production like web service API, and this article will introduce how to make model prediction APIs with TensorFlow’s SavedModel mechanism.</p><p><img src="/images/tf-logo.png" alt=""></p><h2 id="Iris-DNN-Estimator"><a href="#Iris-DNN-Estimator" class="headerlink" title="Iris DNN Estimator"></a>Iris DNN Estimator</h2><p>First let’s build the famous iris classifier with TensorFlow’s pre-made DNN estimator. Full illustration can be found on TensorFlow’s website (<a href="https://www.tensorflow.org/get_started/premade_estimators" target="_blank" rel="noopener">Premade Estimators</a>), and I create a repository on GitHub (<a href="https://github.com/jizhang/tf-serve/blob/master/iris_dnn.py" target="_blank" rel="noopener"><code>iris_dnn.py</code></a>) for you to fork and work with. Here’s the gist of training the model:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">feature_columns = [tf.feature_column.numeric_column(key=key)</span><br><span class="line">                   <span class="keyword">for</span> key <span class="keyword">in</span> train_x.keys()]</span><br><span class="line">classifier = tf.estimator.DNNClassifier(</span><br><span class="line">    feature_columns=feature_columns,</span><br><span class="line">    hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</span><br><span class="line">    n_classes=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">classifier.train(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: train_input_fn(train_x, train_y, batch_size=BATCH_SIZE),</span><br><span class="line">    steps=STEPS)</span><br><span class="line"></span><br><span class="line">predictions = classifier.predict(</span><br><span class="line">    input_fn=<span class="keyword">lambda</span>: eval_input_fn(predict_x, labels=<span class="keyword">None</span>, batch_size=BATCH_SIZE))</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Export-as-SavedModel"><a href="#Export-as-SavedModel" class="headerlink" title="Export as SavedModel"></a>Export as SavedModel</h2><p>TensorFlow provides the <a href="https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators" target="_blank" rel="noopener">SavedModel</a> utility to let us export the trained model for future predicting and serving. <code>Estimator</code> exposes an <code>export_savedmodel</code> method, which requires two arguments: the export directory and a receiver function. Latter defines what kind of input data the exported model accepts. Usually we will use TensorFlow’s <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/core/example/example.proto" target="_blank" rel="noopener"><code>Example</code></a> type, which contains the features of one or more items. For instance, an iris data item can be defined as:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Example(</span><br><span class="line">    features=Features(</span><br><span class="line">        feature=&#123;</span><br><span class="line">            <span class="string">'SepalLength'</span>: Feature(float_list=FloatList(value=[<span class="number">5.1</span>])),</span><br><span class="line">            <span class="string">'SepalWidth'</span>: Feature(float_list=FloatList(value=[<span class="number">3.3</span>])),</span><br><span class="line">            <span class="string">'PetalLength'</span>: Feature(float_list=FloatList(value=[<span class="number">1.7</span>])),</span><br><span class="line">            <span class="string">'PetalWidth'</span>: Feature(float_list=FloatList(value=[<span class="number">0.5</span>])),</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The receiver function needs to be able to parse the incoming serialized <code>Example</code> object into a map of tensors for model to consume. TensorFlow provides some utility functions to help building it. We first transform the <code>feature_columns</code> array into a map of <code>Feature</code> as the parsing specification, and then use it to build the receiver function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [</span></span><br><span class="line"><span class="comment">#     _NumericColumn(key='SepalLength', shape=(1,), dtype=tf.float32),</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment"># ]</span></span><br><span class="line">feature_columns = [tf.feature_column.numeric_column(key=key)</span><br><span class="line">                   <span class="keyword">for</span> key <span class="keyword">in</span> train_x.keys()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#     'SepalLength': FixedLenFeature(shape=(1,), dtype=tf.float32),</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line">feature_spec = tf.feature_column.make_parse_example_spec(feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build receiver function, and export.</span></span><br><span class="line">serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)</span><br><span class="line">export_dir = classifier.export_savedmodel(<span class="string">'export'</span>, serving_input_receiver_fn)</span><br></pre></td></tr></table></figure><h2 id="Inspect-SavedModel-with-CLI-Tool"><a href="#Inspect-SavedModel-with-CLI-Tool" class="headerlink" title="Inspect SavedModel with CLI Tool"></a>Inspect SavedModel with CLI Tool</h2><p>Each export will create a timestamped directory, containing the information of the trained model.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export/1524907728/saved_model.pb</span><br><span class="line">export/1524907728/variables</span><br><span class="line">export/1524907728/variables/variables.data-00000-of-00001</span><br><span class="line">export/1524907728/variables/variables.index</span><br></pre></td></tr></table></figure><p>TensorFlow provides a command line tool to inspect the exported model, or even run predictions with it.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ saved_model_cli show --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default</span><br><span class="line">The given SavedModel SignatureDef contains the following input(s):</span><br><span class="line">  inputs[<span class="string">'inputs'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1)</span><br><span class="line">The given SavedModel SignatureDef contains the following output(s):</span><br><span class="line">  outputs[<span class="string">'classes'</span>] tensor_info:</span><br><span class="line">      dtype: DT_STRING</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">  outputs[<span class="string">'scores'</span>] tensor_info:</span><br><span class="line">      dtype: DT_FLOAT</span><br><span class="line">      shape: (-1, 3)</span><br><span class="line">Method name is: tensorflow/serving/classify</span><br><span class="line"></span><br><span class="line">$ saved_model_cli run --dir <span class="built_in">export</span>/1524906774 \</span><br><span class="line">  --tag_set serve --signature_def serving_default \</span><br><span class="line">  --input_examples <span class="string">'inputs=[&#123;"SepalLength":[5.1],"SepalWidth":[3.3],"PetalLength":[1.7],"PetalWidth":[0.5]&#125;]'</span></span><br><span class="line">Result <span class="keyword">for</span> output key classes:</span><br><span class="line">[[b<span class="string">'0'</span> b<span class="string">'1'</span> b<span class="string">'2'</span>]]</span><br><span class="line">Result <span class="keyword">for</span> output key scores:</span><br><span class="line">[[9.9919027e-01 8.0969761e-04 1.2872645e-09]]</span><br></pre></td></tr></table></figure><h2 id="Serve-SavedModel-with-contrib-predictor"><a href="#Serve-SavedModel-with-contrib-predictor" class="headerlink" title="Serve SavedModel with contrib.predictor"></a>Serve SavedModel with <code>contrib.predictor</code></h2><p>In <code>contrib.predictor</code> package, there is a convenient method for us to build a predictor function from exported model.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load model from export directory, and make a predict function.</span></span><br><span class="line">predict_fn = tf.contrib.predictor.from_saved_model(export_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test inputs represented by Pandas DataFrame.</span></span><br><span class="line">inputs = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">'SepalLength'</span>: [<span class="number">5.1</span>, <span class="number">5.9</span>, <span class="number">6.9</span>],</span><br><span class="line">    <span class="string">'SepalWidth'</span>: [<span class="number">3.3</span>, <span class="number">3.0</span>, <span class="number">3.1</span>],</span><br><span class="line">    <span class="string">'PetalLength'</span>: [<span class="number">1.7</span>, <span class="number">4.2</span>, <span class="number">5.4</span>],</span><br><span class="line">    <span class="string">'PetalWidth'</span>: [<span class="number">0.5</span>, <span class="number">1.5</span>, <span class="number">2.1</span>],</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert input data into serialized Example strings.</span></span><br><span class="line">examples = []</span><br><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> inputs.iterrows():</span><br><span class="line">    feature = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> col, value <span class="keyword">in</span> row.iteritems():</span><br><span class="line">        feature[col] = tf.train.Feature(float_list=tf.train.FloatList(value=[value]))</span><br><span class="line">    example = tf.train.Example(</span><br><span class="line">        features=tf.train.Features(</span><br><span class="line">            feature=feature</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    examples.append(example.SerializeToString())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = predict_fn(&#123;<span class="string">'inputs'</span>: examples&#125;)</span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#     'classes': [</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2'],</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2'],</span></span><br><span class="line"><span class="comment">#         [b'0', b'1', b'2']</span></span><br><span class="line"><span class="comment">#     ],</span></span><br><span class="line"><span class="comment">#     'scores': [</span></span><br><span class="line"><span class="comment">#         [9.9826765e-01, 1.7323202e-03, 4.7271198e-15],</span></span><br><span class="line"><span class="comment">#         [2.1470961e-04, 9.9776912e-01, 2.0161823e-03],</span></span><br><span class="line"><span class="comment">#         [4.2676111e-06, 4.8709501e-02, 9.5128632e-01]</span></span><br><span class="line"><span class="comment">#     ]</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><p>We can tidy up the prediction outputs to make the result clearer:</p><table><thead><tr><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>ClassID</th><th>Probability</th></tr></thead><tbody><tr><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>0</td><td>0.998268</td></tr><tr><td>5.9</td><td>3.0</td><td>4.2</td><td>1.5</td><td>1</td><td>0.997769</td></tr><tr><td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td>2</td><td>0.951286</td></tr></tbody></table><p>Under the hood, <code>from_saved_model</code> uses the <code>saved_model.loader</code> to load the exported model to a TensorFlow session, extract input / output definitions, create necessary tensors and invoke <code>session.run</code> to get results. I write a simple example (<a href="https://github.com/jizhang/tf-serve/blob/master/iris_sess.py" target="_blank" rel="noopener"><code>iris_sess.py</code></a>) of this workflow, or you can refer to TensorFlow’s source code <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/predictor/saved_model_predictor.py" target="_blank" rel="noopener"><code>saved_model_predictor.py</code></a>. <a href="https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/tools/saved_model_cli.py" target="_blank" rel="noopener"><code>saved_model_cli</code></a> also works this way.</p><h2 id="Serve-SavedModel-with-TensorFlow-Serving"><a href="#Serve-SavedModel-with-TensorFlow-Serving" class="headerlink" title="Serve SavedModel with TensorFlow Serving"></a>Serve SavedModel with TensorFlow Serving</h2><p>Finally, let’s see how to use TensorFlow’s side project, <a href="https://www.tensorflow.org/serving/" target="_blank" rel="noopener">TensorFlow Serving</a>, to expose our trained model to the outside world.</p><h3 id="Setup-TensorFlow-ModelServer"><a href="#Setup-TensorFlow-ModelServer" class="headerlink" title="Setup TensorFlow ModelServer"></a>Setup TensorFlow ModelServer</h3><p>TensorFlow server code is written in C++. A convenient way to install it is via package repository. You can follow the <a href="https://www.tensorflow.org/serving/setup" target="_blank" rel="noopener">official document</a>, add the TensorFlow distribution URI, and install the binary:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install tensorflow-model-server</span><br></pre></td></tr></table></figure><p>Then use the following command to start a ModelServer, which will automatically pick up the latest model from the export directory.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ tensorflow_model_server --port=9000 --model_base_path=/root/<span class="built_in">export</span></span><br><span class="line">2018-05-14 01:05:12.561 Loading SavedModel with tags: &#123; serve &#125;; from: /root/<span class="built_in">export</span>/1524907728</span><br><span class="line">2018-05-14 01:05:12.639 Successfully loaded servable version &#123;name: default version: 1524907728&#125;</span><br><span class="line">2018-05-14 01:05:12.641 Running ModelServer at 0.0.0.0:9000 ...</span><br></pre></td></tr></table></figure><h3 id="Request-Remote-Model-via-SDK"><a href="#Request-Remote-Model-via-SDK" class="headerlink" title="Request Remote Model via SDK"></a>Request Remote Model via SDK</h3><p>TensorFlow Serving is based on gRPC and Protocol Buffers. So as to make remote procedure calls, we need to install the TensorFlow Serving API, along with its dependencies. Note that TensorFlow only provides client SDK in Python 2.7, but there is a contributed Python 3.x package available on PyPI.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install tensorflow-seving-api-python3==1.7.0</span><br></pre></td></tr></table></figure><p>The procedure is straight forward, we create the connection, assemble some <code>Example</code> instances, send to remote server and get the predictions. Full code can be found in <a href="https://github.com/jizhang/tf-serve/blob/master/iris_remote.py" target="_blank" rel="noopener"><code>iris_remote.py</code></a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create connection, boilerplate of gRPC.</span></span><br><span class="line">channel = implementations.insecure_channel(<span class="string">'127.0.0.1'</span>, <span class="number">9000</span>)</span><br><span class="line">stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get test inputs, and assemble a list of Examples, unserialized.</span></span><br><span class="line">inputs = pd.DateFrame()</span><br><span class="line">examples = [tf.tain.Example() <span class="keyword">for</span> index, row <span class="keyword">in</span> inputs.iterrows()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare RPC request, specify the model name.</span></span><br><span class="line">request = classification_pb2.ClassificationRequest()</span><br><span class="line">request.model_spec.name = <span class="string">'default'</span></span><br><span class="line">request.input.example_list.examples.extend(examples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get response, and tidy up.</span></span><br><span class="line">response = stub.Classify(request, <span class="number">10.0</span>)</span><br><span class="line"><span class="comment"># result &#123;</span></span><br><span class="line"><span class="comment">#   classifications &#123;</span></span><br><span class="line"><span class="comment">#     classes &#123;</span></span><br><span class="line"><span class="comment">#       label: "0"</span></span><br><span class="line"><span class="comment">#       score: 0.998267650604248</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#     ...</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment">#   ...</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.tensorflow.org/get_started/premade_estimators" target="_blank" rel="noopener">https://www.tensorflow.org/get_started/premade_estimators</a></li><li><a href="https://www.tensorflow.org/programmers_guide/saved_model" target="_blank" rel="noopener">https://www.tensorflow.org/programmers_guide/saved_model</a></li><li><a href="https://www.tensorflow.org/serving/" target="_blank" rel="noopener">https://www.tensorflow.org/serving/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;TensorFlow&lt;/a&gt; is one of the most popular machine learning frameworks that allow us to build various models with minor efforts. There are several ways to utilize these models in production like web service API, and this article will introduce how to make model prediction APIs with TensorFlow’s SavedModel mechanism.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/tf-logo.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Iris-DNN-Estimator&quot;&gt;&lt;a href=&quot;#Iris-DNN-Estimator&quot; class=&quot;headerlink&quot; title=&quot;Iris DNN Estimator&quot;&gt;&lt;/a&gt;Iris DNN Estimator&lt;/h2&gt;&lt;p&gt;First let’s build the famous iris classifier with TensorFlow’s pre-made DNN estimator. Full illustration can be found on TensorFlow’s website (&lt;a href=&quot;https://www.tensorflow.org/get_started/premade_estimators&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Premade Estimators&lt;/a&gt;), and I create a repository on GitHub (&lt;a href=&quot;https://github.com/jizhang/tf-serve/blob/master/iris_dnn.py&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;iris_dnn.py&lt;/code&gt;&lt;/a&gt;) for you to fork and work with. Here’s the gist of training the model:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;feature_columns = [tf.feature_column.numeric_column(key=key)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                   &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; key &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; train_x.keys()]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;classifier = tf.estimator.DNNClassifier(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    feature_columns=feature_columns,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    hidden_units=[&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    n_classes=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;classifier.train(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input_fn=&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt;: train_input_fn(train_x, train_y, batch_size=BATCH_SIZE),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    steps=STEPS)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;predictions = classifier.predict(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input_fn=&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt;: eval_input_fn(predict_x, labels=&lt;span class=&quot;keyword&quot;&gt;None&lt;/span&gt;, batch_size=BATCH_SIZE))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="tensorflow" scheme="http://shzhangji.com/tags/tensorflow/"/>
    
      <category term="machine learning" scheme="http://shzhangji.com/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Connect HBase with Python and Thrift</title>
    <link href="http://shzhangji.com/blog/2018/04/22/connect-hbase-with-python-and-thrift/"/>
    <id>http://shzhangji.com/blog/2018/04/22/connect-hbase-with-python-and-thrift/</id>
    <published>2018-04-22T08:44:12.000Z</published>
    <updated>2018-04-22T07:51:29.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://hbase.apache.org/" target="_blank" rel="noopener">Apache HBase</a> is a key-value store in Hadoop ecosystem. It is based on HDFS, and can provide high performance data access on large amount of volume. HBase is written in Java, and has native support for Java clients. But with the help of Thrift and various language bindings, we can access HBase in web services quite easily. This article will describe how to read and write HBase table with Python and Thrift.</p><p><img src="/images/hbase.png" alt=""></p><h2 id="Generate-Thrift-Class"><a href="#Generate-Thrift-Class" class="headerlink" title="Generate Thrift Class"></a>Generate Thrift Class</h2><p>For anyone who is new to <a href="https://thrift.apache.org/" target="_blank" rel="noopener">Apache Thrift</a>, it provides an IDL (Interface Description Language) to let you describe your service methods and data types and then transform them into different languages. For instance, a Thrift type definition like this:</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TColumn</span> </span>&#123;</span><br><span class="line">  <span class="number">1</span>: <span class="keyword">required</span> <span class="built_in">binary</span> family,</span><br><span class="line">  <span class="number">2</span>: <span class="keyword">optional</span> <span class="built_in">binary</span> qualifier,</span><br><span class="line">  <span class="number">3</span>: <span class="keyword">optional</span> <span class="built_in">i64</span> timestamp</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Will be transformed into the following Python code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TColumn</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, family=None, qualifier=None, timestamp=None,)</span>:</span></span><br><span class="line">        self.family = family</span><br><span class="line">        self.qualifier = qualifier</span><br><span class="line">        self.timestamp = timestamp</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self, iprot)</span>:</span></span><br><span class="line">        iprot.readStructBegin()</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            (fname, ftype, fid) = iprot.readFieldBegin()</span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(self, oprot)</span>:</span></span><br><span class="line">        oprot.writeStructBegin(<span class="string">'TColumn'</span>)</span><br><span class="line">        <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="HBase-Thrift-vs-Thrift2"><a href="#HBase-Thrift-vs-Thrift2" class="headerlink" title="HBase Thrift vs Thrift2"></a>HBase Thrift vs Thrift2</h3><p>HBase provides <a href="https://github.com/apache/hbase/tree/master/hbase-thrift/src/main/resources/org/apache/hadoop/hbase" target="_blank" rel="noopener">two versions</a> of Thrift IDL files, and they have two main differences.</p><p>First, <code>thrift2</code> mimics the data types and methods from HBase Java API, which could be more intuitive to use. For instance, constructing a <code>Get</code> operation in Java is:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Get get = <span class="keyword">new</span> Get(Bytes.toBytes(<span class="string">"rowkey"</span>));</span><br><span class="line">get.addColumn(Bytes.toBytes(<span class="string">"cf"</span>), Bytes.toBytes(<span class="string">"col1"</span>));</span><br><span class="line">get.addColumn(Bytes.toBytes(<span class="string">"cf"</span>), Bytes.toBytes(<span class="string">"col2"</span>));</span><br></pre></td></tr></table></figure><p>In <code>thrift2</code>, there is a corresponding <code>TGet</code> type:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tget = TGet(</span><br><span class="line">    row=<span class="string">'rowkey'</span>,</span><br><span class="line">    columns=[</span><br><span class="line">        TColumn(family=<span class="string">'cf'</span>, qualifier=<span class="string">'col1'</span>),</span><br><span class="line">        TColumn(family=<span class="string">'cf'</span>, qualifier=<span class="string">'col2'</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>While in <code>thrift</code>, we directly invoke one of the <code>get</code> methods:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">client.getRowWithColumns(</span><br><span class="line">    tableName=<span class="string">'tbl'</span>,</span><br><span class="line">    row=<span class="string">'rowkey'</span>,</span><br><span class="line">    columns=[<span class="string">'cf:col1'</span>, <span class="string">'cf:col2'</span>],</span><br><span class="line">    attributes=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The second difference is that <code>thrift2</code> lacks the administration interfaces, like <code>createTable</code>, <code>majorCompact</code>, etc. Currently these APIs are still under development, so if you need to use them via Thrift, you will have to fall back to version one.</p><p>After deciding which version we use, now we can download the <code>hbase.thrift</code> file, and generate Python code from it. One note on Thrift version though. Since we will use Python 3.x, which is supported by Thrift 0.10 onwards, so make sure you install the right version. Execute the following command, and you will get several Python files.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ thrift -gen py hbase.thrift</span><br><span class="line">$ find gen-py</span><br><span class="line">gen-py/hbase/__init__.py</span><br><span class="line">gen-py/hbase/constants.py</span><br><span class="line">gen-py/hbase/THBaseService.py</span><br><span class="line">gen-py/hbase/ttypes.py</span><br></pre></td></tr></table></figure><h2 id="Run-HBase-in-Standalone-Mode"><a href="#Run-HBase-in-Standalone-Mode" class="headerlink" title="Run HBase in Standalone Mode"></a>Run HBase in Standalone Mode</h2><p>In case you do not have a running HBase service to test against, you can follow the quick start guide (<a href="https://hbase.apache.org/book.html#quickstart" target="_blank" rel="noopener">link</a>) to download the binaries, do some minor configuration, and then execute the following commands to start a standalone HBase server as well as the Thrift2 server.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/start-hbase.sh</span><br><span class="line">bin/hbase-daemon.sh start thrift2</span><br><span class="line">bin/hbase shell</span><br></pre></td></tr></table></figure><p>Then in the HBase shell, we create a test table and read / write some data.</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; create <span class="string">"tsdata"</span>, NAME =&gt; <span class="string">"cf"</span></span><br><span class="line">&gt; put <span class="string">"tsdata"</span>, <span class="string">"sys.cpu.user:20180421:192.168.1.1"</span>, <span class="string">"cf:1015"</span>, <span class="string">"0.28"</span></span><br><span class="line">&gt; get <span class="string">"tsdata"</span>, <span class="string">"sys.cpu.user:20180421:192.168.1.1"</span></span><br><span class="line">COLUMN                                        CELL</span><br><span class="line"> <span class="symbol">cf:</span><span class="number">1015</span>                                      timestamp=<span class="number">1524277135973</span>, value=<span class="number">0</span>.<span class="number">28</span></span><br><span class="line"><span class="number">1</span> row(s) <span class="keyword">in</span> <span class="number">0</span>.<span class="number">0330</span> seconds</span><br></pre></td></tr></table></figure><h2 id="Connect-to-HBase-via-Thrift2"><a href="#Connect-to-HBase-via-Thrift2" class="headerlink" title="Connect to HBase via Thrift2"></a>Connect to HBase via Thrift2</h2><p>Here is the boilerplate of making a connection to HBase Thrift server. Note that Thrift client is not thread-safe, and it does neither provide connection pooling facility. You may choose to connect on every request, which is actually fast enough, or maintain a pool of connections yourself.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> thrift.transport <span class="keyword">import</span> TSocket</span><br><span class="line"><span class="keyword">from</span> thrift.protocol <span class="keyword">import</span> TBinaryProtocol</span><br><span class="line"><span class="keyword">from</span> thrift.transport <span class="keyword">import</span> TTransport</span><br><span class="line"><span class="keyword">from</span> hbase <span class="keyword">import</span> THBaseService</span><br><span class="line"></span><br><span class="line">transport = TTransport.TBufferedTransport(TSocket.TSocket(<span class="string">'127.0.0.1'</span>, <span class="number">9090</span>))</span><br><span class="line">protocol = TBinaryProtocol.TBinaryProtocolAccelerated(transport)</span><br><span class="line">client = THBaseService.Client(protocol)</span><br><span class="line">transport.open()</span><br><span class="line"><span class="comment"># perform some operations with "client"</span></span><br><span class="line">transport.close()</span><br></pre></td></tr></table></figure><p>We can test the connection with some basic operations:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hbase.ttypes <span class="keyword">import</span> TPut, TColumnValue, TGet</span><br><span class="line">tput = TPut(</span><br><span class="line">    row=<span class="string">'sys.cpu.user:20180421:192.168.1.1'</span>,</span><br><span class="line">    columnValues=[</span><br><span class="line">        TColumnValue(family=<span class="string">'cf'</span>, qualifier=<span class="string">'1015'</span>, value=<span class="string">'0.28'</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">client.put(<span class="string">'tsdata'</span>, tput)</span><br><span class="line"></span><br><span class="line">tget = TGet(row=<span class="string">'sys.cpu.user:20180421:192.168.1.1'</span>)</span><br><span class="line">tresult = client.get(<span class="string">'tsdata'</span>, tget)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tresult.columnValues:</span><br><span class="line">    print(col.qualifier, <span class="string">'='</span>, col.value)</span><br></pre></td></tr></table></figure><h2 id="Thrift2-Data-Types-and-Methods-Overview"><a href="#Thrift2-Data-Types-and-Methods-Overview" class="headerlink" title="Thrift2 Data Types and Methods Overview"></a>Thrift2 Data Types and Methods Overview</h2><p>For a full list of the available APIs, one can directly look into <code>hbase.thrift</code> or <code>hbase/THBaseService.py</code> files. Following is an abridged table of those data types and methods.</p><h3 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h3><table><thead><tr><th>Class</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>TColumn</td><td>Represents a column family or a single column.</td><td>TColumn(family=’cf’, qualifier=’gender’)</td></tr><tr><td>TColumnValue</td><td>Column and its value.</td><td>TColumnValue(family=’cf’, qualifier=’gender’, value=’male’)</td></tr><tr><td>TResult</td><td>Query result, a single row. <code>row</code> attribute would be <code>None</code> if no result is found.</td><td>TResult(row=’employee_001’, columnValues=[TColumnValue])</td></tr><tr><td>TGet</td><td>Query a single row.</td><td>TGet(row=’employee_001’, columns=[TColumn])</td></tr><tr><td>TPut</td><td>Mutate a single row.</td><td>TPut(row=’employee_001’, columnValues=[TColumnValue])</td></tr><tr><td>TDelete</td><td>Delete an entire row or only some columns.</td><td>TDelete(row=’employee_001’, columns=[TColumn])</td></tr><tr><td>TScan</td><td>Scan for multiple rows and columns.</td><td>See below.</td></tr></tbody></table><h3 id="THBaseService-Methods"><a href="#THBaseService-Methods" class="headerlink" title="THBaseService Methods"></a>THBaseService Methods</h3><table><thead><tr><th>Method Signature</th><th>Description</th></tr></thead><tbody><tr><td>get(table: str, tget: TGet) -&gt; TResult</td><td>Query a single row.</td></tr><tr><td>getMultiple(table: str, tgets: List[TGet]) -&gt; List[TResult]</td><td>Query multiple rows.</td></tr><tr><td>put(table: str, tput: TPut) -&gt; None</td><td>Mutate a row.</td></tr><tr><td>putMultiple(table: str, tputs: List[TPut]) -&gt; None</td><td>Mutate multiple rows.</td></tr><tr><td>deleteSingle(table: str, tdelete: TDelete) -&gt; None</td><td>Delete a row.</td></tr><tr><td>deleteMultiple(table: str, tdeletes: List[TDelete]) -&gt; None</td><td>Delete multiple rows.</td></tr><tr><td>openScanner(table: str, tscan: TScan) -&gt; int</td><td>Open a scanner, returns scannerId.</td></tr><tr><td>getScannerRows(scannerId: int, numRows: int) -&gt; List[TResult]</td><td>Get scanner rows.</td></tr><tr><td>closeScanner(scannerId: int) -&gt; None</td><td>Close a scanner.</td></tr><tr><td>getScannerResults(table: str, tscan: TScan, numRows: int) -&gt; List[TResult]</td><td>A convenient method to get scan results.</td></tr></tbody></table><h3 id="Scan-Operation-Example"><a href="#Scan-Operation-Example" class="headerlink" title="Scan Operation Example"></a>Scan Operation Example</h3><p>I wrote some example codes on GitHub (<a href="https://github.com/jizhang/python-hbase" target="_blank" rel="noopener">link</a>), and the following is how a <code>Scan</code> operation is made.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">scanner_id = client.openScanner(</span><br><span class="line">    table=<span class="string">'tsdata'</span>,</span><br><span class="line">    tscan=TScan(</span><br><span class="line">        startRow=<span class="string">'sys.cpu.user:20180421'</span>,</span><br><span class="line">        stopRow=<span class="string">'sys.cpu.user:20180422'</span>,</span><br><span class="line">        columns=[TColumn(<span class="string">'cf'</span>, <span class="string">'1015'</span>)]</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    num_rows = <span class="number">10</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        tresults = client.getScannerRows(scanner_id, num_rows)</span><br><span class="line">        <span class="keyword">for</span> tresult <span class="keyword">in</span> tresults:</span><br><span class="line">            print(tresult)</span><br><span class="line">        <span class="keyword">if</span> len(tresults) &lt; num_rows:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    client.closeScanner(scanner_id)</span><br></pre></td></tr></table></figure><h2 id="Thrift-Server-High-Availability"><a href="#Thrift-Server-High-Availability" class="headerlink" title="Thrift Server High Availability"></a>Thrift Server High Availability</h2><p>There are several solutions to eliminate the single point of failure of Thrift server. You can either (1) randomly select a server address on the client-side, and fall back to others if failure is detected, (2) setup a proxy facility to load balance the TCP connections, or (3) run individual Thrift server on every client machine, and let client code connects the local Thrift server. Usually we use the second approach, so you may consult your system administrator on that topic.</p><p><img src="/images/hbase-thrift-ha.png" alt=""></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/" target="_blank" rel="noopener">https://blog.cloudera.com/blog/2013/09/how-to-use-the-hbase-thrift-interface-part-1/</a></li><li><a href="https://thrift.apache.org/tutorial/py" target="_blank" rel="noopener">https://thrift.apache.org/tutorial/py</a></li><li><a href="https://yq.aliyun.com/articles/88299" target="_blank" rel="noopener">https://yq.aliyun.com/articles/88299</a></li><li><a href="http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html" target="_blank" rel="noopener">http://opentsdb.net/docs/build/html/user_guide/backends/hbase.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://hbase.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache HBase&lt;/a&gt; is a key-value store in Hadoop ecosystem. It is based on HDFS, and can provide high performance data access on large amount of volume. HBase is written in Java, and has native support for Java clients. But with the help of Thrift and various language bindings, we can access HBase in web services quite easily. This article will describe how to read and write HBase table with Python and Thrift.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/hbase.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Generate-Thrift-Class&quot;&gt;&lt;a href=&quot;#Generate-Thrift-Class&quot; class=&quot;headerlink&quot; title=&quot;Generate Thrift Class&quot;&gt;&lt;/a&gt;Generate Thrift Class&lt;/h2&gt;&lt;p&gt;For anyone who is new to &lt;a href=&quot;https://thrift.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Thrift&lt;/a&gt;, it provides an IDL (Interface Description Language) to let you describe your service methods and data types and then transform them into different languages. For instance, a Thrift type definition like this:&lt;/p&gt;
&lt;figure class=&quot;highlight thrift&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TColumn&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;required&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;binary&lt;/span&gt; family,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;optional&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;binary&lt;/span&gt; qualifier,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;: &lt;span class=&quot;keyword&quot;&gt;optional&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;i64&lt;/span&gt; timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Will be transformed into the following Python code:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TColumn&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(object)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, family=None, qualifier=None, timestamp=None,)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.family = family&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.qualifier = qualifier&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.timestamp = timestamp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, iprot)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        iprot.readStructBegin()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;True&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            (fname, ftype, fid) = iprot.readFieldBegin()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;comment&quot;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, oprot)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        oprot.writeStructBegin(&lt;span class=&quot;string&quot;&gt;&#39;TColumn&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;# ...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="hbase" scheme="http://shzhangji.com/tags/hbase/"/>
    
      <category term="thrift" scheme="http://shzhangji.com/tags/thrift/"/>
    
  </entry>
  
  <entry>
    <title>Form Handling in Vuex Strict Mode</title>
    <link href="http://shzhangji.com/blog/2018/04/17/form-handling-in-vuex-strict-mode/"/>
    <id>http://shzhangji.com/blog/2018/04/17/form-handling-in-vuex-strict-mode/</id>
    <published>2018-04-17T06:13:40.000Z</published>
    <updated>2018-04-18T00:30:52.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/vue.png" alt=""></p><p>When handling form inputs in Vue, we usually use <code>v-model</code> to achieve two-way binding. But if we want to put form data into Vuex store, two-way binding becomes a problem, since in <strong>strict mode</strong>, Vuex doesn’t allow state change outside mutation handlers. Take the following snippet for instance, while full code can be found on GitHub (<a href="https://github.com/jizhang/vuex-form" target="_blank" rel="noopener">link</a>).</p><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  state: &#123;</span><br><span class="line">    namespaced: <span class="literal">true</span>,</span><br><span class="line">    table: &#123;</span><br><span class="line">      table_name: <span class="string">''</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>src/components/NonStrict.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-group</span> <span class="attr">label</span>=<span class="string">"Table Name:"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"table.table_name"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">b-form-group</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">import</span> &#123; mapState &#125; <span class="keyword">from</span> <span class="string">'vuex'</span></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapState(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'table'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>When we input something in “Table Name” field, an error will be thrown in browser’s console:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Error: [vuex] Do not mutate vuex store state outside mutation handlers.</span><br><span class="line">    at assert (vuex.esm.js?358c:97)</span><br><span class="line">    at Vue.store._vm.$watch.deep (vuex.esm.js?358c:746)</span><br><span class="line">    at Watcher.run (vue.esm.js?efeb:3233)</span><br></pre></td></tr></table></figure><p>Apart from not using strict mode at all, which is fine if you’re ready to lose some benefits of tracking every mutation to the store, there’re several ways to solve this error. In this article, we’ll explore these solutions, and explain how they work.</p><a id="more"></a><h2 id="Local-Copy"><a href="#Local-Copy" class="headerlink" title="Local Copy"></a>Local Copy</h2><p>The first solution is to copy the form data from Vuex store to local state, do normal two-way binding, and commit to store when user submits the form.</p><p><code>src/components/LocalCopy.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"table.table_name"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">import</span> _ <span class="keyword">from</span> <span class="string">'lodash'</span></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  data () &#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="javascript">      table: _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="undefined">    handleSubmit (event) &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">this</span>.$store.commit(<span class="string">'table/setTable'</span>, <span class="keyword">this</span>.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  mutations: &#123;</span><br><span class="line">    setTable (state, payload) &#123;</span><br><span class="line">      state.table = payload</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There’re two caveats in this solution. One is when you try to update the form after committing to store, you’ll again get “Error: [vuex] Do not mutate vuex store state outside mutation handlers.” It’s because the component’s local copy is assigned into Vuex store. We can modify the <code>setTable</code> mutation to solve it.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">setTable (state, payload) &#123;</span><br><span class="line">  <span class="comment">// assign properties individually</span></span><br><span class="line">  _.assign(state.table, payload)</span><br><span class="line">  <span class="comment">// or, clone the payload</span></span><br><span class="line">  state.table = _.cloneDeep(payload)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Another problem is when other components commit changes to Vuex store’s <code>table</code>, e.g. in a dialog with sub-forms, current component will not be updated. In this case, we’ll need to set a watched property.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  data () &#123;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">return</span> &#123;</span></span><br><span class="line"><span class="javascript">      table: _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="undefined">    storeTable () &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">return</span> _.cloneDeep(<span class="keyword">this</span>.$store.state.table.table)</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  watch: &#123;</span></span><br><span class="line"><span class="undefined">    storeTable (newValue) &#123;</span></span><br><span class="line"><span class="javascript">      <span class="keyword">this</span>.table = newValue</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>This approach can also bypass the first caveat, because following updates in component’s form will not affect the object inside Vuex store.</p><h2 id="Explicit-Update"><a href="#Explicit-Update" class="headerlink" title="Explicit Update"></a>Explicit Update</h2><p>A ReactJS-like approach is to commit data on input / change event, i.e. use one-way data binding instead of two-way, and let Vuex store become the single source of truth of your application.</p><p><code>src/components/ExplicitUpdate.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">:value</span>=<span class="string">"table.table_name"</span> @<span class="attr">input</span>=<span class="string">"updateTableForm(&#123; table_name: $event &#125;)"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapState(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'table'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapMutations(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'updateTableForm'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>src/store/table.js</code></p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> table &#123;</span><br><span class="line">  mutations: &#123;</span><br><span class="line">    updateTableForm (state, payload) &#123;</span><br><span class="line">      _.assign(state.table, payload)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This is also the recommended way of form handling in Vuex <a href="https://vuex.vuejs.org/en/forms.html" target="_blank" rel="noopener">doc</a>, and according to Vue’s <a href="https://vuejs.org/v2/guide/forms.html" target="_blank" rel="noopener">doc</a>, <code>v-model</code> is essentially a syntax sugar for updating data on user input events.</p><h2 id="Computed-Property"><a href="#Computed-Property" class="headerlink" title="Computed Property"></a>Computed Property</h2><p>Vue’s computed property supports getter and setter, we can use it as a bridge between Vuex store and component. One limitation is computed property doesn’t support nested property, so we need to make aliases for nested states.</p><p><code>src/components/ComputedProperty.vue</code></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">b-form-input</span> <span class="attr">v-model</span>=<span class="string">"tableName"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">b-form-select</span> <span class="attr">v-model</span>=<span class="string">"tableCategory"</span> /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span></span><br><span class="line"><span class="undefined">  computed: &#123;</span></span><br><span class="line"><span class="undefined">    tableName: &#123;</span></span><br><span class="line"><span class="undefined">      get () &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">return</span> <span class="keyword">this</span>.$store.state.table.table.table_name</span></span><br><span class="line"><span class="undefined">      &#125;,</span></span><br><span class="line"><span class="undefined">      set (value) &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">this</span>.updateTableForm(&#123; <span class="attr">table_name</span>: value &#125;)</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    tableCategory: &#123;</span></span><br><span class="line"><span class="undefined">      get () &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">return</span> <span class="keyword">this</span>.$store.state.table.table.category</span></span><br><span class="line"><span class="undefined">      &#125;,</span></span><br><span class="line"><span class="undefined">      set (value) &#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">this</span>.updateTableForm(&#123; <span class="attr">category</span>: value &#125;)</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;,</span></span><br><span class="line"><span class="undefined">  &#125;,</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">  methods: &#123;</span></span><br><span class="line"><span class="javascript">    ...mapMutations(<span class="string">'table'</span>, [</span></span><br><span class="line"><span class="javascript">      <span class="string">'updateTableForm'</span></span></span><br><span class="line"><span class="undefined">    ])</span></span><br><span class="line"><span class="undefined">  &#125;</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><p>When there’re a lot of fields, it becomes quite verbose to list them all. We may create some utilities for this purpose. First, in Vuex store, we add a common mutation that can set arbitrary state indicated by a lodash-style path.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mutations: &#123;</span><br><span class="line">  myUpdateField (state, payload) &#123;</span><br><span class="line">    <span class="keyword">const</span> &#123; path, value &#125; = payload</span><br><span class="line">    _.set(state, path, value)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then in component, we write a function that takes alias / path pairs, and creates getter / setter for them.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> mapFields = <span class="function">(<span class="params">namespace, fields</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> _.mapValues(fields, path =&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">      get () &#123;</span><br><span class="line">        <span class="keyword">return</span> _.get(<span class="keyword">this</span>.$store.state[namespace], path)</span><br><span class="line">      &#125;,</span><br><span class="line">      set (value) &#123;</span><br><span class="line">        <span class="keyword">this</span>.$store.commit(<span class="string">`<span class="subst">$&#123;namespace&#125;</span>/myUpdateField`</span>, &#123; path, value &#125;)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">  computed: &#123;</span><br><span class="line">    ...mapFields(<span class="string">'table'</span>, &#123;</span><br><span class="line">      tableName: <span class="string">'table.table_name'</span>,</span><br><span class="line">      tableCategory: <span class="string">'table.category'</span>,</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In fact, someone’s already created a project named <a href="https://github.com/maoberlehner/vuex-map-fields" target="_blank" rel="noopener">vuex-map-fields</a>, whose <code>mapFields</code> utility does exactly the same thing.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://vuex.vuejs.org/en/forms.html" target="_blank" rel="noopener">https://vuex.vuejs.org/en/forms.html</a></li><li><a href="https://ypereirareis.github.io/blog/2017/04/25/vuejs-two-way-data-binding-state-management-vuex-strict-mode/" target="_blank" rel="noopener">https://ypereirareis.github.io/blog/2017/04/25/vuejs-two-way-data-binding-state-management-vuex-strict-mode/</a></li><li><a href="https://markus.oberlehner.net/blog/form-fields-two-way-data-binding-and-vuex/" target="_blank" rel="noopener">https://markus.oberlehner.net/blog/form-fields-two-way-data-binding-and-vuex/</a></li><li><a href="https://forum.vuejs.org/t/vuex-form-best-practices/20084" target="_blank" rel="noopener">https://forum.vuejs.org/t/vuex-form-best-practices/20084</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/vue.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;When handling form inputs in Vue, we usually use &lt;code&gt;v-model&lt;/code&gt; to achieve two-way binding. But if we want to put form data into Vuex store, two-way binding becomes a problem, since in &lt;strong&gt;strict mode&lt;/strong&gt;, Vuex doesn’t allow state change outside mutation handlers. Take the following snippet for instance, while full code can be found on GitHub (&lt;a href=&quot;https://github.com/jizhang/vuex-form&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;src/store/table.js&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  state: &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    namespaced: &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    table: &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      table_name: &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;src/components/NonStrict.vue&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight html&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;b-form-group&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;label&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;Table Name:&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;b-form-input&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;v-model&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&quot;table.table_name&quot;&lt;/span&gt; /&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;b-form-group&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;script&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; &amp;#123; mapState &amp;#125; &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;vuex&#39;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;  computed: &amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;    ...mapState(&lt;span class=&quot;string&quot;&gt;&#39;table&#39;&lt;/span&gt;, [&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;javascript&quot;&gt;      &lt;span class=&quot;string&quot;&gt;&#39;table&#39;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;    ])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;undefined&quot;&gt;&lt;/span&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;script&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;When we input something in “Table Name” field, an error will be thrown in browser’s console:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Error: [vuex] Do not mutate vuex store state outside mutation handlers.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at assert (vuex.esm.js?358c:97)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at Vue.store._vm.$watch.deep (vuex.esm.js?358c:746)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    at Watcher.run (vue.esm.js?efeb:3233)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Apart from not using strict mode at all, which is fine if you’re ready to lose some benefits of tracking every mutation to the store, there’re several ways to solve this error. In this article, we’ll explore these solutions, and explain how they work.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="javascript" scheme="http://shzhangji.com/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/tags/frontend/"/>
    
      <category term="vue" scheme="http://shzhangji.com/tags/vue/"/>
    
      <category term="vuex" scheme="http://shzhangji.com/tags/vuex/"/>
    
  </entry>
  
  <entry>
    <title>Error Handling in RESTful API</title>
    <link href="http://shzhangji.com/blog/2018/04/07/error-handling-in-restful-api/"/>
    <id>http://shzhangji.com/blog/2018/04/07/error-handling-in-restful-api/</id>
    <published>2018-04-07T06:49:19.000Z</published>
    <updated>2018-05-15T01:01:44.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/restful-api.png" alt="RESTful API"></p><p>RESTful API is a common tool of building web services, especially in front and back-end separated application. It is based on HTTP protocol, which is simple, text-oriented, and well supported by various languages, browsers or clients. However, REST is not yet standardized, so that the developers need to decide how to design their APIs. One of the decisions is error handling. Should I use HTTP status code? How to handle form validation errors, etc. This article will propose an error handling mechanism for RESTful API, based on my daily work and understanding of this technique.</p><h2 id="Types-of-Errors"><a href="#Types-of-Errors" class="headerlink" title="Types of Errors"></a>Types of Errors</h2><p>I tend to categorize errors into two types, global and local. Global errors include requesting an unknown API url, not being authorized to access this API, or there’s something wrong with the server code, unexpected and fatal. These errors should be caught by the web framework, no customized handling in individual API function.</p><p>Local errors, on the other hand, are closely related to the current API. Examples are form validation, violation of unique constraint, or other expected errors. We need to write specific codes to catch these errors, and raise a global error with message and payload for framework to catch and respond with.</p><p>Flask, for instance, provides a mechanism to catch exceptions globally:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BadRequest</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""Custom exception class to be thrown when local error occurs."""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, message, status=<span class="number">400</span>, payload=None)</span>:</span></span><br><span class="line">        self.message = message</span><br><span class="line">        self.status = status</span><br><span class="line">        self.payload = payload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.errorhandler(BadRequest)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_bad_request</span><span class="params">(error)</span>:</span></span><br><span class="line">    <span class="string">"""Catch BadRequest exception globally, serialize into JSON, and respond with 400."""</span></span><br><span class="line">    payload = dict(error.payload <span class="keyword">or</span> ())</span><br><span class="line">    payload[<span class="string">'status'</span>] = error.status</span><br><span class="line">    payload[<span class="string">'message'</span>] = error.message</span><br><span class="line">    <span class="keyword">return</span> jsonify(payload), <span class="number">400</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route('/person', methods=['POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">person_post</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""Create a new person object and return its ID"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> request.form.get(<span class="string">'username'</span>):</span><br><span class="line">        <span class="keyword">raise</span> BadRequest(<span class="string">'username cannot be empty'</span>, <span class="number">40001</span>, &#123; <span class="string">'ext'</span>: <span class="number">1</span> &#125;)</span><br><span class="line">    <span class="keyword">return</span> jsonify(last_insert_id=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Error-Response-Payload"><a href="#Error-Response-Payload" class="headerlink" title="Error Response Payload"></a>Error Response Payload</h2><p>When you post to <code>/person</code> with an empty <code>username</code>, it’ll return the following error response:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 400 Bad Request</span><br><span class="line">Content-Type: application/json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;status&quot;: 40001,</span><br><span class="line">  &quot;message&quot;: &quot;username cannot be empty&quot;,</span><br><span class="line">  &quot;ext&quot;: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There’re several parts in this response: HTTP status code, a custom status code, error message, and some extra information.</p><h3 id="Use-HTTP-Status-Code"><a href="#Use-HTTP-Status-Code" class="headerlink" title="Use HTTP Status Code"></a>Use HTTP Status Code</h3><p>HTTP status code itself provides rich semantics for errors. Generally <code>4xx</code> for client-side error and <code>5xx</code> server-side. Here’s a brief list of commonly used codes:</p><ul><li><code>200</code> Response is OK.</li><li><code>400</code> Bad request, e.g. user posts some in valid data.</li><li><code>401</code> Unauthorized. With <code>Flask-Login</code>, you can decorate a route with <code>@login_required</code>, and if the user hasn’t logged in, <code>401</code> will be returned, and client-side can redirect to login page.</li><li><code>403</code> Access is forbidden.</li><li><code>404</code> Resource not found.</li><li><code>500</code> Internal server error. Usually for unexpected and irrecoverable exceptions on the server-side.</li></ul><h3 id="Custom-Error-Code"><a href="#Custom-Error-Code" class="headerlink" title="Custom Error Code"></a>Custom Error Code</h3><p>When client receives an error, we can either open a global modal dialog to show the message, or handle the errors locally, such as displaying error messages below each form control. For this to work, we need to give these local errors a special coding convention, say <code>400</code> for global error, while <code>40001</code> and <code>40002</code> will trigger different error handlers.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fetch().then(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (response.status == <span class="number">400</span>) &#123; <span class="comment">// http status code</span></span><br><span class="line">    response.json().then(<span class="function"><span class="params">responseJson</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (responseJson.status == <span class="number">400</span>) &#123; <span class="comment">// custom error code</span></span><br><span class="line">        <span class="comment">// global error handler</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (responseJson.status == <span class="number">40001</span>) &#123; <span class="comment">// custom error code</span></span><br><span class="line">        <span class="comment">// custom error handler</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h3 id="More-Error-Information"><a href="#More-Error-Information" class="headerlink" title="More Error Information"></a>More Error Information</h3><p>Sometimes it is ideal to return all validation errors in one response, and we can use <code>payload</code> to achieve that.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"status"</span>: <span class="number">40001</span>,</span><br><span class="line">  <span class="string">"message"</span>: <span class="string">"form validation failed"</span></span><br><span class="line">  <span class="string">"errors"</span>: [</span><br><span class="line">    &#123; <span class="string">"name"</span>: <span class="string">"username"</span>, <span class="string">"error"</span>: <span class="string">"username cannot be empty"</span> &#125;,</span><br><span class="line">    &#123; <span class="string">"name"</span>: <span class="string">"password"</span>, <span class="string">"error"</span>: <span class="string">"password minimum length is 6"</span> &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Fetch-API"><a href="#Fetch-API" class="headerlink" title="Fetch API"></a>Fetch API</h2><p>For AJAX request, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API" target="_blank" rel="noopener">Fetch API</a> becomes the standard library. We can wrap it into a function that does proper error handling. Full code can be found in GitHub (<a href="https://github.com/jizhang/rest-error/blob/master/src/request.js" target="_blank" rel="noopener">link</a>).</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">request</span>(<span class="params">url, args, form</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> fetch(url, config)</span><br><span class="line">    .then(<span class="function"><span class="params">response</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (response.ok) &#123;</span><br><span class="line">        <span class="keyword">return</span> response.json()</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (response.status === <span class="number">400</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> response.json()</span><br><span class="line">          .then(<span class="function"><span class="params">responseJson</span> =&gt;</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (responseJson.status === <span class="number">400</span>) &#123;</span><br><span class="line">              alert(responseJson.message) <span class="comment">// global error handler</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// let subsequent "catch()" in the Promise chain handle the error</span></span><br><span class="line">            <span class="keyword">throw</span> responseJson</span><br><span class="line">          &#125;, error =&gt; &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(<span class="number">400</span>)</span><br><span class="line">          &#125;)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// handle predefined HTTP status code respectively</span></span><br><span class="line">      <span class="keyword">switch</span> (response.status) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">401</span>:</span><br><span class="line">          <span class="keyword">break</span> <span class="comment">// redirect to login page</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">          alert(<span class="string">'HTTP Status Code '</span> + response.status)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(response.status)</span><br><span class="line">    &#125;, error =&gt; &#123;</span><br><span class="line">      alert(error.message)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RequestError(<span class="number">0</span>, error.message)</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This method will reject the promise whenever an error happens. Invokers can catch the error and check its <code>status</code>. Here’s an example of combining this approach with MobX and ReactJS:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MobX Store</span></span><br><span class="line">loginUser = flow(<span class="function"><span class="keyword">function</span>* <span class="title">loginUser</span>(<span class="params">form</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.loading = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// yield may throw an error, i.e. reject this Promise</span></span><br><span class="line">    <span class="keyword">this</span>.userId = <span class="keyword">yield</span> request(<span class="string">'/login'</span>, <span class="literal">null</span>, form)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.loading = <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// React Component</span></span><br><span class="line">login = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  userStore.loginUser(<span class="keyword">this</span>.state.form)</span><br><span class="line">    .catch(<span class="function"><span class="params">error</span> =&gt;</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (error.status === <span class="number">40001</span>) &#123;</span><br><span class="line">        <span class="comment">// custom error handler</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Representational_state_transfer</a></li><li><a href="https://alidg.me/blog/2016/9/24/rest-api-error-handling" target="_blank" rel="noopener">https://alidg.me/blog/2016/9/24/rest-api-error-handling</a></li><li><a href="https://www.wptutor.io/web/js/generators-coroutines-async-javascript" target="_blank" rel="noopener">https://www.wptutor.io/web/js/generators-coroutines-async-javascript</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/restful-api.png&quot; alt=&quot;RESTful API&quot;&gt;&lt;/p&gt;
&lt;p&gt;RESTful API is a common tool of building web services, especially in front and back-end separated application. It is based on HTTP protocol, which is simple, text-oriented, and well supported by various languages, browsers or clients. However, REST is not yet standardized, so that the developers need to decide how to design their APIs. One of the decisions is error handling. Should I use HTTP status code? How to handle form validation errors, etc. This article will propose an error handling mechanism for RESTful API, based on my daily work and understanding of this technique.&lt;/p&gt;
&lt;h2 id=&quot;Types-of-Errors&quot;&gt;&lt;a href=&quot;#Types-of-Errors&quot; class=&quot;headerlink&quot; title=&quot;Types of Errors&quot;&gt;&lt;/a&gt;Types of Errors&lt;/h2&gt;&lt;p&gt;I tend to categorize errors into two types, global and local. Global errors include requesting an unknown API url, not being authorized to access this API, or there’s something wrong with the server code, unexpected and fatal. These errors should be caught by the web framework, no customized handling in individual API function.&lt;/p&gt;
&lt;p&gt;Local errors, on the other hand, are closely related to the current API. Examples are form validation, violation of unique constraint, or other expected errors. We need to write specific codes to catch these errors, and raise a global error with message and payload for framework to catch and respond with.&lt;/p&gt;
&lt;p&gt;Flask, for instance, provides a mechanism to catch exceptions globally:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;BadRequest&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Exception)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;Custom exception class to be thrown when local error occurs.&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, message, status=&lt;span class=&quot;number&quot;&gt;400&lt;/span&gt;, payload=None)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.message = message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.status = status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.payload = payload&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@app.errorhandler(BadRequest)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;handle_bad_request&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(error)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;Catch BadRequest exception globally, serialize into JSON, and respond with 400.&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload = dict(error.payload &lt;span class=&quot;keyword&quot;&gt;or&lt;/span&gt; ())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload[&lt;span class=&quot;string&quot;&gt;&#39;status&#39;&lt;/span&gt;] = error.status&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    payload[&lt;span class=&quot;string&quot;&gt;&#39;message&#39;&lt;/span&gt;] = error.message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; jsonify(payload), &lt;span class=&quot;number&quot;&gt;400&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@app.route(&#39;/person&#39;, methods=[&#39;POST&#39;])&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;person_post&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;Create a new person object and return its ID&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; request.form.get(&lt;span class=&quot;string&quot;&gt;&#39;username&#39;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;raise&lt;/span&gt; BadRequest(&lt;span class=&quot;string&quot;&gt;&#39;username cannot be empty&#39;&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;40001&lt;/span&gt;, &amp;#123; &lt;span class=&quot;string&quot;&gt;&#39;ext&#39;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; jsonify(last_insert_id=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="restful" scheme="http://shzhangji.com/tags/restful/"/>
    
      <category term="javascript" scheme="http://shzhangji.com/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/tags/frontend/"/>
    
  </entry>
  
  <entry>
    <title>Flume Source Code: Component Lifecycle</title>
    <link href="http://shzhangji.com/blog/2017/10/23/flume-source-code-component-lifecycle/"/>
    <id>http://shzhangji.com/blog/2017/10/23/flume-source-code-component-lifecycle/</id>
    <published>2017-10-23T04:57:32.000Z</published>
    <updated>2017-10-24T01:24:34.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://flume.apache.org/" target="_blank" rel="noopener">Apache Flume</a> is a real-time ETL tool for data warehouse platform. It consists of different types of components, and during runtime all of them are managed by Flume’s lifecycle and supervisor mechanism. This article will walk you through the source code of Flume’s component lifecycle management.</p><h2 id="Repository-Structure"><a href="#Repository-Structure" class="headerlink" title="Repository Structure"></a>Repository Structure</h2><p>Flume’s source code can be downloaded from GitHub. It’s a Maven project, so we can import it into an IDE for efficient code reading. The following is the main structure of the project:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/flume-ng-node</span><br><span class="line">/flume-ng-code</span><br><span class="line">/flume-ng-sdk</span><br><span class="line">/flume-ng-sources/flume-kafka-source</span><br><span class="line">/flume-ng-channels/flume-kafka-channel</span><br><span class="line">/flume-ng-sinks/flume-hdfs-sink</span><br></pre></td></tr></table></figure><h2 id="Application-Entrance"><a href="#Application-Entrance" class="headerlink" title="Application Entrance"></a>Application Entrance</h2><p>The <code>main</code> entrance of Flume agent is in the <code>org.apache.flume.node.Application</code> class of <code>flume-ng-node</code> module. Following is an abridged source code:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    CommandLineParser parser = <span class="keyword">new</span> GnuParser();</span><br><span class="line">    <span class="keyword">if</span> (isZkConfigured) &#123;</span><br><span class="line">      <span class="keyword">if</span> (reload) &#123;</span><br><span class="line">        PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        components.add(zookeeperConfigurationProvider);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider;</span><br><span class="line">        application.handleConfigurationEvent();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// PropertiesFileConfigurationProvider</span></span><br><span class="line">    &#125;</span><br><span class="line">    application.start();</span><br><span class="line">    Runtime.getRuntime().addShutdownHook(<span class="keyword">new</span> Thread(<span class="string">"agent-shutdown-hook"</span>) &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        appReference.stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The process can be illustrated as follows:</p><ol><li>Parse command line arguments with <code>commons-cli</code>, including the Flume agent’s name, configuration method and path.</li><li>Configurations can be provided via properties file or ZooKeeper. Both provider support live-reload, i.e. we can update component settings without restarting the agent.<ul><li>File-based live-reload is implemented by using a background thread that checks the last modification time of the file.</li><li>ZooKeeper-based live-reload is provided by Curator’s <code>NodeCache</code> recipe, which uses ZooKeeper’s <em>watch</em> functionality underneath.</li></ul></li><li>If live-reload is on (by default), configuration providers will add themselves into the application’s component list, and after calling <code>Application#start</code>, a <code>LifecycleSupervisor</code> will start the provider, and trigger the reload event to parse the configuration and load all defined components.</li><li>If live-reload is off, configuration providers will parse the file immediately and start all components, also supervised by <code>LifecycleSupervisor</code>.</li><li>Finally add a JVM shutdown hook by <code>Runtime#addShutdownHook</code>, which in turn invokes <code>Application#stop</code> to shutdown the Flume agent.</li></ol><a id="more"></a><h2 id="Configuration-Reload"><a href="#Configuration-Reload" class="headerlink" title="Configuration Reload"></a>Configuration Reload</h2><p>In <code>PollingPropertiesFileConfigurationProvider</code>, when it detects file changes, it will invoke the <code>AbstractConfigurationProvider#getConfiguration</code> method to parse the configuration file into an <code>MaterializedConfiguration</code> instance, which contains the source, sink, and channel definitions. And then, the polling thread send an event to <code>Application</code> via a Guava’s <code>EventBus</code> instance, which effectively invokes the <code>Application#handleConfigurationEvent</code> method to reload all components.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Application class</span></span><br><span class="line"><span class="meta">@Subscribe</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">handleConfigurationEvent</span><span class="params">(MaterializedConfiguration conf)</span> </span>&#123;</span><br><span class="line">  stopAllComponents();</span><br><span class="line">  startAllComponents(conf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// PollingPropertiesFileConfigurationProvider$FileWatcherRunnable</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  eventBus.post(getConfiguration());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Start-Components"><a href="#Start-Components" class="headerlink" title="Start Components"></a>Start Components</h2><p>The starting process lies in <code>Application#startAllComponents</code>. The method accepts a new set of components, starts the <code>Channel</code>s first, followed by <code>Sink</code>s and <code>Source</code>s.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startAllComponents</span><span class="params">(MaterializedConfiguration materializedConfiguration)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.materializedConfiguration = materializedConfiguration;</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;String, Channel&gt; entry :</span><br><span class="line">      materializedConfiguration.getChannels().entrySet()) &#123;</span><br><span class="line">    supervisor.supervise(entry.getValue(),</span><br><span class="line">        <span class="keyword">new</span> SupervisorPolicy.AlwaysRestartPolicy(), LifecycleState.START);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//  Wait for all channels to start.</span></span><br><span class="line">  <span class="keyword">for</span> (Channel ch : materializedConfiguration.getChannels().values()) &#123;</span><br><span class="line">    <span class="keyword">while</span> (ch.getLifecycleState() != LifecycleState.START</span><br><span class="line">        &amp;&amp; !supervisor.isComponentInErrorState(ch)) &#123;</span><br><span class="line">      Thread.sleep(<span class="number">500</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Start and supervise sinkds and sources</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The <code>LifecycleSupervisor</code> manages instances that implement <code>LifecycleAware</code> interface. Supervisor will schedule a <code>MonitorRunnable</code> instance with a fixed delay (3 secs), which tries to convert a <code>LifecycleAware</code> instance into its <code>desiredState</code>, by calling <code>LifecycleAware#start</code> or <code>stop</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MonitorRunnable</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!lifecycleAware.getLifecycleState().equals(</span><br><span class="line">        supervisoree.status.desiredState)) &#123;</span><br><span class="line">      <span class="keyword">switch</span> (supervisoree.status.desiredState) &#123;</span><br><span class="line">        <span class="keyword">case</span> START:</span><br><span class="line">          lifecycleAware.start();</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> STOP:</span><br><span class="line">          lifecycleAware.stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Stop-Components"><a href="#Stop-Components" class="headerlink" title="Stop Components"></a>Stop Components</h2><p>When JVM is shutting down, the hook invokes <code>Application#stop</code>, which calls <code>LifecycleSupervisor#stop</code>, that first shutdowns the <code>MonitorRunnable</code>s’ executor pool, and changes all components’ desired status to <code>STOP</code>, waiting for them to fully shutdown.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LifecycleSupervisor</span> <span class="keyword">implements</span> <span class="title">LifecycleAware</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    monitorService.shutdown();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">final</span> Entry&lt;LifecycleAware, Supervisoree&gt; entry :</span><br><span class="line">        supervisedProcesses.entrySet()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (entry.getKey().getLifecycleState().equals(LifecycleState.START)) &#123;</span><br><span class="line">        entry.getValue().status.desiredState = LifecycleState.STOP;</span><br><span class="line">        entry.getKey().stop();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Source-and-Source-Runner"><a href="#Source-and-Source-Runner" class="headerlink" title="Source and Source Runner"></a>Source and Source Runner</h2><p>Take <code>KafkaSource</code> for an instance, we shall see how agent supervises source components, and the same thing happens to sinks and channels.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaSource</span> <span class="keyword">extends</span> <span class="title">AbstractPollableSource</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStart</span><span class="params">()</span> <span class="keyword">throws</span> FlumeException </span>&#123;</span><br><span class="line">    consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, <span class="keyword">byte</span>[]&gt;(kafkaProps);</span><br><span class="line">    it = consumer.poll(<span class="number">1000</span>).iterator();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doStop</span><span class="params">()</span> <span class="keyword">throws</span> FlumeException </span>&#123;</span><br><span class="line">    consumer.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>KafkaSource</code> is a pollable source, which means it needs a runner thread to constantly poll for more data to process.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PollableSourceRunner</span> <span class="keyword">extends</span> <span class="title">SourceRunner</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    source.start();</span><br><span class="line">    runner = <span class="keyword">new</span> PollingRunner();</span><br><span class="line">    runnerThread = <span class="keyword">new</span> Thread(runner);</span><br><span class="line">    runnerThread.start();</span><br><span class="line">    lifecycleState = LifecycleState.START;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    runnerThread.interrupt();</span><br><span class="line">    runnerThread.join();</span><br><span class="line">    source.stop();</span><br><span class="line">    lifecycleState = LifecycleState.STOP;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">PollingRunner</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">while</span> (!shouldStop.get()) &#123;</span><br><span class="line">        source.process();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Both <code>AbstractPollableSource</code> and <code>SourceRunner</code> are subclass of <code>LifecycleAware</code>, which means they have <code>start</code> and <code>stop</code> methods for supervisor to call. In this case, <code>SourceRunner</code> is the component that Flume agent actually supervises, and <code>PollableSource</code> is instantiated and managed by <code>SourceRunner</code>. Details lie in <code>AbstractConfigurationProvider#loadSources</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loadSources</span><span class="params">(Map&lt;String, SourceRunner&gt; sourceRunnerMap)</span> </span>&#123;</span><br><span class="line">  Source source = sourceFactory.create();</span><br><span class="line">  Configurables.configure(source, config);</span><br><span class="line">  sourceRunnerMap.put(comp.getComponentName(),</span><br><span class="line">      SourceRunner.forSource(source));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">https://github.com/apache/flume</a></li><li><a href="https://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">https://flume.apache.org/FlumeUserGuide.html</a></li><li><a href="https://kafka.apache.org/0100/javadoc/index.html" target="_blank" rel="noopener">https://kafka.apache.org/0100/javadoc/index.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://flume.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Flume&lt;/a&gt; is a real-time ETL tool for data warehouse platform. It consists of different types of components, and during runtime all of them are managed by Flume’s lifecycle and supervisor mechanism. This article will walk you through the source code of Flume’s component lifecycle management.&lt;/p&gt;
&lt;h2 id=&quot;Repository-Structure&quot;&gt;&lt;a href=&quot;#Repository-Structure&quot; class=&quot;headerlink&quot; title=&quot;Repository Structure&quot;&gt;&lt;/a&gt;Repository Structure&lt;/h2&gt;&lt;p&gt;Flume’s source code can be downloaded from GitHub. It’s a Maven project, so we can import it into an IDE for efficient code reading. The following is the main structure of the project:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-node&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-code&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sdk&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sources/flume-kafka-source&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-channels/flume-kafka-channel&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/flume-ng-sinks/flume-hdfs-sink&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;Application-Entrance&quot;&gt;&lt;a href=&quot;#Application-Entrance&quot; class=&quot;headerlink&quot; title=&quot;Application Entrance&quot;&gt;&lt;/a&gt;Application Entrance&lt;/h2&gt;&lt;p&gt;The &lt;code&gt;main&lt;/code&gt; entrance of Flume agent is in the &lt;code&gt;org.apache.flume.node.Application&lt;/code&gt; class of &lt;code&gt;flume-ng-node&lt;/code&gt; module. Following is an abridged source code:&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Application&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    CommandLineParser parser = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; GnuParser();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (isZkConfigured) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (reload) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        PollingZooKeeperConfigurationProvider zookeeperConfigurationProvider;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        components.add(zookeeperConfigurationProvider);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125; &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        StaticZooKeeperConfigurationProvider zookeeperConfigurationProvider;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        application.handleConfigurationEvent();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125; &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;comment&quot;&gt;// PropertiesFileConfigurationProvider&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    application.start();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    Runtime.getRuntime().addShutdownHook(&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Thread(&lt;span class=&quot;string&quot;&gt;&quot;agent-shutdown-hook&quot;&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;meta&quot;&gt;@Override&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        appReference.stop();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;#125;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;The process can be illustrated as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Parse command line arguments with &lt;code&gt;commons-cli&lt;/code&gt;, including the Flume agent’s name, configuration method and path.&lt;/li&gt;
&lt;li&gt;Configurations can be provided via properties file or ZooKeeper. Both provider support live-reload, i.e. we can update component settings without restarting the agent.&lt;ul&gt;
&lt;li&gt;File-based live-reload is implemented by using a background thread that checks the last modification time of the file.&lt;/li&gt;
&lt;li&gt;ZooKeeper-based live-reload is provided by Curator’s &lt;code&gt;NodeCache&lt;/code&gt; recipe, which uses ZooKeeper’s &lt;em&gt;watch&lt;/em&gt; functionality underneath.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If live-reload is on (by default), configuration providers will add themselves into the application’s component list, and after calling &lt;code&gt;Application#start&lt;/code&gt;, a &lt;code&gt;LifecycleSupervisor&lt;/code&gt; will start the provider, and trigger the reload event to parse the configuration and load all defined components.&lt;/li&gt;
&lt;li&gt;If live-reload is off, configuration providers will parse the file immediately and start all components, also supervised by &lt;code&gt;LifecycleSupervisor&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Finally add a JVM shutdown hook by &lt;code&gt;Runtime#addShutdownHook&lt;/code&gt;, which in turn invokes &lt;code&gt;Application#stop&lt;/code&gt; to shutdown the Flume agent.&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/tags/java/"/>
    
      <category term="flume" scheme="http://shzhangji.com/tags/flume/"/>
    
      <category term="source code" scheme="http://shzhangji.com/tags/source-code/"/>
    
  </entry>
  
  <entry>
    <title>Pandas and Tidy Data</title>
    <link href="http://shzhangji.com/blog/2017/09/30/pandas-and-tidy-data/"/>
    <id>http://shzhangji.com/blog/2017/09/30/pandas-and-tidy-data/</id>
    <published>2017-09-30T04:24:32.000Z</published>
    <updated>2017-09-30T04:29:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>In the paper <a href="https://www.jstatsoft.org/article/view/v059i10" target="_blank" rel="noopener">Tidy Data</a>, <a href="https://en.wikipedia.org/wiki/Hadley_Wickham" target="_blank" rel="noopener">Dr. Wickham</a> proposed a specific form of data structure: each variable is a column, each observation is a row, and each type of observational unit is a table. He argued that with tidy data, data analysts can manipulate, model, and visualize data more easily and effectively. He lists <em>five common data structures</em> that are untidy, and demonstrates how to use <a href="https://github.com/hadley/tidy-data/" target="_blank" rel="noopener">R language</a> to tidy them. In this article, we’ll use Python and Pandas to achieve the same tidiness.</p><p>Source code and demo data can be found on GitHub (<a href="https://github.com/jizhang/pandas-tidy-data" target="_blank" rel="noopener">link</a>), and readers are supposed to have Python environment installed, preferably with Anaconda and Spyder IDE.</p><h2 id="Column-headers-are-values-not-variable-names"><a href="#Column-headers-are-values-not-variable-names" class="headerlink" title="Column headers are values, not variable names"></a>Column headers are values, not variable names</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">'data/pew.csv'</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/pew.png" alt="Religion and Income - Pew Forum"></p><p>Column names “&lt;$10k”, “$10-20k” are really income ranges that constitutes a variable. Variables are measurements of attributes, like height, weight, and in this case, income and religion. The values within the table form another variable, frequency. To make <em>each variable a column</em>, we do the following transformation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = df.set_index(<span class="string">'religion'</span>)</span><br><span class="line">df = df.stack()</span><br><span class="line">df.index = df.index.rename(<span class="string">'income'</span>, level=<span class="number">1</span>)</span><br><span class="line">df.name = <span class="string">'frequency'</span></span><br><span class="line">df = df.reset_index()</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/pew-tidy.png" alt="Religion and Income - Tidy"></p><a id="more"></a><p>Here we use the <a href="https://pandas.pydata.org/pandas-docs/stable/reshaping.html" target="_blank" rel="noopener">stack / unstack</a> feature of Pandas MultiIndex objects. <code>stack()</code> will use the column names to form a second level of index, then we do some proper naming and use <code>reset_index()</code> to flatten the table. In line 4 <code>df</code> is actually a Series, since Pandas will automatically convert from a single-column DataFrame.</p><p>Pandas provides another more commonly used method to do the transformation, <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html" target="_blank" rel="noopener"><code>melt()</code></a>. It accepts the following arguments:</p><ul><li><code>frame</code>: the DataFrame to manipulate.</li><li><code>id_vars</code>: columns that stay put.</li><li><code>value_vars</code>: columns that will be transformed to a variable.</li><li><code>var_name</code>: name the newly added variable column.</li><li><code>value_name</code>: name the value column.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/pew.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'religion'</span>], value_vars=list(df.columns)[<span class="number">1</span>:],</span><br><span class="line">             var_name=<span class="string">'income'</span>, value_name=<span class="string">'frequency'</span>)</span><br><span class="line">df = df.sort_values(by=<span class="string">'religion'</span>)</span><br><span class="line">df.to_csv(<span class="string">'data/pew-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>This will give the same result. We’ll use <code>melt()</code> method a lot in the following sections.</p><p>Let’s take a look at another form of untidiness that falls in this section:</p><p><img src="/images/tidy-data/billboard.png" alt="Billboard 2000"></p><p>In this dataset, weekly ranks are recorded in separate columns. To answer the question “what’s the rank of ‘Dancing Queen’ in 2000-07-15”, we need to do some calculations with <code>date.entered</code> and the week columns. Let’s transform it into a tidy form:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/billboard.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=list(df.columns)[:<span class="number">5</span>], value_vars=list(df.columns)[<span class="number">5</span>:],</span><br><span class="line">             var_name=<span class="string">'week'</span>, value_name=<span class="string">'rank'</span>)</span><br><span class="line">df[<span class="string">'week'</span>] = df[<span class="string">'week'</span>].str[<span class="number">2</span>:].astype(int)</span><br><span class="line">df[<span class="string">'date.entered'</span>] = pd.to_datetime(df[<span class="string">'date.entered'</span>]) + pd.to_timedelta((df[<span class="string">'week'</span>] - <span class="number">1</span>) * <span class="number">7</span>, <span class="string">'d'</span>)</span><br><span class="line">df = df.rename(columns=&#123;<span class="string">'date.entered'</span>: <span class="string">'date'</span>&#125;)</span><br><span class="line">df = df.sort_values(by=[<span class="string">'track'</span>, <span class="string">'date'</span>])</span><br><span class="line">df.to_csv(<span class="string">'data/billboard-intermediate.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/billboard-intermediate.png" alt="Billboard 2000 - Intermediate Tidy"></p><p>We’ve also transformed the <code>date.entered</code> variable into the exact date of that week. Now <code>week</code> becomes a single column that represents a variable. But we can see a lot of duplications in this table, like artist and track. We’ll solve this problem in the fourth section.</p><h2 id="Multiple-variables-stored-in-one-column"><a href="#Multiple-variables-stored-in-one-column" class="headerlink" title="Multiple variables stored in one column"></a>Multiple variables stored in one column</h2><p>Storing variable values in columns is quite common because it makes the data table more compact, and easier to do analysis like cross validation, etc. The following dataset even manages to store two variables in the column, sex and age.</p><p><img src="/images/tidy-data/tb.png" alt="Tuberculosis (TB)"></p><p><code>m</code> stands for <code>male</code>, <code>f</code> for <code>female</code>, and age ranges are <code>0-14</code>, <code>15-24</code>, and so forth. To tidy it, we first melt the columns, use Pandas’ string operation to extract <code>sex</code>, and do a value mapping for the <code>age</code> ranges.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/tb.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'country'</span>, <span class="string">'year'</span>], value_vars=list(df.columns)[<span class="number">2</span>:],</span><br><span class="line">             var_name=<span class="string">'column'</span>, value_name=<span class="string">'cases'</span>)</span><br><span class="line">df = df[df[<span class="string">'cases'</span>] != <span class="string">'---'</span>]</span><br><span class="line">df[<span class="string">'cases'</span>] = df[<span class="string">'cases'</span>].astype(int)</span><br><span class="line">df[<span class="string">'sex'</span>] = df[<span class="string">'column'</span>].str[<span class="number">0</span>]</span><br><span class="line">df[<span class="string">'age'</span>] = df[<span class="string">'column'</span>].str[<span class="number">1</span>:].map(&#123;</span><br><span class="line">    <span class="string">'014'</span>: <span class="string">'0-14'</span>,</span><br><span class="line">    <span class="string">'1524'</span>: <span class="string">'15-24'</span>,</span><br><span class="line">    <span class="string">'2534'</span>: <span class="string">'25-34'</span>,</span><br><span class="line">    <span class="string">'3544'</span>: <span class="string">'35-44'</span>,</span><br><span class="line">    <span class="string">'4554'</span>: <span class="string">'45-54'</span>,</span><br><span class="line">    <span class="string">'5564'</span>: <span class="string">'55-64'</span>,</span><br><span class="line">    <span class="string">'65'</span>: <span class="string">'65+'</span></span><br><span class="line">&#125;)</span><br><span class="line">df = df[[<span class="string">'country'</span>, <span class="string">'year'</span>, <span class="string">'sex'</span>, <span class="string">'age'</span>, <span class="string">'cases'</span>]]</span><br><span class="line">df.to_csv(<span class="string">'data/tb-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/tb-tidy.png" alt="Tuberculosis (TB) - Tidy"></p><h2 id="Variables-are-stored-in-both-rows-and-columns"><a href="#Variables-are-stored-in-both-rows-and-columns" class="headerlink" title="Variables are stored in both rows and columns"></a>Variables are stored in both rows and columns</h2><p>This is a temperature dataset collection by a Weather Station named MX17004. Dates are spread in columns which can be melted into one column. <code>tmax</code> and <code>tmin</code> stand for highest and lowest temperatures, and they are really variables of each observational unit, in this case, each day, so we should <code>unstack</code> them into different columns.</p><p><img src="/images/tidy-data/weather.png" alt="Weather Station"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/weather.csv'</span>)</span><br><span class="line">df = pd.melt(df, id_vars=[<span class="string">'id'</span>, <span class="string">'year'</span>, <span class="string">'month'</span>, <span class="string">'element'</span>],</span><br><span class="line">             value_vars=list(df.columns)[<span class="number">4</span>:],</span><br><span class="line">             var_name=<span class="string">'date'</span>, value_name=<span class="string">'value'</span>)</span><br><span class="line">df[<span class="string">'date'</span>] = df[<span class="string">'date'</span>].str[<span class="number">1</span>:].astype(<span class="string">'int'</span>)</span><br><span class="line">df[<span class="string">'date'</span>] = df[[<span class="string">'year'</span>, <span class="string">'month'</span>, <span class="string">'date'</span>]].apply(</span><br><span class="line">    <span class="keyword">lambda</span> row: <span class="string">'&#123;:4d&#125;-&#123;:02d&#125;-&#123;:02d&#125;'</span>.format(*row),</span><br><span class="line">    axis=<span class="number">1</span>)</span><br><span class="line">df = df.loc[df[<span class="string">'value'</span>] != <span class="string">'---'</span>, [<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'element'</span>, <span class="string">'value'</span>]]</span><br><span class="line">df = df.set_index([<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'element'</span>])</span><br><span class="line">df = df.unstack()</span><br><span class="line">df.columns = list(df.columns.get_level_values(<span class="string">'element'</span>))</span><br><span class="line">df = df.reset_index()</span><br><span class="line">df.to_csv(<span class="string">'data/weather-tidy.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/weather-tidy.png" alt="Weather Station - Tidy"></p><h2 id="Multiple-types-in-one-table"><a href="#Multiple-types-in-one-table" class="headerlink" title="Multiple types in one table"></a>Multiple types in one table</h2><p>In the processed Billboard dataset, we can see duplicates of song tracks, it’s because this table actually contains two types of observational units, song tracks and weekly ranks. To tidy it, we first generate identities for each song track, i.e. <code>id</code>, and then separate them into different tables.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'data/billboard-intermediate.csv'</span>)</span><br><span class="line">df_track = df[[<span class="string">'artist'</span>, <span class="string">'track'</span>, <span class="string">'time'</span>]].drop_duplicates()</span><br><span class="line">df_track.insert(<span class="number">0</span>, <span class="string">'id'</span>, range(<span class="number">1</span>, len(df_track) + <span class="number">1</span>))</span><br><span class="line">df = pd.merge(df, df_track, on=[<span class="string">'artist'</span>, <span class="string">'track'</span>, <span class="string">'time'</span>])</span><br><span class="line">df = df[[<span class="string">'id'</span>, <span class="string">'date'</span>, <span class="string">'rank'</span>]]</span><br><span class="line">df_track.to_csv(<span class="string">'data/billboard-track.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">df.to_csv(<span class="string">'data/billboard-rank.csv'</span>, index=<span class="keyword">False</span>)</span><br><span class="line">print(df_track, <span class="string">'\n\n'</span>, df)</span><br></pre></td></tr></table></figure><p><img src="/images/tidy-data/billboard-track.png" alt="Billboard 2000 - Track"></p><p><img src="/images/tidy-data/billboard-rank.png" alt="Billboard 2000 - Rank"></p><h2 id="One-type-in-multiple-tables"><a href="#One-type-in-multiple-tables" class="headerlink" title="One type in multiple tables"></a>One type in multiple tables</h2><p>Datasets can be separated in two ways, by different values of an variable like year 2000, 2001, location China, Britain, or by different attributes like temperature from one sensor, humidity from another. In the first case, we can write a utility function that walks through the data directory, reads each file, and assigns the filename to a dedicated column. In the end we can combine these DataFrames with <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html" target="_blank" rel="noopener"><code>pd.concat</code></a>. In the latter case, there should be some attribute that can identify the same units, like date, personal ID, etc. We can use <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.merge.html" target="_blank" rel="noopener"><code>pd.merge</code></a> to join datasets by common keys.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://tomaugspurger.github.io/modern-5-tidy.html" target="_blank" rel="noopener">https://tomaugspurger.github.io/modern-5-tidy.html</a></li><li><a href="https://hackernoon.com/reshaping-data-in-python-fa27dda2ff77" target="_blank" rel="noopener">https://hackernoon.com/reshaping-data-in-python-fa27dda2ff77</a></li><li><a href="http://www.jeannicholashould.com/tidy-data-in-python.html" target="_blank" rel="noopener">http://www.jeannicholashould.com/tidy-data-in-python.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In the paper &lt;a href=&quot;https://www.jstatsoft.org/article/view/v059i10&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Tidy Data&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Hadley_Wickham&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Dr. Wickham&lt;/a&gt; proposed a specific form of data structure: each variable is a column, each observation is a row, and each type of observational unit is a table. He argued that with tidy data, data analysts can manipulate, model, and visualize data more easily and effectively. He lists &lt;em&gt;five common data structures&lt;/em&gt; that are untidy, and demonstrates how to use &lt;a href=&quot;https://github.com/hadley/tidy-data/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;R language&lt;/a&gt; to tidy them. In this article, we’ll use Python and Pandas to achieve the same tidiness.&lt;/p&gt;
&lt;p&gt;Source code and demo data can be found on GitHub (&lt;a href=&quot;https://github.com/jizhang/pandas-tidy-data&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;link&lt;/a&gt;), and readers are supposed to have Python environment installed, preferably with Anaconda and Spyder IDE.&lt;/p&gt;
&lt;h2 id=&quot;Column-headers-are-values-not-variable-names&quot;&gt;&lt;a href=&quot;#Column-headers-are-values-not-variable-names&quot; class=&quot;headerlink&quot; title=&quot;Column headers are values, not variable names&quot;&gt;&lt;/a&gt;Column headers are values, not variable names&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;data/pew.csv&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/images/tidy-data/pew.png&quot; alt=&quot;Religion and Income - Pew Forum&quot;&gt;&lt;/p&gt;
&lt;p&gt;Column names “&amp;lt;$10k”, “$10-20k” are really income ranges that constitutes a variable. Variables are measurements of attributes, like height, weight, and in this case, income and religion. The values within the table form another variable, frequency. To make &lt;em&gt;each variable a column&lt;/em&gt;, we do the following transformation:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;df = df.set_index(&lt;span class=&quot;string&quot;&gt;&#39;religion&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = df.stack()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.index = df.index.rename(&lt;span class=&quot;string&quot;&gt;&#39;income&#39;&lt;/span&gt;, level=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.name = &lt;span class=&quot;string&quot;&gt;&#39;frequency&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df = df.reset_index()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&quot;/images/tidy-data/pew-tidy.png&quot; alt=&quot;Religion and Income - Tidy&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/tags/analytics/"/>
    
      <category term="pandas" scheme="http://shzhangji.com/tags/pandas/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam Quick Start with Python</title>
    <link href="http://shzhangji.com/blog/2017/09/12/apache-beam-quick-start-with-python/"/>
    <id>http://shzhangji.com/blog/2017/09/12/apache-beam-quick-start-with-python/</id>
    <published>2017-09-12T13:08:25.000Z</published>
    <updated>2017-09-13T01:44:34.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://beam.apache.org/get-started/beam-overview/" target="_blank" rel="noopener">Apache Beam</a> is a big data processing standard created by Google in 2016. It provides unified DSL to process both batch and stream data, and can be executed on popular platforms like Spark, Flink, and of course Google’s commercial product Dataflow. Beam’s model is based on previous works known as <a href="https://web.archive.org/web/20160923141630/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35650.pdf" target="_blank" rel="noopener">FlumeJava</a> and <a href="https://web.archive.org/web/20160201091359/http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf" target="_blank" rel="noopener">Millwheel</a>, and addresses solutions for data processing tasks like ETL, analysis, and <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101" target="_blank" rel="noopener">stream processing</a>. Currently it provides SDK in two languages, Java and Python. This article will introduce how to use Python to write Beam applications.</p><p><img src="/images/beam/arch.jpg" alt="Apache Beam Pipeline"></p><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>Apache Beam Python SDK requires Python 2.7.x. You can use <a href="https://github.com/pyenv/pyenv" target="_blank" rel="noopener">pyenv</a> to manage different Python versions, or compile from <a href="https://www.python.org/downloads/source/" target="_blank" rel="noopener">source</a> (make sure you have SSL installed). And then you can install Beam SDK from PyPI, better in a virtual environment:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ virtualenv venv --distribute</span><br><span class="line">$ source venv/bin/activate</span><br><span class="line">(venv) $ pip install apache-beam</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Wordcount-Example"><a href="#Wordcount-Example" class="headerlink" title="Wordcount Example"></a>Wordcount Example</h2><p>Wordcount is the de-facto “Hello World” in big data field, so let’s take a look at how it’s done with Beam:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> apache_beam <span class="keyword">as</span> beam</span><br><span class="line"><span class="keyword">from</span> apache_beam.options.pipeline_options <span class="keyword">import</span> PipelineOptions</span><br><span class="line"><span class="keyword">with</span> beam.Pipeline(options=PipelineOptions()) <span class="keyword">as</span> p:</span><br><span class="line">    lines = p | <span class="string">'Create'</span> &gt;&gt; beam.Create([<span class="string">'cat dog'</span>, <span class="string">'snake cat'</span>, <span class="string">'dog'</span>])</span><br><span class="line">    counts = (</span><br><span class="line">        lines</span><br><span class="line">        | <span class="string">'Split'</span> &gt;&gt; (beam.FlatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">' '</span>))</span><br><span class="line">                      .with_output_types(unicode))</span><br><span class="line">        | <span class="string">'PairWithOne'</span> &gt;&gt; beam.Map(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>))</span><br><span class="line">        | <span class="string">'GroupAndSum'</span> &gt;&gt; beam.CombinePerKey(sum)</span><br><span class="line">    )</span><br><span class="line">    counts | <span class="string">'Print'</span> &gt;&gt; beam.ParDo(<span class="keyword">lambda</span> (w, c): print(<span class="string">'%s: %s'</span> % (w, c)))</span><br></pre></td></tr></table></figure><p>Run the script, you’ll get the counts of difference words:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(venv) $ python wordcount.py</span><br><span class="line">cat: 2</span><br><span class="line">snake: 1</span><br><span class="line">dog: 2</span><br></pre></td></tr></table></figure><p>There’re three fundamental concepts in Apache Beam, namely Pipeline, PCollection, and Transform.</p><ul><li><strong>Pipeline</strong> holds the DAG (Directed Acyclic Graph) of data and process tasks. It’s analogous to MapReduce <code>Job</code> and Storm <code>Topology</code>.</li><li><strong>PCollection</strong> is the data structure to which we apply various operations, like parse, convert, or aggregate. You can think of it as Spark <code>RDD</code>.</li><li>And <strong>Transform</strong> is where your main logic goes. Each transform will take a PCollection in and produce a new PCollection. Beam provides many built-in Transforms, and we’ll cover them later.</li></ul><p>As in this example, <code>Pipeline</code> and <code>PipelineOptions</code> are used to construct a pipeline. Use the <code>with</code> statement so that context manager will invoke <code>Pipeline.run</code> and <code>wait_until_finish</code> automatically.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Output PCollection] = [Input PCollection] | [Label] &gt;&gt; [Transform]</span><br></pre></td></tr></table></figure><p><code>|</code> is the operator to apply transforms, and each transform can be optionally supplied with a unique label. Transforms can be chained, and we can compose arbitrary shapes of transforms, and at runtime they’ll be represented as DAG.</p><p><code>beam.Create</code> is a transform that creates PCollection from memory data, mainly for testing. Beam has built-in sources and sinks to read and write bounded or unbounded data, and it’s possible to implement our own.</p><p><code>beam.Map</code> is a <em>one-to-one</em> transform, and in this example we convert a word string to a <code>(word, 1)</code> tuple. <code>beam.FlatMap</code> is a combination of <code>Map</code> and <code>Flatten</code>, i.e. we split each line into an array of words, and then flatten these sequences into a single one.</p><p><code>CombinePerKey</code> works on two-element tuples. It groups the tuples by the first element (the key), and apply the provided function to the list of second elements (values). Finally, we use <code>beam.ParDo</code> to print out the counts. This is a rather basic transform, and we’ll discuss it in the following section.</p><h2 id="Input-and-Output"><a href="#Input-and-Output" class="headerlink" title="Input and Output"></a>Input and Output</h2><p>Currently, Beam’s Python SDK has very limited supports for IO. This table (<a href="https://beam.apache.org/documentation/io/built-in/" target="_blank" rel="noopener">source</a>) gives an overview of the available built-in transforms:</p><table><thead><tr><th>Language</th><th>File-based</th><th>Messaging</th><th>Database</th></tr></thead><tbody><tr><td>Java</td><td>HDFS<br>TextIO<br>XML</td><td>AMQP<br>Kafka<br>JMS</td><td>Hive<br>Solr<br>JDBC</td></tr><tr><td>Python</td><td>textio<br>avroio<br>tfrecordio</td><td>-</td><td>Google Big Query<br>Google Cloud Datastore</td></tr></tbody></table><p>The following snippet demonstrates the usage of <code>textio</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines = p | <span class="string">'Read'</span> &gt;&gt; beam.io.ReadFromText(<span class="string">'/path/to/input-*.csv'</span>)</span><br><span class="line">lines | <span class="string">'Write'</span> &gt;&gt; beam.io.WriteToText(<span class="string">'/path/to/output'</span>, file_name_suffix=<span class="string">'.csv'</span>)</span><br></pre></td></tr></table></figure><p><code>textio</code> is able to read multiple input files by using wildcard or you can flatten PCollections created from difference sources. The outputs are also split into several files due to pipeline’s parallel processing nature.</p><h2 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h2><p>There’re basic transforms and higher-level built-ins. In general, we prefer to use the later so that we can focus on the application logic. The following table lists some commonly used higher-level transforms:</p><table><thead><tr><th>Transform</th><th>Meaning</th></tr></thead><tbody><tr><td>Create(value)</td><td>Creates a PCollection from an iterable.</td></tr><tr><td>Filter(fn)</td><td>Use callable <code>fn</code> to filter out elements.</td></tr><tr><td>Map(fn)</td><td>Use callable <code>fn</code> to do a one-to-one transformation.</td></tr><tr><td>FlatMap(fn)</td><td>Similar to <code>Map</code>, but <code>fn</code> needs to return an iterable of zero or more elements, and these iterables will be flattened into one PCollection.</td></tr><tr><td>Flatten()</td><td>Merge several PCollections into a single one.</td></tr><tr><td>Partition(fn)</td><td>Split a PCollection into several partitions. <code>fn</code> is a <code>PartitionFn</code> or a callable that accepts two arguments - <code>element</code>, <code>num_partitions</code>.</td></tr><tr><td>GroupByKey()</td><td>Works on a PCollection of key/value pairs (two-element tuples), groups by common key, and returns <code>(key, iter&lt;value&gt;)</code> pairs.</td></tr><tr><td>CoGroupByKey()</td><td>Groups results across several PCollections by key. e.g. input <code>(k, v)</code> and <code>(k, w)</code>, output <code>(k, (iter&lt;v&gt;, iter&lt;w&gt;))</code>.</td></tr><tr><td>RemoveDuplicates()</td><td>Get distint values in PCollection.</td></tr><tr><td>CombinePerKey(fn)</td><td>Similar to <code>GroupByKey</code>, but combines the values by a <code>CombineFn</code> or a callable that takes an iterable, such as <code>sum</code>, <code>max</code>.</td></tr><tr><td>CombineGlobally(fn)</td><td>Reduces a PCollection to a single value by applying <code>fn</code>.</td></tr></tbody></table><h3 id="Callable-DoFn-and-ParDo"><a href="#Callable-DoFn-and-ParDo" class="headerlink" title="Callable, DoFn, and ParDo"></a>Callable, DoFn, and ParDo</h3><p>Most transforms accepts a callable as argument. In Python, <a href="https://docs.python.org/2/library/functions.html#callable" target="_blank" rel="noopener">callable</a> can be a function, method, lambda expression, or class instance that has <code>__call__</code> method. Under the hood, Beam will wrap the callable as a <code>DoFn</code>, and all these transforms will invoke <code>ParDo</code>, the lower-level transform, with the <code>DoFn</code>.</p><p>Let’s replace the expression <code>lambda x: x.split(&#39; &#39;)</code> with a <code>DoFn</code> class:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SplitFn</span><span class="params">(beam.DoFn)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(self, element)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> element.split(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">lines | beam.ParDo(SplitFn())</span><br></pre></td></tr></table></figure><p>The <code>ParDo</code> transform works like <code>FlatMap</code>, except that it only accepts <code>DoFn</code>. In addition to <code>return</code>, we can <code>yield</code> element from <code>process</code> method:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SplitAndPairWithOneFn</span><span class="params">(beam.DoFn)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(self, element)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> element.split(<span class="string">' '</span>):</span><br><span class="line">            <span class="keyword">yield</span> (word, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="Combiner-Functions"><a href="#Combiner-Functions" class="headerlink" title="Combiner Functions"></a>Combiner Functions</h3><p>Combiner functions, or <code>CombineFn</code>, are used to reduce a collection of elements into a single value. You can either perform on the entire PCollection (<code>CombineGlobally</code>), or combine the values for each key (<code>CombinePerKey</code>). Beam is capable of wrapping callables into <code>CombinFn</code>. The callable should take an iterable and returns a single value. Since Beam distributes computation to multiple nodes, the combiner function will be invoked multiple times to get partial results, so they ought to be <a href="https://en.wikipedia.org/wiki/Commutative_property" target="_blank" rel="noopener">commutative</a> and <a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="noopener">associative</a>. <code>sum</code>, <code>min</code>, <code>max</code> are good examples.</p><p>Beam provides some built-in combiners like count, mean, top. Take count for instance, the following two lines are equivalent, they return the total count of lines.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lines | beam.combiners.Count.Globally()</span><br><span class="line">lines | beam.CombineGlobally(beam.combiners.CountCombineFn())</span><br></pre></td></tr></table></figure><p>Other combiners can be found in Beam Python SDK Documentation (<a href="https://beam.apache.org/documentation/sdks/pydoc/2.1.0/apache_beam.transforms.html#module-apache_beam.transforms.combiners" target="_blank" rel="noopener">link</a>). For more complex combiners, we need to subclass the <code>CombinFn</code> and implement four methods. Take the built-in <code>Mean</code> for an example:</p><p><a href="https://github.com/apache/beam/blob/v2.1.0/sdks/python/apache_beam/transforms/combiners.py#L75" target="_blank" rel="noopener"><code>apache_beam/transforms/combiners.py</code></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeanCombineFn</span><span class="params">(core.CombineFn)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">create_accumulator</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Create a "local" accumulator to track sum and count."""</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add_input</span><span class="params">(self, <span class="params">(sum_, count)</span>, element)</span>:</span></span><br><span class="line">    <span class="string">"""Process the incoming value."""</span></span><br><span class="line">    <span class="keyword">return</span> sum_ + element, count + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">merge_accumulators</span><span class="params">(self, accumulators)</span>:</span></span><br><span class="line">    <span class="string">"""Merge several accumulators into a single one."""</span></span><br><span class="line">    sums, counts = zip(*accumulators)</span><br><span class="line">    <span class="keyword">return</span> sum(sums), sum(counts)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">extract_output</span><span class="params">(self, <span class="params">(sum_, count)</span>)</span>:</span></span><br><span class="line">    <span class="string">"""Compute the mean average."""</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">      <span class="keyword">return</span> float(<span class="string">'NaN'</span>)</span><br><span class="line">    <span class="keyword">return</span> sum_ / float(count)</span><br></pre></td></tr></table></figure><h3 id="Composite-Transform"><a href="#Composite-Transform" class="headerlink" title="Composite Transform"></a>Composite Transform</h3><p>Take a look at the <a href="https://github.com/apache/beam/blob/v2.1.0/sdks/python/apache_beam/transforms/combiners.py#L101" target="_blank" rel="noopener">source code</a> of <code>beam.combiners.Count.Globally</code> we used before. It subclasses <code>PTransform</code> and applies some transforms to the PCollection. This forms a sub-graph of DAG, and we call it composite transform. Composite transforms are used to gather relative codes into logical modules, making them easy to understand and maintain.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Count</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">Globally</span><span class="params">(ptransform.PTransform)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">expand</span><span class="params">(self, pcoll)</span>:</span></span><br><span class="line">      <span class="keyword">return</span> pcoll | core.CombineGlobally(CountCombineFn())</span><br></pre></td></tr></table></figure><p>More built-in transforms are listed below:</p><table><thead><tr><th>Transform</th><th>Meaning</th></tr></thead><tbody><tr><td>Count.Globally()</td><td>Count the total number of elements.</td></tr><tr><td>Count.PerKey()</td><td>Count number elements of each unique key.</td></tr><tr><td>Count.PerElement()</td><td>Count the occurrences of each element.</td></tr><tr><td>Mean.Globally()</td><td>Compute the average of all elements.</td></tr><tr><td>Mean.PerKey()</td><td>Compute the averages for each key.</td></tr><tr><td>Top.Of(n, reverse)</td><td>Get the top <code>n</code> elements from the PCollection. See also Top.Largest(n), Top.Smallest(n).</td></tr><tr><td>Top.PerKey(n, reverse)</td><td>Get top <code>n</code> elements for each key. See also Top.LargestPerKey(n), Top.SmallestPerKey(n)</td></tr><tr><td>Sample.FixedSizeGlobally(n)</td><td>Get a sample of <code>n</code> elements.</td></tr><tr><td>Sample.FixedSizePerKey(n)</td><td>Get samples from each key.</td></tr><tr><td>ToList()</td><td>Combine to a single list.</td></tr><tr><td>ToDict()</td><td>Combine to a single dict. Works on 2-element tuples.</td></tr></tbody></table><h2 id="Windowing"><a href="#Windowing" class="headerlink" title="Windowing"></a>Windowing</h2><p>When processing event data, such as access log or click stream, there’s an <em>event time</em> property attached to every item, and it’s common to perform aggregation on a per-time-window basis. With Beam, we can define different kinds of windows to divide event data into groups. Windowing can be used in both bounded and unbounded data source. Since current Python SDK only supports bounded source, the following example will work on an offline access log file, but the process can be applied to unbounded source as is.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">64.242.88.10 - - [07/Mar/2004:16:05:49 -0800] &quot;GET /edit HTTP/1.1&quot; 401 12846</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:06:51 -0800] &quot;GET /rdiff HTTP/1.1&quot; 200 4523</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] &quot;GET /hsdivision HTTP/1.1&quot; 200 6291</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:11:58 -0800] &quot;GET /view HTTP/1.1&quot; 200 7352</span><br><span class="line">64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] &quot;GET /view HTTP/1.1&quot; 200 5253</span><br></pre></td></tr></table></figure><p><code>logmining.py</code>, full source code can be found on GitHub (<a href="https://github.com/jizhang/hello-beam/blob/master/logmining.py" target="_blank" rel="noopener">link</a>).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">lines = p | <span class="string">'Create'</span> &gt;&gt; beam.io.ReadFromText(<span class="string">'access.log'</span>)</span><br><span class="line">windowed_counts = (</span><br><span class="line">    lines</span><br><span class="line">    | <span class="string">'Timestamp'</span> &gt;&gt; beam.Map(<span class="keyword">lambda</span> x: beam.window.TimestampedValue(</span><br><span class="line">                              x, extract_timestamp(x)))</span><br><span class="line">    | <span class="string">'Window'</span> &gt;&gt; beam.WindowInto(beam.window.SlidingWindows(<span class="number">600</span>, <span class="number">300</span>))</span><br><span class="line">    | <span class="string">'Count'</span> &gt;&gt; (beam.CombineGlobally(beam.combiners.CountCombineFn())</span><br><span class="line">                  .without_defaults())</span><br><span class="line">)</span><br><span class="line">windowed_counts =  windowed_counts | beam.ParDo(PrintWindowFn())</span><br></pre></td></tr></table></figure><p>First of all, we need to add a timestamp to each record. <code>extract_timestamp</code> is a custom function to parse <code>[07/Mar/2004:16:05:49 -0800]</code> as a unix timestamp. <code>TimestampedValue</code> links this timestamp to the record. Then we define a sliding window with the size <em>10 minutes</em> and period <em>5 minutes</em>, which means the first window is <code>[00:00, 00:10)</code>, second window is <code>[00:05, 00:15)</code>, and so forth. All windows have a <em>10 minutes</em> duration, and adjacent windows have a <em>5 minutes</em> shift. Sliding window is different from fixed window, in that the same elements could appear in different windows. The combiner function is a simple count, so the pipeline result of the first five logs will be:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[2004-03-08T00:00:00Z, 2004-03-08T00:10:00Z) @ 2</span><br><span class="line">[2004-03-08T00:05:00Z, 2004-03-08T00:15:00Z) @ 4</span><br><span class="line">[2004-03-08T00:10:00Z, 2004-03-08T00:20:00Z) @ 2</span><br><span class="line">[2004-03-08T00:15:00Z, 2004-03-08T00:25:00Z) @ 1</span><br><span class="line">[2004-03-08T00:20:00Z, 2004-03-08T00:30:00Z) @ 1</span><br></pre></td></tr></table></figure><p>In stream processing for unbounded source, event data will arrive in different order, so we need to deal with late data with Beam’s watermark and trigger facility. This is a rather advanced topic, and the Python SDK has not yet implemented this feature. If you’re interested, please refer to Stream <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101" target="_blank" rel="noopener">101</a> and <a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102" target="_blank" rel="noopener">102</a> articles.</p><h2 id="Pipeline-Runner"><a href="#Pipeline-Runner" class="headerlink" title="Pipeline Runner"></a>Pipeline Runner</h2><p>As mentioned above, Apache Beam is just a standard that provides SDK and APIs. It’s the pipeline runner that is responsible to execute the workflow graph. The following matrix lists all available runners and their capabilities compared to Beam Model.</p><p><img src="/images/beam/matrix.png" alt="Beam Capability Matrix"></p><p><a href="https://beam.apache.org/documentation/runners/capability-matrix/" target="_blank" rel="noopener">Source</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://beam.apache.org/documentation/programming-guide/" target="_blank" rel="noopener">https://beam.apache.org/documentation/programming-guide/</a></li><li><a href="https://beam.apache.org/documentation/sdks/pydoc/2.1.0/" target="_blank" rel="noopener">https://beam.apache.org/documentation/sdks/pydoc/2.1.0/</a></li><li><a href="https://sookocheff.com/post/dataflow/get-to-know-dataflow/" target="_blank" rel="noopener">https://sookocheff.com/post/dataflow/get-to-know-dataflow/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://beam.apache.org/get-started/beam-overview/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Beam&lt;/a&gt; is a big data processing standard created by Google in 2016. It provides unified DSL to process both batch and stream data, and can be executed on popular platforms like Spark, Flink, and of course Google’s commercial product Dataflow. Beam’s model is based on previous works known as &lt;a href=&quot;https://web.archive.org/web/20160923141630/https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35650.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;FlumeJava&lt;/a&gt; and &lt;a href=&quot;https://web.archive.org/web/20160201091359/http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41378.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Millwheel&lt;/a&gt;, and addresses solutions for data processing tasks like ETL, analysis, and &lt;a href=&quot;https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;stream processing&lt;/a&gt;. Currently it provides SDK in two languages, Java and Python. This article will introduce how to use Python to write Beam applications.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/beam/arch.jpg&quot; alt=&quot;Apache Beam Pipeline&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Installation&quot;&gt;&lt;a href=&quot;#Installation&quot; class=&quot;headerlink&quot; title=&quot;Installation&quot;&gt;&lt;/a&gt;Installation&lt;/h2&gt;&lt;p&gt;Apache Beam Python SDK requires Python 2.7.x. You can use &lt;a href=&quot;https://github.com/pyenv/pyenv&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;pyenv&lt;/a&gt; to manage different Python versions, or compile from &lt;a href=&quot;https://www.python.org/downloads/source/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;source&lt;/a&gt; (make sure you have SSL installed). And then you can install Beam SDK from PyPI, better in a virtual environment:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ virtualenv venv --distribute&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ source venv/bin/activate&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;(venv) $ pip install apache-beam&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/tags/stream-processing/"/>
    
      <category term="apache beam" scheme="http://shzhangji.com/tags/apache-beam/"/>
    
      <category term="mapreduce" scheme="http://shzhangji.com/tags/mapreduce/"/>
    
  </entry>
  
  <entry>
    <title>Hive Window and Analytical Functions</title>
    <link href="http://shzhangji.com/blog/2017/09/04/hive-window-and-analytical-functions/"/>
    <id>http://shzhangji.com/blog/2017/09/04/hive-window-and-analytical-functions/</id>
    <published>2017-09-04T13:55:23.000Z</published>
    <updated>2017-09-06T02:19:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>SQL is one of the major tools of data analysis. It provides filtering, transforming and aggregation functionalities, and we can use it to process big volume of data with the help of Hive and Hadoop. However, legacy SQL does not support operations like grouped ranking and moving average, because the <code>GROUP BY</code> clause can only produce one aggregation result for each group, but not for each row. Fortunately, with the new SQL standard coming, we can use the <code>WINDOW</code> clause to compute aggregations on a set of rows and return the result for each row.</p><p><img src="/images/hive-window/window-stock.png" alt="Moving Average"></p><p>For instance, if we want to calculate the two-day moving average for each stock, we can write the following query:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="string">`date`</span>, <span class="string">`stock`</span>, <span class="string">`close`</span></span><br><span class="line">  ,<span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> <span class="string">`w`</span> <span class="keyword">AS</span> <span class="string">`mavg`</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="string">`t_stock`</span></span><br><span class="line">WINDOW <span class="string">`w`</span> <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="string">`date`</span></span><br><span class="line">               <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="number">1</span> <span class="keyword">PRECEDING</span> <span class="keyword">AND</span> <span class="keyword">CURRENT</span> <span class="keyword">ROW</span>)</span><br></pre></td></tr></table></figure><p><code>OVER</code>, <code>WINDOW</code> and <code>ROWS BETWEEN AND</code> are all newly added SQL keywords to support windowing operations. In this query, <code>PARTITION BY</code> and <code>ORDER BY</code> works like <code>GROUP BY</code> and <code>ORDER BY</code> after the <code>WHERE</code> clause, except it doesn’t collapse the rows, but only divides them into non-overlapping partitions to work on. <code>ROWS BETWEEN AND</code> here constructs a <strong>window frame</strong>. In this case, each frame contains the previous row and current row. We’ll discuss more on frames later. Finally, <code>AVG</code> is a window function that computes results on each frame. Note that <code>WINDOW</code> clause can also be directly appended to window function:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">AVG</span>(<span class="string">`close`</span>) <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`stock`</span>) <span class="keyword">AS</span> <span class="string">`mavg`</span> <span class="keyword">FROM</span> <span class="string">`t_stock`</span>;</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="Window-Query-Concepts"><a href="#Window-Query-Concepts" class="headerlink" title="Window Query Concepts"></a>Window Query Concepts</h2><p><img src="/images/hive-window/concepts.png" alt="Concepts"></p><p><a href="https://en.wikibooks.org/wiki/Structured_Query_Language/Window_functions" target="_blank" rel="noopener">Source</a></p><p>SQL window query introduces three concepts, namely window partition, window frame and window function.</p><p><code>PARTITION</code> clause divides result set into <strong>window partitions</strong> by one or more columns, and the rows within can be optionally sorted by one or more columns. If there’s not <code>PARTITION BY</code>, the entire result set is treated as a single partition; if there’s not <code>ORDER BY</code>, window frames cannot be defined, and all rows within the partition constitutes a single frame.</p><p><strong>Window frame</strong> selects rows from partition for window function to work on. There’re two ways of defining frame in Hive, <code>ROWS</code> AND <code>RANGE</code>. For both types, we define the upper bound and lower bound. For instance, <code>ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW</code> selects rows from the beginning of the partition to the current row; <code>SUM(close) RANGE BETWEEN 100 PRECEDING AND 200 FOLLOWING</code> selects rows by the <em>distance</em> from the current row’s value. Say current <code>close</code> is <code>200</code>, and this frame will includes rows whose <code>close</code> values range from <code>100</code> to <code>400</code>, within the partition. All possible combinations of frame definitions are listed as follows, and the default definition is <code>RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(ROWS | RANGE) BETWEEN (UNBOUNDED | [num]) PRECEDING AND ([num] PRECEDING | CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)</span><br><span class="line">(ROWS | RANGE) BETWEEN CURRENT ROW AND (CURRENT ROW | (UNBOUNDED | [num]) FOLLOWING)</span><br><span class="line">(ROWS | RANGE) BETWEEN [num] FOLLOWING AND (UNBOUNDED | [num]) FOLLOWING</span><br></pre></td></tr></table></figure><p>All <strong>window functions</strong> compute results on the current frame. Hive supports the following functions:</p><ul><li><code>FIRST_VALUE(col)</code>, <code>LAST_VALUE(col)</code> returns the column value of first / last row within the frame;</li><li><code>LEAD(col, n)</code>, <code>LAG(col, n)</code> returns the column value of n-th row before / after current row;</li><li><code>RANK()</code>, <code>ROW_NUMBER()</code> assigns a sequence of the current row within the frame. The difference is <code>RANK()</code> will contain duplicate if there’re identical values.</li><li><code>COUNT()</code>, <code>SUM(col)</code>, <code>MIN(col)</code> works as usual.</li></ul><h2 id="Hive-Query-Examples"><a href="#Hive-Query-Examples" class="headerlink" title="Hive Query Examples"></a>Hive Query Examples</h2><h3 id="Top-K"><a href="#Top-K" class="headerlink" title="Top K"></a>Top K</h3><p>First, let’s create some test data of employee incomes in Hive:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> t_employee (<span class="keyword">id</span> <span class="built_in">INT</span>, emp_name <span class="built_in">VARCHAR</span>(<span class="number">20</span>), dep_name <span class="built_in">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">salary <span class="built_in">DECIMAL</span>(<span class="number">7</span>, <span class="number">2</span>), age <span class="built_in">DECIMAL</span>(<span class="number">3</span>, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> t_employee <span class="keyword">VALUES</span></span><br><span class="line">( <span class="number">1</span>,  <span class="string">'Matthew'</span>, <span class="string">'Management'</span>,  <span class="number">4500</span>, <span class="number">55</span>),</span><br><span class="line">( <span class="number">2</span>,  <span class="string">'Olivia'</span>,  <span class="string">'Management'</span>,  <span class="number">4400</span>, <span class="number">61</span>),</span><br><span class="line">( <span class="number">3</span>,  <span class="string">'Grace'</span>,   <span class="string">'Management'</span>,  <span class="number">4000</span>, <span class="number">42</span>),</span><br><span class="line">( <span class="number">4</span>,  <span class="string">'Jim'</span>,     <span class="string">'Production'</span>,  <span class="number">3700</span>, <span class="number">35</span>),</span><br><span class="line">( <span class="number">5</span>,  <span class="string">'Alice'</span>,   <span class="string">'Production'</span>,  <span class="number">3500</span>, <span class="number">24</span>),</span><br><span class="line">( <span class="number">6</span>,  <span class="string">'Michael'</span>, <span class="string">'Production'</span>,  <span class="number">3600</span>, <span class="number">28</span>),</span><br><span class="line">( <span class="number">7</span>,  <span class="string">'Tom'</span>,     <span class="string">'Production'</span>,  <span class="number">3800</span>, <span class="number">35</span>),</span><br><span class="line">( <span class="number">8</span>,  <span class="string">'Kevin'</span>,   <span class="string">'Production'</span>,  <span class="number">4000</span>, <span class="number">52</span>),</span><br><span class="line">( <span class="number">9</span>,  <span class="string">'Elvis'</span>,   <span class="string">'Service'</span>,     <span class="number">4100</span>, <span class="number">40</span>),</span><br><span class="line">(<span class="number">10</span>,  <span class="string">'Sophia'</span>,  <span class="string">'Sales'</span>,       <span class="number">4300</span>, <span class="number">36</span>),</span><br><span class="line">(<span class="number">11</span>,  <span class="string">'Samantha'</span>,<span class="string">'Sales'</span>,       <span class="number">4100</span>, <span class="number">38</span>);</span><br></pre></td></tr></table></figure><p>We can use the <code>RANK()</code> function to find out who earns the most within each department:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> dep_name, emp_name, salary</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">    dep_name, emp_name, salary</span><br><span class="line">    ,<span class="keyword">RANK</span>() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> dep_name <span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">DESC</span>) <span class="keyword">AS</span> rnk</span><br><span class="line">  <span class="keyword">FROM</span> t_employee</span><br><span class="line">) a</span><br><span class="line"><span class="keyword">WHERE</span> rnk = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>Normally when there’s duplicates, <code>RANK()</code> returns the same value for each row and <em>skip</em> the next sequence number. Use <code>DENSE_RANK()</code> if you want consecutive ranks.</p><h3 id="Cumulative-Distribution"><a href="#Cumulative-Distribution" class="headerlink" title="Cumulative Distribution"></a>Cumulative Distribution</h3><p>We can calculate the cumulative distribution of salaries among all departments. For example, salary <code>4000</code>‘s cumulative distribution is <code>0.55</code>, which means 55% people’s salaries are less or equal to <code>4000</code>. To calculate this, we first count the frequencies of every salary, and do a cumulative summing:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  salary</span><br><span class="line">  ,<span class="keyword">SUM</span>(cnt) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary)</span><br><span class="line">  / <span class="keyword">SUM</span>(cnt) <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary <span class="keyword">ROWS</span> <span class="keyword">BETWEEN</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">PRECEDING</span></span><br><span class="line">                   <span class="keyword">AND</span> <span class="keyword">UNBOUNDED</span> <span class="keyword">FOLLOWING</span>)</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span> salary, <span class="keyword">count</span>(*) <span class="keyword">AS</span> cnt</span><br><span class="line">  <span class="keyword">FROM</span> t_employee</span><br><span class="line">  <span class="keyword">GROUP</span> <span class="keyword">BY</span> salary</span><br><span class="line">) a;</span><br></pre></td></tr></table></figure><p>This can also be done with Hive’s <code>CUME_DIST()</code> window function. There’s another <code>PERCENT_RANK()</code> function, which computes the rank of the salary as percentage.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  salary</span><br><span class="line">  ,<span class="keyword">CUME_DIST</span>() <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary) <span class="keyword">AS</span> pct_cum</span><br><span class="line">  ,<span class="keyword">PERCENT_RANK</span>() <span class="keyword">OVER</span> (<span class="keyword">ORDER</span> <span class="keyword">BY</span> salary) <span class="keyword">AS</span> pct_rank</span><br><span class="line"><span class="keyword">FROM</span> t_employee;</span><br></pre></td></tr></table></figure><p><img src="/images/hive-window/employee-pct.png" alt="Cumulative Distribution"></p><h3 id="Clickstream-Sessionization"><a href="#Clickstream-Sessionization" class="headerlink" title="Clickstream Sessionization"></a>Clickstream Sessionization</h3><p>We can divide click events into different sessions by setting a <em>timeout</em>, in this case 30 minutes, and assign an id to each session:</p><p><img src="/images/hive-window/clickstream.png" alt="Click Stream"></p><p>First, in subquery <code>b</code>, we use the <code>LAG(col)</code> function to calculate the time difference between current row and previous row, and if it’s more than 30 minutes, a new session is marked. Then we do a cumulative sum of the <code>new_session</code> field so that each session will get an incremental sequence.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  ipaddress, clicktime</span><br><span class="line">  ,<span class="keyword">SUM</span>(<span class="keyword">IF</span>(new_session, <span class="number">1</span>, <span class="number">0</span>)) <span class="keyword">OVER</span> x + <span class="number">1</span> <span class="keyword">AS</span> sessionid</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">  <span class="keyword">SELECT</span></span><br><span class="line">    ipaddress, clicktime, ts</span><br><span class="line">    ,ts - LAG(ts) <span class="keyword">OVER</span> w &gt; <span class="number">1800</span> <span class="keyword">AS</span> new_session</span><br><span class="line">  <span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> *, <span class="keyword">UNIX_TIMESTAMP</span>(clicktime) <span class="keyword">AS</span> ts</span><br><span class="line">    <span class="keyword">FROM</span> t_clickstream</span><br><span class="line">  ) a</span><br><span class="line">  WINDOW w <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> ipaddress <span class="keyword">ORDER</span> <span class="keyword">BY</span> ts)</span><br><span class="line">) b</span><br><span class="line">WINDOW x <span class="keyword">AS</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> ipaddress <span class="keyword">ORDER</span> <span class="keyword">BY</span> ts);</span><br></pre></td></tr></table></figure><h2 id="Implementation-Detail"><a href="#Implementation-Detail" class="headerlink" title="Implementation Detail"></a>Implementation Detail</h2><p>Briefly speaking, window query consists of two steps: divide records into partitions, and evaluate window functions on each of them. The partitioning process is intuitive in map-reduce paradigm, since Hadoop will take care of the shuffling and sorting. However, ordinary UDAF can only return one row for each group, but in window query, there need to be a <em>table in, table out</em> contract. So the community introduced Partitioned Table Function (PTF) into Hive.</p><p>PTF, as the name suggests, works on partitions, and inputs / outputs a set of table rows. The following sequence diagram lists the major classes of PTF mechanism. <code>PTFOperator</code> reads data from sorted source and create input partitions; <code>WindowTableFunction</code> manages window frames, invokes window functions (UDAF), and writes the results to output partitions.</p><p><img src="/images/hive-window/window-sequence.png" alt="PTF Sequence Diagram"></p><p>The HIVE-896 ticket (<a href="https://issues.apache.org/jira/browse/HIVE-896" target="_blank" rel="noopener">link</a>) contains discussions on introducing analytical window functions into Hive, and this slide (<a href="https://www.slideshare.net/Hadoop_Summit/analytical-queries-with-hive" target="_blank" rel="noopener">link</a>), authored by one of the committers, explains how they implemented and merged PTF into Hive.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+WindowingAndAnalytics</a></li><li><a href="https://github.com/hbutani/SQLWindowing" target="_blank" rel="noopener">https://github.com/hbutani/SQLWindowing</a></li><li><a href="https://content.pivotal.io/blog/time-series-analysis-1-introduction-to-window-functions" target="_blank" rel="noopener">https://content.pivotal.io/blog/time-series-analysis-1-introduction-to-window-functions</a></li><li><a href="https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html" target="_blank" rel="noopener">https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SQL is one of the major tools of data analysis. It provides filtering, transforming and aggregation functionalities, and we can use it to process big volume of data with the help of Hive and Hadoop. However, legacy SQL does not support operations like grouped ranking and moving average, because the &lt;code&gt;GROUP BY&lt;/code&gt; clause can only produce one aggregation result for each group, but not for each row. Fortunately, with the new SQL standard coming, we can use the &lt;code&gt;WINDOW&lt;/code&gt; clause to compute aggregations on a set of rows and return the result for each row.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/hive-window/window-stock.png&quot; alt=&quot;Moving Average&quot;&gt;&lt;/p&gt;
&lt;p&gt;For instance, if we want to calculate the two-day moving average for each stock, we can write the following query:&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`date`&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ,&lt;span class=&quot;keyword&quot;&gt;AVG&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;OVER&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`w`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`mavg`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`t_stock`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WINDOW &lt;span class=&quot;string&quot;&gt;`w`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`date`&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;               &lt;span class=&quot;keyword&quot;&gt;ROWS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BETWEEN&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;PRECEDING&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;CURRENT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;OVER&lt;/code&gt;, &lt;code&gt;WINDOW&lt;/code&gt; and &lt;code&gt;ROWS BETWEEN AND&lt;/code&gt; are all newly added SQL keywords to support windowing operations. In this query, &lt;code&gt;PARTITION BY&lt;/code&gt; and &lt;code&gt;ORDER BY&lt;/code&gt; works like &lt;code&gt;GROUP BY&lt;/code&gt; and &lt;code&gt;ORDER BY&lt;/code&gt; after the &lt;code&gt;WHERE&lt;/code&gt; clause, except it doesn’t collapse the rows, but only divides them into non-overlapping partitions to work on. &lt;code&gt;ROWS BETWEEN AND&lt;/code&gt; here constructs a &lt;strong&gt;window frame&lt;/strong&gt;. In this case, each frame contains the previous row and current row. We’ll discuss more on frames later. Finally, &lt;code&gt;AVG&lt;/code&gt; is a window function that computes results on each frame. Note that &lt;code&gt;WINDOW&lt;/code&gt; clause can also be directly appended to window function:&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AVG&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;`close`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;OVER&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`stock`&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`mavg`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`t_stock`&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="analytics" scheme="http://shzhangji.com/tags/analytics/"/>
    
      <category term="sql" scheme="http://shzhangji.com/tags/sql/"/>
    
      <category term="hive" scheme="http://shzhangji.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>An Introduction to stream-lib The Stream Processing Utilities</title>
    <link href="http://shzhangji.com/blog/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/"/>
    <id>http://shzhangji.com/blog/2017/08/27/an-introduction-to-stream-lib-the-stream-processing-utilities/</id>
    <published>2017-08-27T02:57:24.000Z</published>
    <updated>2017-08-28T00:55:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>When processing a large amount of data, certain operations will cost a lot of time and space, such as counting the distinct values, or figuring out the 95th percentile of a sequence of numbers. But sometimes the accuracy is not that important. Maybe you just want a brief summary of the dataset, or it’s a monitoring system, where limited error rate is tolerable. There’re plenty of such algorithms that can trade accuracy with huge saves of time-space. What’s more, most of the data structures can be merged, making it possible to use in stream processing applications. <a href="https://github.com/addthis/stream-lib" target="_blank" rel="noopener"><code>stream-lib</code></a> is a collection of these algorithms. They are Java implementations based on academical research and papers. This artile will give a brief introduction to this utility library.</p><h2 id="Count-Cardinality-with-HyperLogLog"><a href="#Count-Cardinality-with-HyperLogLog" class="headerlink" title="Count Cardinality with HyperLogLog"></a>Count Cardinality with <code>HyperLogLog</code></h2><p>Unique visitors (UV) is the major metric of websites. We usually generate UUIDs for each user and track them by HTTP Cookie, or roughly use the IP address. We can use a <code>HashSet</code> to count the exact value of UV, but that takes a lot of memory. With <code>HyperLogLog</code>, an algorithm for the count-distinct problem, we are able to <a href="https://en.wikipedia.org/wiki/HyperLogLog" target="_blank" rel="noopener">estimate cardinalities of &gt; 10^9 with a typical accuracy of 2%, using 1.5 kB of memory</a>.</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.clearspring.analytics<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>stream<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ICardinality card = <span class="keyword">new</span> HyperLogLog(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i : <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span> &#125;) &#123;</span><br><span class="line">    card.offer(i);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(card.cardinality()); <span class="comment">// 4</span></span><br></pre></td></tr></table></figure><a id="more"></a><p><code>HyperLogLog</code> estimates cardinality by counting the leading zeros of each member’s binary value. If the maximum count is <code>n</code>, the cardinality is <code>2^n</code>. There’re some key points in this algorithm. First, members needs to be uniformly distributed, which we can use a hash function to achieve. <code>stream-lib</code> uses <a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">MurmurHash</a>, a simple, fast, and well distributed hash function, that is used in lots of hash-based lookup algorithms. Second, to decrease the variance of the result, set members are splitted into subsets, and the final result is the harmonic mean of all subsets’ cardinality. The integer argument that we passed to <code>HyperLogLog</code> constructor is the number of bits that it’ll use to split subsets, and the accuracy can be derived from this formula: <code>1.04/sqrt(2^log2m)</code>.</p><p><code>HyperLogLog</code> is an extension of <code>LogLog</code> algorithm, and the <code>HyperLogLogPlus</code> makes some more improvements. For instance, it uses a 64 bit hash function to remove the correction factor that adjusts hash collision; for small cardinality, it applies an empirical bias correction; and it also supports growing from a sparse data strucutre of registers (holding subsets) to a dense one. These algorithms are all included in <code>stream-lib</code></p><h2 id="Test-Membership-with-BloomFilter"><a href="#Test-Membership-with-BloomFilter" class="headerlink" title="Test Membership with BloomFilter"></a>Test Membership with <code>BloomFilter</code></h2><p><img src="/images/stream-lib/bloom-filter.jpg" alt="Bloom Filter"></p><p><code>BloomFilter</code> is a widely used data structure to test whether a set contains a certain member. The key is it will give false positive result, but never false negative. For example, Chrome maintains a malicious URLs in local storage, and it’s a bloom filter. When typing a new URL, if the filter says it’s not malicious, then it’s definitely not. But if the filter says it is in the set, then Chrome needs to contact the remote server for further confirmation.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Filter filter = <span class="keyword">new</span> BloomFilter(<span class="number">100</span>, <span class="number">0.01</span>);</span><br><span class="line">filter.add(<span class="string">"google.com"</span>);</span><br><span class="line">filter.add(<span class="string">"twitter.com"</span>);</span><br><span class="line">filter.add(<span class="string">"facebook.com"</span>);</span><br><span class="line">System.out.println(filter.isPresent(<span class="string">"bing.com"</span>)); <span class="comment">// false</span></span><br></pre></td></tr></table></figure><p>The contruction process of a bloom filter is faily simple:</p><ul><li>Create a bit array of <code>n</code> bits. In Java, we can use the <a href="https://docs.oracle.com/javase/8/docs/api/java/util/BitSet.html" target="_blank" rel="noopener"><code>BitSet</code></a> class.</li><li>Apply <code>k</code> number of hash functions to the incoming value, and set the corresponding bits to true.</li><li>When testing a membership, apply those hash functions and get the bits’ values:<ul><li>If every bit hits, the value might be in the set, with a False Positive Probability (FPP);</li><li>If not all bits hit, the value is definitely not in the set.</li></ul></li></ul><p>Again, those hash functions need to be uniformly distributed, and pairwise independent. Murmur hash meets the criteria. The FPP can be calculated by this formula: <code>(1-e^(-kn/m))^k</code>. This page (<a href="https://llimllib.github.io/bloomfilter-tutorial/" target="_blank" rel="noopener">link</a>) provides an online visualization of bloom filter. Other use cases are: anti-spam in email service, non-existent rows detection in Cassandra and HBase, and Squid also uses it to do <a href="https://wiki.squid-cache.org/SquidFaq/CacheDigests" target="_blank" rel="noopener">cache digest</a>.</p><h2 id="Top-k-Elements-with-CountMinSketch"><a href="#Top-k-Elements-with-CountMinSketch" class="headerlink" title="Top-k Elements with CountMinSketch"></a>Top-k Elements with <code>CountMinSketch</code></h2><p><img src="/images/stream-lib/count-min-sketch.png" alt="Count Min Sketch"></p><p><a href="https://stackoverflow.com/a/35356116/1030720" target="_blank" rel="noopener">Source</a></p><p><a href="https://en.wikipedia.org/wiki/Count%E2%80%93min_sketch" target="_blank" rel="noopener"><code>CountMinSketch</code></a> is a “sketching” algorithm that uses minimal space to track frequencies of incoming events. We can for example find out the top K tweets streaming out of Twitter, or count the most visited pages of a website. The “sketch” can be used to estimate these frequencies, with some loss of accuracy, of course.</p><p>The following snippet shows how to use <code>stream-lib</code> to get the top three animals in the <code>List</code>:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; animals;</span><br><span class="line">IFrequency freq = <span class="keyword">new</span> CountMinSketch(<span class="number">10</span>, <span class="number">5</span>, <span class="number">0</span>);</span><br><span class="line">Map&lt;String, Long&gt; top = Collections.emptyMap();</span><br><span class="line"><span class="keyword">for</span> (String animal : animals) &#123;</span><br><span class="line">    freq.add(animal, <span class="number">1</span>);</span><br><span class="line">    top = Stream.concat(top.keySet().stream(), Stream.of(animal)).distinct()</span><br><span class="line">              .map(a -&gt; <span class="keyword">new</span> SimpleEntry&lt;String, Long&gt;(a, freq.estimateCount(a)))</span><br><span class="line">              .sorted(Comparator.comparing(SimpleEntry&lt;String, Long&gt;::getValue).reversed())</span><br><span class="line">              .limit(<span class="number">3</span>)</span><br><span class="line">              .collect(Collectors.toMap(SimpleEntry::getKey, SimpleEntry::getValue));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(top); <span class="comment">// &#123;rabbit=25, bird=45, spider=35&#125;</span></span><br></pre></td></tr></table></figure><p><code>CountMinSketch#estimateCount</code> is a <em>point query</em> that asks for the count of an event. Since the “sketch” cannot remeber the exact events, we need to store them else where.</p><p>The data structure of count-min sketch is similar to bloom filter, instead of one bit array of <code>w</code> bits, it uses <code>d</code> number of them, so as to form a <code>d x w</code> matrix. When a value comes, it applies <code>d</code> number of hash functions, and update the corresponding bit in the matrix. These hash functions need only to be <a href="https://en.wikipedia.org/wiki/Pairwise_independence" target="_blank" rel="noopener">pairwise independent</a>, so <code>stream-lib</code> uses a simple yet fast <code>(a*x+b) mod p</code> formula. When doing <em>point query</em>, calculate the hash values, and the smallest value is the frequency.</p><p>The estimation error is <code>ε = e / w</code> while probability of bad estimate is <code>δ = 1 / e ^ d</code>. So we can increase <code>w</code> and / or <code>d</code> to improve the results. Original paper can be found in this <a href="https://web.archive.org/web/20060907232042/http://www.eecs.harvard.edu/~michaelm/CS222/countmin.pdf" target="_blank" rel="noopener">link</a>.</p><h2 id="Histogram-and-Quantile-with-T-Digest"><a href="#Histogram-and-Quantile-with-T-Digest" class="headerlink" title="Histogram and Quantile with T-Digest"></a>Histogram and Quantile with <code>T-Digest</code></h2><p><img src="/images/stream-lib/t-digest.png" alt="T-Digest"></p><p><a href="https://dataorigami.net/blogs/napkin-folding/19055451-percentile-and-quantile-estimation-of-big-data-the-t-digest" target="_blank" rel="noopener">Source</a></p><p>Median, 95th percentile are common use cases in descriptive statistics. Median for instance is less influenced by outliers than mean, but the calculation is not simple. One needs to track all data, sort them, and then get the final result. With <code>T-Digest</code>, we can agian generate a summarized distribution of the dataset and estimate the quantiles.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Random rand = <span class="keyword">new</span> Random();</span><br><span class="line">List&lt;Double&gt; data = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">TDigest digest = <span class="keyword">new</span> TDigest(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000000</span>; ++i) &#123;</span><br><span class="line">    <span class="keyword">double</span> d = rand.nextDouble();</span><br><span class="line">    data.add(d);</span><br><span class="line">    digest.add(d);</span><br><span class="line">&#125;</span><br><span class="line">Collections.sort(data);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">double</span> q : <span class="keyword">new</span> <span class="keyword">double</span>[] &#123; <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.9</span> &#125;) &#123;</span><br><span class="line">    System.out.println(String.format(<span class="string">"quantile=%.1f digest=%.4f exact=%.4f"</span>,</span><br><span class="line">            q, digest.quantile(q), data.get((<span class="keyword">int</span>) (data.size() * q))));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// quantile=0.1 digest=0.0998 exact=0.1003</span></span><br><span class="line"><span class="comment">// quantile=0.5 digest=0.5009 exact=0.5000</span></span><br><span class="line"><span class="comment">// quantile=0.9 digest=0.8994 exact=0.8998</span></span><br></pre></td></tr></table></figure><p>The <code>T-Digest</code> paper can be found in this <a href="https://raw.githubusercontent.com/tdunning/t-digest/master/docs/t-digest-paper/histo.pdf" target="_blank" rel="noopener">link</a>. In brief, it uses a variant of 1-dimensional k-means clustering mechanism, representing the empirical distribution by retaining the centroids of subsets. Besides, different <code>T-Digest</code> instances can be merged into a larger, more accurate instance, which can be used in parallel processing with ease.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>As we can see, most algorithms tries to save space and time with the cost of slight accuracy. By “sketching” the batch or streaming dataset, we can catch the “interesting” features and give very good estimation, especially when the dataset itself fullfills certain distribution. <code>stream-lib</code> and other opensourced projects certainly ease the process for us end users.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.javadoc.io/doc/com.clearspring.analytics/stream/2.9.5" target="_blank" rel="noopener">https://www.javadoc.io/doc/com.clearspring.analytics/stream/2.9.5</a></li><li><a href="http://www.addthis.com/blog/2011/03/29/new-open-source-stream-summarizing-java-library/" target="_blank" rel="noopener">http://www.addthis.com/blog/2011/03/29/new-open-source-stream-summarizing-java-library/</a></li><li><a href="https://www.mapr.com/blog/some-important-streaming-algorithms-you-should-know-about" target="_blank" rel="noopener">https://www.mapr.com/blog/some-important-streaming-algorithms-you-should-know-about</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When processing a large amount of data, certain operations will cost a lot of time and space, such as counting the distinct values, or figuring out the 95th percentile of a sequence of numbers. But sometimes the accuracy is not that important. Maybe you just want a brief summary of the dataset, or it’s a monitoring system, where limited error rate is tolerable. There’re plenty of such algorithms that can trade accuracy with huge saves of time-space. What’s more, most of the data structures can be merged, making it possible to use in stream processing applications. &lt;a href=&quot;https://github.com/addthis/stream-lib&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;stream-lib&lt;/code&gt;&lt;/a&gt; is a collection of these algorithms. They are Java implementations based on academical research and papers. This artile will give a brief introduction to this utility library.&lt;/p&gt;
&lt;h2 id=&quot;Count-Cardinality-with-HyperLogLog&quot;&gt;&lt;a href=&quot;#Count-Cardinality-with-HyperLogLog&quot; class=&quot;headerlink&quot; title=&quot;Count Cardinality with HyperLogLog&quot;&gt;&lt;/a&gt;Count Cardinality with &lt;code&gt;HyperLogLog&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;Unique visitors (UV) is the major metric of websites. We usually generate UUIDs for each user and track them by HTTP Cookie, or roughly use the IP address. We can use a &lt;code&gt;HashSet&lt;/code&gt; to count the exact value of UV, but that takes a lot of memory. With &lt;code&gt;HyperLogLog&lt;/code&gt;, an algorithm for the count-distinct problem, we are able to &lt;a href=&quot;https://en.wikipedia.org/wiki/HyperLogLog&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;estimate cardinalities of &amp;gt; 10^9 with a typical accuracy of 2%, using 1.5 kB of memory&lt;/a&gt;.&lt;/p&gt;
&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;com.clearspring.analytics&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;stream&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;2.9.5&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ICardinality card = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HyperLogLog(&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i : &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;[] &amp;#123; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; &amp;#125;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    card.offer(i);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;System.out.println(card.cardinality()); &lt;span class=&quot;comment&quot;&gt;// 4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/tags/java/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/tags/stream-processing/"/>
    
      <category term="algorithm" scheme="http://shzhangji.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Extract Data from MySQL with Binlog and Canal</title>
    <link href="http://shzhangji.com/blog/2017/08/12/extract-data-from-mysql-with-binlog-and-canal/"/>
    <id>http://shzhangji.com/blog/2017/08/12/extract-data-from-mysql-with-binlog-and-canal/</id>
    <published>2017-08-12T11:15:09.000Z</published>
    <updated>2017-08-14T00:37:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>Data extraction is the very first step of an ETL process. We need to load data from external data stores like RDMBS or logging file system, and then we can do cleaning, transformation and summary. In modern website stack, MySQL is the most widely used database, and it’s common to extract data from different instances and load into a central MySQL database, or directly into Hive. There’re several query-based techniques that we can use to do the extraction, including the popular open source software <a href="http://sqoop.apache.org/" target="_blank" rel="noopener">Sqoop</a>, but they are not meant for real-time data ingestion. Binlog, on the other hand, is a real-time data stream that is used to do replication between master and slave instances. With the help of Alibaba’s open sourced <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">Canal</a> project, we can easily utilize the binlog facility to do data extraction from MySQL database to various destinations.</p><p><img src="/images/canal.png" alt="Canal"></p><h2 id="Canal-Components"><a href="#Canal-Components" class="headerlink" title="Canal Components"></a>Canal Components</h2><p>In brief, Canal simulates itself to be a MySQL slave and dump binlog from master, parse it, and send to downstream sinks. Canal consists of two major components, namely Canal server and Canal client. A Canal server can connect to multiple MySQL instances, and maintains an event queue for each instance. Canal clients can then subscribe to theses queues and receive data changes. The following is a quick start guide to get Canal going.</p><a id="more"></a><h3 id="Configure-MySQL-Master"><a href="#Configure-MySQL-Master" class="headerlink" title="Configure MySQL Master"></a>Configure MySQL Master</h3><p>MySQL binlog is not enabled by default. Locate your <code>my.cnf</code> file and make these changes:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server-id = 1</span><br><span class="line">log_bin = /path/to/mysql-bin.log</span><br><span class="line">binlog_format = ROW</span><br></pre></td></tr></table></figure><p>Note that <code>binlog_format</code> must be <code>ROW</code>, becuase in <code>STATEMENT</code> or <code>MIXED</code> mode, only SQL statements will be logged and transferred (to save log size), but what we need is full data of the changed rows.</p><p>Slave connects to master via an dedicated account, which must have the global <code>REPLICATION</code> priviledges. We can use the <code>GRANT</code> statement to create the account:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, <span class="keyword">REPLICATION</span> <span class="keyword">SLAVE</span>, <span class="keyword">REPLICATION</span> <span class="keyword">CLIENT</span></span><br><span class="line"><span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'canal'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'canal'</span>;</span><br></pre></td></tr></table></figure><h3 id="Startup-Canal-Server"><a href="#Startup-Canal-Server" class="headerlink" title="Startup Canal Server"></a>Startup Canal Server</h3><p>Download Canal server from its GitHub Releases page (<a href="https://github.com/alibaba/canal/releases" target="_blank" rel="noopener">link</a>). The config files reside in <code>conf</code> directory. A typical layout is:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">canal.deployer/conf/canal.properties</span><br><span class="line">canal.deployer/conf/instanceA/instance.properties</span><br><span class="line">canal.deployer/conf/instanceB/instance.properties</span><br></pre></td></tr></table></figure><p>In <code>conf/canal.properties</code> there’s the main configuration. <code>canal.port</code> for example defines which port Canal server is listening. <code>instanceA/instance.properties</code> defines the MySQL instance that Canal server will draw binlog from. Important settings are:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># slaveId cannot collide with the server-id in my.cnf</span><br><span class="line">canal.instance.mysql.slaveId = 1234</span><br><span class="line">canal.instance.master.address = 127.0.0.1:3306</span><br><span class="line">canal.instance.dbUsername = canal</span><br><span class="line">canal.instance.dbPassword = canal</span><br><span class="line">canal.instance.connectionCharset = UTF-8</span><br><span class="line"># process all tables from all databases</span><br><span class="line">canal.instance.filter.regex = .*\\..*</span><br></pre></td></tr></table></figure><p>Start the server by <code>sh bin/startup.sh</code>, and you’ll see the following output in <code>logs/example/example.log</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Loading properties file from class path resource [canal.properties]</span><br><span class="line">Loading properties file from class path resource [example/instance.properties]</span><br><span class="line">start CannalInstance for 1-example</span><br><span class="line">[destination = example , address = /127.0.0.1:3306 , EventParser] prepare to find start position just show master status</span><br></pre></td></tr></table></figure><h3 id="Write-Canal-Client"><a href="#Write-Canal-Client" class="headerlink" title="Write Canal Client"></a>Write Canal Client</h3><p>To consume update events from Canal server, we can create a Canal client in our application, specify the instance and tables we’re interested in, and start polling.</p><p>First, add <code>com.alibaba.otter:canal.client</code> dependency to your <code>pom.xml</code>, and construct a Canal client:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CanalConnector connector = CanalConnectors.newSingleConnector(</span><br><span class="line">        <span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">11111</span>), <span class="string">"example"</span>, <span class="string">""</span>, <span class="string">""</span>);</span><br><span class="line"></span><br><span class="line">connector.connect();</span><br><span class="line">connector.subscribe(<span class="string">".*\\..*"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    Message message = connector.getWithoutAck(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">long</span> batchId = message.getId();</span><br><span class="line">    <span class="keyword">if</span> (batchId == -<span class="number">1</span> || message.getEntries().isEmpty()) &#123;</span><br><span class="line">        Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        printEntries(message.getEntries());</span><br><span class="line">        connector.ack(batchId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The code is quite similar to consuming from a message queue. The update events are sent in batches, and you can acknowledge every batch after being properly processed.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printEntries</span></span><br><span class="line">RowChange rowChange = RowChange.parseFrom(entry.getStoreValue());</span><br><span class="line"><span class="keyword">for</span> (RowData rowData : rowChange.getRowDatasList()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (rowChange.getEventType() == EventType.INSERT) &#123;</span><br><span class="line">      printColumns(rowData.getAfterCollumnList());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Every <code>Entry</code> in a message represents a set of row changes with the same event type, e.g. INSERT, UPDATE, or DELETE. For each row, we can get the column data like this:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printColumns</span></span><br><span class="line">String line = columns.stream()</span><br><span class="line">        .map(column -&gt; column.getName() + <span class="string">"="</span> + column.getValue())</span><br><span class="line">        .collect(Collectors.joining(<span class="string">","</span>));</span><br><span class="line">System.out.println(line);</span><br></pre></td></tr></table></figure><p>Full example can be found on GitHub (<a href="https://github.com/jizhang/java-sandbox/blob/blog-canal/src/main/java/com/shzhangji/javasandbox/canal/SimpleClient.java" target="_blank" rel="noopener">link</a>).</p><h2 id="Load-into-Data-Warehouse"><a href="#Load-into-Data-Warehouse" class="headerlink" title="Load into Data Warehouse"></a>Load into Data Warehouse</h2><h3 id="RDBMS-with-Batch-Insert"><a href="#RDBMS-with-Batch-Insert" class="headerlink" title="RDBMS with Batch Insert"></a>RDBMS with Batch Insert</h3><p>For DB based data warehouse, we can directly use the <code>REPLACE</code> statement and let the database deduplicates rows by primary key. One concern is the instertion performance, so it’s often necessary to cache the data for a while and do a batch insertion, like:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">REPLACE</span> <span class="keyword">INTO</span> <span class="string">`user`</span> (<span class="string">`id`</span>, <span class="string">`name`</span>, <span class="string">`age`</span>, <span class="string">`updated`</span>) <span class="keyword">VALUES</span></span><br><span class="line">(<span class="number">1</span>, <span class="string">'Jerry'</span>, <span class="number">30</span>, <span class="string">'2017-08-12 16:00:00'</span>),</span><br><span class="line">(<span class="number">2</span>, <span class="string">'Mary'</span>, <span class="number">28</span>, <span class="string">'2017-08-12 17:00:00'</span>),</span><br><span class="line">(<span class="number">3</span>, <span class="string">'Tom'</span>, <span class="number">36</span>, <span class="string">'2017-08-12 18:00:00'</span>);</span><br></pre></td></tr></table></figure><p>Another approach is to write the extracted data into a delimited text file, then execute a <code>LOAD DATA</code> statement. These files can also be used to import data into Hive. But for both approaches, make sure you escape the string columns properly, so as to avoid insertion errors.</p><h3 id="Hive-based-Warehouse"><a href="#Hive-based-Warehouse" class="headerlink" title="Hive-based Warehouse"></a>Hive-based Warehouse</h3><p>Hive tables are stored on HDFS, which is an append-only file system, so it takes efforts to update data in a previously loaded table. One can use a JOIN-based approach, Hive transaction, or switch to HBase.</p><p>Data can be categorized into base and delta. For example, yesterday’s <code>user</code> table is the base, while today’s updated rows are the delta. Using a <code>FULL OUTER JOIN</code> we can generate the latest snapshot:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  <span class="keyword">COALESCE</span>(b.<span class="string">`id`</span>, a.<span class="string">`id`</span>) <span class="keyword">AS</span> <span class="string">`id`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`name`</span>, a.<span class="string">`name`</span>) <span class="keyword">AS</span> <span class="string">`name`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`age`</span>, a.<span class="string">`age`</span>) <span class="keyword">AS</span> <span class="string">`age`</span></span><br><span class="line">  ,<span class="keyword">COALESCE</span>(b.<span class="string">`updated`</span>, a.<span class="string">`updated`</span>) <span class="keyword">AS</span> <span class="string">`updated`</span></span><br><span class="line"><span class="keyword">FROM</span> dw_stage.<span class="string">`user`</span> a</span><br><span class="line"><span class="keyword">FULL</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> (</span><br><span class="line">  <span class="comment">-- deduplicate by selecting the latest record</span></span><br><span class="line">  <span class="keyword">SELECT</span> <span class="string">`id`</span>, <span class="string">`name`</span>, <span class="string">`age`</span>, <span class="string">`updated`</span></span><br><span class="line">  <span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> *, ROW_NUMBER() <span class="keyword">OVER</span> (<span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="string">`id`</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="string">`updated`</span> <span class="keyword">DESC</span>) <span class="keyword">AS</span> <span class="string">`n`</span></span><br><span class="line">    <span class="keyword">FROM</span> dw_stage.<span class="string">`user_delta`</span></span><br><span class="line">  ) b</span><br><span class="line">  <span class="keyword">WHERE</span> <span class="string">`n`</span> = <span class="number">1</span></span><br><span class="line">) b</span><br><span class="line"><span class="keyword">ON</span> a.<span class="string">`id`</span> = b.<span class="string">`id`</span>;</span><br></pre></td></tr></table></figure><p>Hive 0.13 introduces transaction and ACID table, 0.14 brings us the <code>INSERT</code>, <code>UPDATE</code> and <code>DELETE</code> statements, and Hive 2.0.0 provides a new <a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog+Streaming+Mutation+API" target="_blank" rel="noopener">Streaming Mutation API</a> that can be used to submit insert/update/delete transactions to Hive tables programmatically. Currently, ACID tables must use ORC file format, and be bucketed by primiary key. Hive will store the mutative operations in delta files. When reading from this table, <code>OrcInputFormat</code> will figure out which record is the latest. The official sample code can be found in the test suite (<a href="https://github.com/apache/hive/blob/master/hcatalog/streaming/src/test/org/apache/hive/hcatalog/streaming/mutate/ExampleUseCase.java" target="_blank" rel="noopener">link</a>).</p><p>And the final approach is to use HBase, which is a key-value store built on HDFS, making it perfect for data updates. Its table can also be used by MapReduce jobs, or you can create an external Hive table that points directly to HBase. More information can be found on the <a href="http://hbase.apache.org/" target="_blank" rel="noopener">official website</a>.</p><h2 id="Initialize-Target-Table"><a href="#Initialize-Target-Table" class="headerlink" title="Initialize Target Table"></a>Initialize Target Table</h2><p>Data extraction is usually on-demand, so there may be already historical data in the source table. One obvious approach is dumping the full table manually and load into destination. Or we can reuse the Canal facility, notify the client to query data from source and do the updates.</p><p>First, we create a helper table in the source database:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`retl_buffer`</span> (</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">BIGINT</span> AUTO_INCREMENT PRIMARY <span class="keyword">KEY</span></span><br><span class="line">  ,table_name <span class="built_in">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">  ,pk_value <span class="built_in">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>To reload all records in <code>user</code> table:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`retl_buffer`</span> (<span class="string">`table_name`</span>, <span class="string">`pk_value`</span>)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">'user'</span>, <span class="string">`id`</span> <span class="keyword">FROM</span> <span class="string">`user`</span>;</span><br></pre></td></tr></table></figure><p>When Canal client receives the <code>RowChange</code> of <code>retl_buffer</code> table, it can extract the table name and primary key value from the record, query the source database, and write to the destination.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="string">"retl_buffer"</span>.equals(entry.getHeader().getTableName())) &#123;</span><br><span class="line">    String tableName = rowData.getAfterColumns(<span class="number">1</span>).getValue();</span><br><span class="line">    String pkValue = rowData.getAfterColumns(<span class="number">2</span>).getValue();</span><br><span class="line">    System.out.println(<span class="string">"SELECT * FROM "</span> + tableName + <span class="string">" WHERE id = "</span> + pkValue);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This approach is included in another Alibaba’s project <a href="https://github.com/alibaba/otter/wiki/Manager%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%87%AA-%E7%94%B1-%E9%97%A8" target="_blank" rel="noopener">Otter</a>.</p><h2 id="Canal-High-Availability"><a href="#Canal-High-Availability" class="headerlink" title="Canal High Availability"></a>Canal High Availability</h2><ul><li>Canal instances can be supplied with a standby MySQL source, typically in a Master-Master HA scenario. Make sure you turn on the <code>log_slave_updates</code> option in both MySQL instances. Canal uses a dedicated heartbeat check, i.e. update a row periodically to check if current source is alive.</li><li>Canal server itself also supports HA. You’ll need a Zookeeper quorum to enable this feature. Clients will get the current server location from Zookeeper, and the server will record the last binlog offset that has been consumed.</li></ul><p>For more information, please checkout the <a href="https://github.com/alibaba/canal/wiki/AdminGuide" target="_blank" rel="noopener">AdminGuide</a>.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://github.com/alibaba/canal/wiki" target="_blank" rel="noopener">https://github.com/alibaba/canal/wiki</a> (in Chinese)</li><li><a href="https://github.com/alibaba/otter/wiki" target="_blank" rel="noopener">https://github.com/alibaba/otter/wiki</a> (in Chinese)</li><li><a href="https://www.phdata.io/4-strategies-for-updating-hive-tables/" target="_blank" rel="noopener">https://www.phdata.io/4-strategies-for-updating-hive-tables/</a></li><li><a href="https://hortonworks.com/blog/four-step-strategy-incremental-updates-hive/" target="_blank" rel="noopener">https://hortonworks.com/blog/four-step-strategy-incremental-updates-hive/</a></li><li><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Data extraction is the very first step of an ETL process. We need to load data from external data stores like RDMBS or logging file system, and then we can do cleaning, transformation and summary. In modern website stack, MySQL is the most widely used database, and it’s common to extract data from different instances and load into a central MySQL database, or directly into Hive. There’re several query-based techniques that we can use to do the extraction, including the popular open source software &lt;a href=&quot;http://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Sqoop&lt;/a&gt;, but they are not meant for real-time data ingestion. Binlog, on the other hand, is a real-time data stream that is used to do replication between master and slave instances. With the help of Alibaba’s open sourced &lt;a href=&quot;https://github.com/alibaba/canal&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Canal&lt;/a&gt; project, we can easily utilize the binlog facility to do data extraction from MySQL database to various destinations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/canal.png&quot; alt=&quot;Canal&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Canal-Components&quot;&gt;&lt;a href=&quot;#Canal-Components&quot; class=&quot;headerlink&quot; title=&quot;Canal Components&quot;&gt;&lt;/a&gt;Canal Components&lt;/h2&gt;&lt;p&gt;In brief, Canal simulates itself to be a MySQL slave and dump binlog from master, parse it, and send to downstream sinks. Canal consists of two major components, namely Canal server and Canal client. A Canal server can connect to multiple MySQL instances, and maintains an event queue for each instance. Canal clients can then subscribe to theses queues and receive data changes. The following is a quick start guide to get Canal going.&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/tags/java/"/>
    
      <category term="etl" scheme="http://shzhangji.com/tags/etl/"/>
    
      <category term="mysql" scheme="http://shzhangji.com/tags/mysql/"/>
    
      <category term="canal" scheme="http://shzhangji.com/tags/canal/"/>
    
  </entry>
  
  <entry>
    <title>How to Extract Event Time in Apache Flume</title>
    <link href="http://shzhangji.com/blog/2017/08/05/how-to-extract-event-time-in-apache-flume/"/>
    <id>http://shzhangji.com/blog/2017/08/05/how-to-extract-event-time-in-apache-flume/</id>
    <published>2017-08-05T07:10:47.000Z</published>
    <updated>2017-08-07T05:36:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>Extracting data from upstream message queues is a common task in ETL. In a Hadoop based data warehouse, we usually use Flume to import event logs from Kafka into HDFS, and then run MapReduce jobs agaist it, or create Hive external tables partitioned by time. One of the keys of this process is to extract the event time from the logs, since real-time data can have time lags, or your system is temporarily offline and need to perform a catch-up. Flume provides various facilities to help us do this job easily.</p><p><img src="/images/flume.png" alt="Apache Flume"></p><h2 id="HDFS-Sink-and-Timestamp-Header"><a href="#HDFS-Sink-and-Timestamp-Header" class="headerlink" title="HDFS Sink and Timestamp Header"></a>HDFS Sink and Timestamp Header</h2><p>Here is a simple HDFS Sink config:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a1.sinks = k1</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = /user/flume/ds_alog/dt=%Y%m%d</span><br></pre></td></tr></table></figure><p><code>%Y%m%d</code> is the placeholders supported by this sink. It will use the milliseconds in <code>timestamp</code> header to replace them. Also, HDFS Sink provides <code>hdfs.useLocalTimeStamp</code> option so that it’ll use the local time to replace these placeholders, but this is not what we intend.</p><p>Another sink we could use is the Hive Sink, which directly communicates with Hive metastore and loads data into HDFS as Hive table. It supports both delimited text and JSON serializers, and also requires a <code>timestamp</code> header. But we don’t choose it for the following reasons:</p><ul><li>It doesn’t support regular expression serializer, so we cannot extract columns from arbitrary data format like access logs;</li><li>The columns to be extracted are defined in Hive metastore. Say the upstream events add some new keys in JSON, they will be dropped until Hive table definition is updated. As in data warehouse, it’s better to preserve the original source data for a period of time.</li></ul><a id="more"></a><h2 id="Regex-Extractor-Interceptor"><a href="#Regex-Extractor-Interceptor" class="headerlink" title="Regex Extractor Interceptor"></a>Regex Extractor Interceptor</h2><p>Flume has a mechanism called Interceptor, i.e. some optionally chained operations appended to Source, so as to perform various yet primitive transformation. For instance, the <code>TimestampInterceptor</code> is to add current local timestamp to the event header. In this section, I’ll demonstrate how to extract event time from access logs and JSON serialized logs with the help of interceptors.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.123 [2017-06-27 09:08:00] GET /</span><br><span class="line">0.234 [2017-06-27 09:08:01] GET /</span><br></pre></td></tr></table></figure><p><a href="http://flume.apache.org/FlumeUserGuide.html#regex-extractor-interceptor" target="_blank" rel="noopener"><code>RegexExtractorInterceptor</code></a> can be used to extract values based on regular expressions. Here’s the config:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1</span><br><span class="line">a1.sources.r1.interceptors.i1.type = regex_extractor</span><br><span class="line">a1.sources.r1.interceptors.i1.regex = \\[(.*?)\\]</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers = s1</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.type = org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.name = timestamp</span><br><span class="line">a1.sources.r1.interceptors.i1.serializers.s1.pattern = yyyy-MM-dd HH:mm:ss</span><br></pre></td></tr></table></figure><p>It searches the string with pattern <code>\[(.*?)\]</code>, capture the first sub-pattern as <code>s1</code>, then parse it as a datetime string, and finally store it into headers with the name <code>timestamp</code>.</p><h3 id="Search-And-Replace-Interceptor"><a href="#Search-And-Replace-Interceptor" class="headerlink" title="Search And Replace Interceptor"></a>Search And Replace Interceptor</h3><p>For JSON strings:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"actionTime"</span>:<span class="number">1498525680.023</span>,<span class="attr">"actionType"</span>:<span class="string">"pv"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"actionTime"</span>:<span class="number">1498525681.349</span>,<span class="attr">"actionType"</span>:<span class="string">"pv"</span>&#125;</span><br></pre></td></tr></table></figure><p>We can also extract <code>actionTime</code> with a regular expression, but note that HDFS Sink requires the timestamp in milliseconds, so we have to first convert the timestamp with <code>SearchAndReplaceInterceptor</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.interceptors = i1 i2</span><br><span class="line">a1.sources.r1.interceptors.i1.type = search_replace</span><br><span class="line">a1.sources.r1.interceptors.i1.searchPattern = \&quot;actionTime\&quot;:(\\d+)\\.(\\d+)</span><br><span class="line">a1.sources.r1.interceptors.i1.replaceString = \&quot;actionTime\&quot;:$1$2</span><br><span class="line">a1.sources.r1.interceptors.i2.type = regex_extractor</span><br><span class="line">a1.sources.r1.interceptors.i2.regex = \&quot;actionTime\&quot;:(\\d+)</span><br><span class="line">a1.sources.r1.interceptors.i2.serializers = s1</span><br><span class="line">a1.sources.r1.interceptors.i2.serializers.s1.name = timestamp</span><br></pre></td></tr></table></figure><p>There’re two chained interceptors, first one replaces <code>1498525680.023</code> with <code>1498525680023</code> and second extracts <code>actionTime</code> right into headers.</p><h3 id="Custom-Interceptor"><a href="#Custom-Interceptor" class="headerlink" title="Custom Interceptor"></a>Custom Interceptor</h3><p>It’s also possible to write your own interceptor, thus do the extraction and conversion in one step. Your interceptor should implements <code>org.apache.flume.interceptor.Interceptor</code> and then do the job in <code>intercept</code> method. The source code and unit test can be found on GitHub (<a href="https://github.com/jizhang/java-sandbox/blob/blog-flume/src/main/java/com/shzhangji/javasandbox/flume/ActionTimeInterceptor.java" target="_blank" rel="noopener">link</a>). Please add <code>flume-ng-core</code> to your project dependencies.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ActionTimeInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> ObjectMapper mapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            JsonNode node = mapper.readTree(<span class="keyword">new</span> ByteArrayInputStream(event.getBody()));</span><br><span class="line">            <span class="keyword">long</span> timestamp = (<span class="keyword">long</span>) (node.get(<span class="string">"actionTime"</span>).getDoubleValue() * <span class="number">1000</span>);</span><br><span class="line">            event.getHeaders().put(<span class="string">"timestamp"</span>, Long.toString(timestamp));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="comment">// no-op</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Use-Kafka-Channel-Directly"><a href="#Use-Kafka-Channel-Directly" class="headerlink" title="Use Kafka Channel Directly"></a>Use Kafka Channel Directly</h2><p>When the upstream is Kafka, and you have control of the message format, you can further eliminate the Source and directly pass data from Kafka to HDFS. The trick is to write messages in <code>AvroFlumeEvent</code> format, so that <a href="http://flume.apache.org/FlumeUserGuide.html#kafka-channel" target="_blank" rel="noopener">Kafka Channel</a> can deserialize them and use the <code>timestamp</code> header within. Otherwise, Kafka channel will parse messages as plain text with no headers, and HDFS sink will complain missing <code>timestamp</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// construct an AvroFlumeEvent, this class can be found in flume-ng-sdk artifact</span></span><br><span class="line">Map&lt;CharSequence, CharSequence&gt; headers = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">headers.put(<span class="string">"timestamp"</span>, <span class="string">"1498525680023"</span>);</span><br><span class="line">String body = <span class="string">"some message"</span>;</span><br><span class="line">AvroFlumeEvent event = <span class="keyword">new</span> AvroFlumeEvent(headers, ByteBuffer.wrap(body.getBytes()));</span><br><span class="line"></span><br><span class="line"><span class="comment">// serialize event with Avro encoder</span></span><br><span class="line">ByteArrayOutputStream out = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">BinaryEncoder encoder = EncoderFactory.get().directBinaryEncoder(out, <span class="keyword">null</span>);</span><br><span class="line">SpecificDatumWriter&lt;AvroFlumeEvent&gt; writer = <span class="keyword">new</span> SpecificDatumWriter&lt;&gt;(AvroFlumeEvent.class);</span><br><span class="line">writer.write(event, encoder);</span><br><span class="line">encoder.flush();</span><br><span class="line"></span><br><span class="line"><span class="comment">// send bytes to Kafka</span></span><br><span class="line">producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, <span class="keyword">byte</span>[]&gt;(<span class="string">"alog"</span>, out.toByteArray()));</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="noopener">http://flume.apache.org/FlumeUserGuide.html</a></li><li><a href="https://github.com/apache/flume" target="_blank" rel="noopener">https://github.com/apache/flume</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Extracting data from upstream message queues is a common task in ETL. In a Hadoop based data warehouse, we usually use Flume to import event logs from Kafka into HDFS, and then run MapReduce jobs agaist it, or create Hive external tables partitioned by time. One of the keys of this process is to extract the event time from the logs, since real-time data can have time lags, or your system is temporarily offline and need to perform a catch-up. Flume provides various facilities to help us do this job easily.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/flume.png&quot; alt=&quot;Apache Flume&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;HDFS-Sink-and-Timestamp-Header&quot;&gt;&lt;a href=&quot;#HDFS-Sink-and-Timestamp-Header&quot; class=&quot;headerlink&quot; title=&quot;HDFS Sink and Timestamp Header&quot;&gt;&lt;/a&gt;HDFS Sink and Timestamp Header&lt;/h2&gt;&lt;p&gt;Here is a simple HDFS Sink config:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks = k1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks.k1.type = hdfs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;a1.sinks.k1.hdfs.path = /user/flume/ds_alog/dt=%Y%m%d&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;%Y%m%d&lt;/code&gt; is the placeholders supported by this sink. It will use the milliseconds in &lt;code&gt;timestamp&lt;/code&gt; header to replace them. Also, HDFS Sink provides &lt;code&gt;hdfs.useLocalTimeStamp&lt;/code&gt; option so that it’ll use the local time to replace these placeholders, but this is not what we intend.&lt;/p&gt;
&lt;p&gt;Another sink we could use is the Hive Sink, which directly communicates with Hive metastore and loads data into HDFS as Hive table. It supports both delimited text and JSON serializers, and also requires a &lt;code&gt;timestamp&lt;/code&gt; header. But we don’t choose it for the following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It doesn’t support regular expression serializer, so we cannot extract columns from arbitrary data format like access logs;&lt;/li&gt;
&lt;li&gt;The columns to be extracted are defined in Hive metastore. Say the upstream events add some new keys in JSON, they will be dropped until Hive table definition is updated. As in data warehouse, it’s better to preserve the original source data for a period of time.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="java" scheme="http://shzhangji.com/tags/java/"/>
    
      <category term="flume" scheme="http://shzhangji.com/tags/flume/"/>
    
      <category term="etl" scheme="http://shzhangji.com/tags/etl/"/>
    
  </entry>
  
  <entry>
    <title>How to Achieve Exactly-Once Semantics in Spark Streaming</title>
    <link href="http://shzhangji.com/blog/2017/07/31/how-to-achieve-exactly-once-semantics-in-spark-streaming/"/>
    <id>http://shzhangji.com/blog/2017/07/31/how-to-achieve-exactly-once-semantics-in-spark-streaming/</id>
    <published>2017-07-31T14:56:07.000Z</published>
    <updated>2017-08-01T00:56:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>Exactly-once semantics is one of the advanced topics of stream processing. To process every message once and only once, in spite of system or network failure, not only the stream processing framework needs to provide such functionality, but also the message delivery system, the output data store, as well as how we implement the processing procedure, altogether can we ensure the exactly-once semantics. In this article, I’ll demonstrate how to use Spark Streaming, with Kafka as data source and MySQL the output storage, to achieve exactly-once stream processing.</p><p><img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="Spark Streaming"></p><h2 id="An-Introductory-Example"><a href="#An-Introductory-Example" class="headerlink" title="An Introductory Example"></a>An Introductory Example</h2><p>First let’s implement a simple yet complete stream processing application that receive access logs from Kafka, parse and count the errors, then write the errors per minute metric into MySQL database.</p><p>Sample access logs:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-07-30 14:09:08 ERROR some message</span><br><span class="line">2017-07-30 14:09:20 INFO  some message</span><br><span class="line">2017-07-30 14:10:50 ERROR some message</span><br></pre></td></tr></table></figure><p>Output table, where <code>log_time</code> should be truncated to minutes:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> error_log (</span><br><span class="line">  log_time datetime primary <span class="keyword">key</span>,</span><br><span class="line">  log_count <span class="built_in">int</span> <span class="keyword">not</span> <span class="literal">null</span> <span class="keyword">default</span> <span class="number">0</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><a id="more"></a><p>Scala projects are usually managed by <code>sbt</code> tool. Let’s add the following dependencies into <code>build.sbt</code> file. We’re using Spark 2.2 with Kafka 0.10. The choice of database library is ScalikeJDBC 3.0.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scalaVersion := <span class="string">"2.11.11"</span></span><br><span class="line"></span><br><span class="line">libraryDependencies ++= <span class="type">Seq</span>(</span><br><span class="line">  <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-streaming"</span> % <span class="string">"2.2.0"</span> % <span class="string">"provided"</span>,</span><br><span class="line">  <span class="string">"org.apache.spark"</span> %% <span class="string">"spark-streaming-kafka-0-10"</span> % <span class="string">"2.2.0"</span>,</span><br><span class="line">  <span class="string">"org.scalikejdbc"</span> %% <span class="string">"scalikejdbc"</span> % <span class="string">"3.0.1"</span>,</span><br><span class="line">  <span class="string">"mysql"</span> % <span class="string">"mysql-connector-java"</span> % <span class="string">"5.1.43"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>The complete code can be found on GitHub (<a href="https://github.com/jizhang/spark-sandbox/blob/master/src/main/scala/ExactlyOnce.scala" target="_blank" rel="noopener">link</a>), so here only shows the major parts of the application:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// initialize database connection</span></span><br><span class="line"><span class="type">ConnectionPool</span>.singleton(<span class="string">"jdbc:mysql://localhost:3306/spark"</span>, <span class="string">"root"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// create Spark streaming context</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ExactlyOnce"</span>).setIfMissing(<span class="string">"spark.master"</span>, <span class="string">"local[2]"</span>)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// create Kafka DStream with Direct API</span></span><br><span class="line"><span class="keyword">val</span> messages = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>](ssc,</span><br><span class="line">   <span class="type">LocationStrategies</span>.<span class="type">PreferConsistent</span>,</span><br><span class="line">   <span class="type">ConsumerStrategies</span>.<span class="type">Subscribe</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="type">Seq</span>(<span class="string">"alog"</span>), kafkaParams))</span><br><span class="line"></span><br><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="comment">// do transformation</span></span><br><span class="line">  <span class="keyword">val</span> result = rdd.map(_.value)</span><br><span class="line">    .flatMap(parseLog) <span class="comment">// utility function to parse log line into case class</span></span><br><span class="line">    .filter(_.level == <span class="string">"ERROR"</span>)</span><br><span class="line">    .map(log =&gt; log.time.truncatedTo(<span class="type">ChronoUnit</span>.<span class="type">MINUTES</span>) -&gt; <span class="number">1</span>)</span><br><span class="line">    .reduceByKey(_ + _)</span><br><span class="line">    .collect()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// store result into database</span></span><br><span class="line">  <span class="type">DB</span>.autoCommit &#123; <span class="keyword">implicit</span> session =&gt;</span><br><span class="line">    result.foreach &#123; <span class="keyword">case</span> (time, count) =&gt;</span><br><span class="line">      <span class="string">sql""</span><span class="string">"</span></span><br><span class="line"><span class="string">      insert into error_log (log_time, log_count)</span></span><br><span class="line"><span class="string">      value ($&#123;time&#125;, $&#123;count&#125;)</span></span><br><span class="line"><span class="string">      on duplicate key update log_count = log_count + values(log_count)</span></span><br><span class="line"><span class="string">      "</span><span class="string">""</span>.update.apply()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Stream-Processing-Semantics"><a href="#Stream-Processing-Semantics" class="headerlink" title="Stream Processing Semantics"></a>Stream Processing Semantics</h2><p>There’re three semantics in stream processing, namely at-most-once, at-least-once, and exactly-once. In a typical Spark Streaming application, there’re three processing phases: receive data, do transformation, and push outputs. Each phase takes different efforts to achieve different semantics.</p><p>For <strong>receiving data</strong>, it largely depends on the data source. For instance, reading files from a fault-tolerant file system like HDFS, gives us exactly-once semantics. For upstream queues that support acknowledgement, e.g. RabbitMQ, we can combine it with Spark’s write ahead logs to achieve at-least-once semantics. For unreliable receivers like <code>socketTextStream</code>, there might be data loss due to worker/driver failure and gives us undefined semantics. Kafka, on the other hand, is offset based, and its direct API can give us exactly-once semantics.</p><p>When <strong>transforming data</strong> with Spark’s RDD, we automatically get exactly-once semantics, for RDD is itself immutable, fault-tolerant and deterministically re-computable. As long as the source data is available, and there’s no side effects during transformation, the result will always be the same.</p><p><strong>Output operation</strong> by default has at-least-once semantics. The <code>foreachRDD</code> function will execute more than once if there’s worker failure, thus writing same data to external storage multiple times. There’re two approaches to solve this issue, idempotent updates, and transactional updates. They are further discussed in the following sections.</p><h2 id="Exactly-once-with-Idempotent-Writes"><a href="#Exactly-once-with-Idempotent-Writes" class="headerlink" title="Exactly-once with Idempotent Writes"></a>Exactly-once with Idempotent Writes</h2><p>If multiple writes produce the same data, then this output operation is idempotent. <code>saveAsTextFile</code> is a typical idempotent update; messages with unique keys can be written to database without duplication. This approach will give us the equivalent exactly-once semantics. Note though it’s usually for map-only procedures, and it requires some setup on Kafka DStream.</p><ul><li>Set <code>enable.auto.commit</code> to <code>false</code>. By default, Kafka DStream will commit the consumer offsets right after it receives the data. We want to postpone this action unitl the batch is fully processed.</li><li>Turn on Spark Streaming’s checkpointing to store Kafka offsets. But if the application code changes, checkpointed data is not reusable. This leads to a second option:</li><li>Commit Kafka offsets after outputs. Kafka provides a <code>commitAsync</code> API, and the <code>HasOffsetRanges</code> class can be used to extract offsets from the initial RDD:</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  rdd.foreachPartition &#123; iter =&gt;</span><br><span class="line">    <span class="comment">// output to database</span></span><br><span class="line">  &#125;</span><br><span class="line">  messages.asInstanceOf[<span class="type">CanCommitOffsets</span>].commitAsync(offsetRanges)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Exactly-once-with-Transactional-Writes"><a href="#Exactly-once-with-Transactional-Writes" class="headerlink" title="Exactly-once with Transactional Writes"></a>Exactly-once with Transactional Writes</h2><p>Transactional updates require a unique identifier. One can generate from batch time, partition id, or Kafka offsets, and then write the result along with the identifier into external storage within a single transaction. This atomic operation gives us exactly-once semantics, and can be applied to both map-only and aggregation procedures.</p><p>Usually writing to database should happen in <code>foreachPartition</code>, i.e. in worker nodes. It is true for map-only procedure, because Kafka RDD’s partition is correspondent to Kafka partition, so we can extract each partition’s offset like this:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  rdd.foreachPartition &#123; iter =&gt;</span><br><span class="line">    <span class="keyword">val</span> offsetRange = offsetRanges(<span class="type">TaskContext</span>.get.partitionId)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>But for shuffled operations like the error log count example, we need to first collect the result back into driver and then perform the transaction.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">messages.foreachRDD &#123; rdd =&gt;</span><br><span class="line">  <span class="keyword">val</span> offsetRanges = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line">  <span class="keyword">val</span> result = processLogs(rdd).collect() <span class="comment">// parse log and count error</span></span><br><span class="line">  <span class="type">DB</span>.localTx &#123; <span class="keyword">implicit</span> session =&gt;</span><br><span class="line">    result.foreach &#123; <span class="keyword">case</span> (time, count) =&gt;</span><br><span class="line">      <span class="comment">// save to error_log table</span></span><br><span class="line">    &#125;</span><br><span class="line">    offsetRanges.foreach &#123; offsetRange =&gt;</span><br><span class="line">      <span class="keyword">val</span> affectedRows = <span class="string">sql""</span><span class="string">"</span></span><br><span class="line"><span class="string">      update kafka_offset set offset = $&#123;offsetRange.untilOffset&#125;</span></span><br><span class="line"><span class="string">      where topic = $&#123;topic&#125; and `partition` = $&#123;offsetRange.partition&#125;</span></span><br><span class="line"><span class="string">      and offset = $&#123;offsetRange.fromOffset&#125;</span></span><br><span class="line"><span class="string">      "</span><span class="string">""</span>.update.apply()</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (affectedRows != <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">Exception</span>(<span class="string">"fail to update offset"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If the offsets fail to update, or there’s a duplicate offset range detected by <code>offset != $fromOffset</code>, the whole transaction will rollback, which guarantees the exactly-once semantics.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Exactly-once is a very strong semantics in stream processing, and will inevitably bring some overhead to your application and impact the throughput. It’s also not applicable to <a href="https://github.com/koeninger/kafka-exactly-once/blob/master/src/main/scala/example/Windowed.scala" target="_blank" rel="noopener">windowed</a> operations. So you need to decide whether it’s necessary to spend such efforts, or weaker semantics even with few data loss will suffice. But surely knowing how to achieve exactly-once is a good chance of learning, and it’s a great fun.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://blog.cloudera.com/blog/2015/03/exactly-once-spark-streaming-from-apache-kafka/" target="_blank" rel="noopener">http://blog.cloudera.com/blog/2015/03/exactly-once-spark-streaming-from-apache-kafka/</a></li><li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a></li><li><a href="http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html</a></li><li><a href="http://kafka.apache.org/documentation.html#semantics" target="_blank" rel="noopener">http://kafka.apache.org/documentation.html#semantics</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Exactly-once semantics is one of the advanced topics of stream processing. To process every message once and only once, in spite of system or network failure, not only the stream processing framework needs to provide such functionality, but also the message delivery system, the output data store, as well as how we implement the processing procedure, altogether can we ensure the exactly-once semantics. In this article, I’ll demonstrate how to use Spark Streaming, with Kafka as data source and MySQL the output storage, to achieve exactly-once stream processing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://spark.apache.org/docs/latest/img/streaming-arch.png&quot; alt=&quot;Spark Streaming&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;An-Introductory-Example&quot;&gt;&lt;a href=&quot;#An-Introductory-Example&quot; class=&quot;headerlink&quot; title=&quot;An Introductory Example&quot;&gt;&lt;/a&gt;An Introductory Example&lt;/h2&gt;&lt;p&gt;First let’s implement a simple yet complete stream processing application that receive access logs from Kafka, parse and count the errors, then write the errors per minute metric into MySQL database.&lt;/p&gt;
&lt;p&gt;Sample access logs:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:09:08 ERROR some message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:09:20 INFO  some message&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2017-07-30 14:10:50 ERROR some message&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Output table, where &lt;code&gt;log_time&lt;/code&gt; should be truncated to minutes:&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; error_log (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  log_time datetime primary &lt;span class=&quot;keyword&quot;&gt;key&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  log_count &lt;span class=&quot;built_in&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="scala" scheme="http://shzhangji.com/tags/scala/"/>
    
      <category term="spark" scheme="http://shzhangji.com/tags/spark/"/>
    
      <category term="spark streaming" scheme="http://shzhangji.com/tags/spark-streaming/"/>
    
      <category term="kafka" scheme="http://shzhangji.com/tags/kafka/"/>
    
      <category term="stream processing" scheme="http://shzhangji.com/tags/stream-processing/"/>
    
  </entry>
  
  <entry>
    <title>Learn Pandas from a SQL Perspective</title>
    <link href="http://shzhangji.com/blog/2017/07/23/learn-pandas-from-a-sql-perspective/"/>
    <id>http://shzhangji.com/blog/2017/07/23/learn-pandas-from-a-sql-perspective/</id>
    <published>2017-07-23T12:02:50.000Z</published>
    <updated>2017-07-26T01:21:10.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a> is a widely used data processing tool for Python. Along with NumPy and Matplotlib, it provides in-memory high-performance data munging, analyzing, and visualization capabilities. Although Python is an easy-to-learn programming language, it still takes time to learn Pandas APIs and the idiomatic usages. For data engineer and analysts, SQL is the de-facto standard language of data queries. This article will provide examples of how some common SQL queries can be rewritten with Pandas.</p><p>The installation and basic concepts of Pandas is not covered in this post. One can check out the offical documentation, or read the book <a href="https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/" target="_blank" rel="noopener">Python for Data Analysis</a>. And I recommend using the <a href="https://www.continuum.io/downloads" target="_blank" rel="noopener">Anaconda</a> Python distribution, with <a href="https://pythonhosted.org/spyder/" target="_blank" rel="noopener">Spyder</a> IDE included. Before diving into the codes, please import Pandas and NumPy as follows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><h2 id="FROM-Load-Data-into-Memory"><a href="#FROM-Load-Data-into-Memory" class="headerlink" title="FROM - Load Data into Memory"></a><code>FROM</code> - Load Data into Memory</h2><p>First of all, let’s read some data into the workspace (memory). Pandas supports a variety of formats, one of them is CSV. Take the following flight delay dataset for example (<a href="/uploads/flights.csv">link</a>):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">date,delay,distance,origin,destination</span><br><span class="line">02221605,3,358,BUR,SMF</span><br><span class="line">01022100,-5,239,HOU,DAL</span><br><span class="line">03210808,6,288,BWI,ALB</span><br></pre></td></tr></table></figure><p>We can use <code>pd.read_csv</code> to load this file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">'flights.csv'</span>, dtype=&#123;<span class="string">'date'</span>: str&#125;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p>This statement will load <code>flights.csv</code> file into memory, use first line as column names, and try to figure out each column’s type. Since the <code>date</code> column is in <code>%m%d%H%M</code> format, we don’t want to lose the initial <code>0</code> in month, so we pass an explict <code>dtype</code> for it, indicating that this column should stay unparsed.</p><a id="more"></a><p> <code>df.head</code> is a function to peek the dataset. It accepts a single parameter to limit the rows, much like <code>LIMIT</code> caluse. To perform a <code>LIMIT 10, 100</code>, use <code>df.iloc[10:100]</code>. Besides, IPython defaults to show only 60 rows, but we can increase this limit by:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pd.options.display.max_rows = <span class="number">100</span></span><br><span class="line">df.iloc[<span class="number">10</span>:<span class="number">100</span>]</span><br></pre></td></tr></table></figure><p>Another common loading technique is reading from database. Pandas also has built-in support:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conn = pymysql.connect(host=<span class="string">'localhost'</span>, user=<span class="string">'root'</span>)</span><br><span class="line">df = pd.read_sql(<span class="string">"""</span></span><br><span class="line"><span class="string">select `date`, `delay`, `distance`, `origin`, `destination`</span></span><br><span class="line"><span class="string">from flights limit 1000</span></span><br><span class="line"><span class="string">"""</span>, conn)</span><br></pre></td></tr></table></figure><p>To save DataFrame into file or database, use <code>pd.to_csv</code> and <code>pd.to_sql</code> respectively.</p><h2 id="SELECT-Column-Projection"><a href="#SELECT-Column-Projection" class="headerlink" title="SELECT - Column Projection"></a><code>SELECT</code> - Column Projection</h2><p>The <code>SELECT</code> clause in SQL is used to perform column projection and data transformation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'date'</span>] <span class="comment"># SELECT `date`</span></span><br><span class="line">df[[<span class="string">'date'</span>, <span class="string">'delay'</span>]] <span class="comment"># SELECT `date`, `delay`</span></span><br><span class="line">df.loc[<span class="number">10</span>:<span class="number">100</span>, [<span class="string">'date'</span>, <span class="string">'delay'</span>]] <span class="comment"># SELECT `date, `delay` LIMIT 10, 100</span></span><br></pre></td></tr></table></figure><p>SQL provides various functions to transform data, most of them can be replaced by Pandas, or you can simply write one with Python. Here I’ll choose some commonly used functions to illustrate.</p><h3 id="String-Functions"><a href="#String-Functions" class="headerlink" title="String Functions"></a>String Functions</h3><p>Pandas string functions can be invoked by DataFrame and Series’ <code>str</code> attribute, e.g. <code>df[&#39;origin&#39;].str.lower()</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT CONCAT(origin, ' to ', destination)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.cat(df[<span class="string">'destination'</span>], sep=<span class="string">' to '</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'origin'</span>].str.strip() <span class="comment"># TRIM(origin)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.len() <span class="comment"># LENGTH(origin)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str.replace(<span class="string">'a'</span>, <span class="string">'b'</span>) <span class="comment"># REPLACE(origin, 'a', 'b')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT SUBSTRING(origin, 1, 1)</span></span><br><span class="line">df[<span class="string">'origin'</span>].str[<span class="number">0</span>:<span class="number">1</span>] <span class="comment"># use Python string indexing</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT SUBSTRING_INDEX(domain, '.', 2)</span></span><br><span class="line"><span class="comment"># www.example.com -&gt; www.example</span></span><br><span class="line">df[<span class="string">'domain'</span>].str.split(<span class="string">'.'</span>).str[:<span class="number">2</span>].str.join(<span class="string">'.'</span>)</span><br><span class="line">df[<span class="string">'domain'</span>].str.extract(<span class="string">r'^([^.]+\.[^.]+)'</span>)</span><br></pre></td></tr></table></figure><p>Pandas also has a feature called broadcast behaviour, i.e. perform operations between lower dimensional data (or scalar value) with higher dimensional data. For instances:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'full_date'</span>] = <span class="string">'2001'</span> + df[<span class="string">'date'</span>] <span class="comment"># CONCAT('2001', `date`)</span></span><br><span class="line">df[<span class="string">'delay'</span>] / <span class="number">60</span></span><br><span class="line">df[<span class="string">'delay'</span>].div(<span class="number">60</span>) <span class="comment"># same as above</span></span><br></pre></td></tr></table></figure><p>There’re many other string functions that Pandas support out-of-the-box, and they are quite different, thus more powerful than SQL. For a complete list please check the <a href="https://pandas.pydata.org/pandas-docs/stable/text.html" target="_blank" rel="noopener">Working with Text Data</a> doc.</p><h3 id="Date-Functions"><a href="#Date-Functions" class="headerlink" title="Date Functions"></a>Date Functions</h3><p><code>pd.to_datetime</code> is used to convert various datetime representations to the standard <code>datetime64</code> dtype. <code>dt</code> is a property of datetime/period like Series, from which you can extract information about date and time. Full documentation can be found in <a href="https://pandas.pydata.org/pandas-docs/stable/timeseries.html" target="_blank" rel="noopener">Time Series / Date functionality</a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT STR_TO_DATE(full_date, '%Y%m%d%H%i%s') AS `datetime`</span></span><br><span class="line">df[<span class="string">'datetime'</span>] = pd.to_datetime(df[<span class="string">'full_date'</span>], format=<span class="string">'%Y%m%d%H%M%S'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT DATE_FORMAT(`datetime`, '%Y-%m-%d')</span></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.strftime(<span class="string">'%Y-%m-%d'</span>)</span><br><span class="line"></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.month <span class="comment"># MONTH(`datetime`)</span></span><br><span class="line">df[<span class="string">'datetime'</span>].dt.hour <span class="comment"># HOUR(`datetime`)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT UNIX_TIMESTAMP(`datetime`)</span></span><br><span class="line">df[<span class="string">'datetime'</span>].view(<span class="string">'int64'</span>) // pd.Timedelta(<span class="number">1</span>, unit=<span class="string">'s'</span>).value</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT FROM_UNIXTIME(`timestamp`)</span></span><br><span class="line">pd.to_datetime(df[<span class="string">'timestamp'</span>], unit=<span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT `datetime` + INTERVAL 1 DAY</span></span><br><span class="line">df[<span class="string">'datetime'</span>] + pd.Timedelta(<span class="number">1</span>, unit=<span class="string">'D'</span>)</span><br></pre></td></tr></table></figure><h2 id="WHERE-Row-Selection"><a href="#WHERE-Row-Selection" class="headerlink" title="WHERE - Row Selection"></a><code>WHERE</code> - Row Selection</h2><p>For logic operators, Pandas will result in a boolean typed Series, which can be used to filter out rows:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>).head()</span><br><span class="line"><span class="comment"># 0  True</span></span><br><span class="line"><span class="comment"># 1 False</span></span><br><span class="line"><span class="comment"># 2  True</span></span><br><span class="line"><span class="comment"># dtype: bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE delay &gt; 0</span></span><br><span class="line">df[df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>We can combine multiple conditions with bitwise operators:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># WHERE delay &gt; 0 AND distance &lt;= 500</span></span><br><span class="line">df[(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>) &amp; (df[<span class="string">'distance'</span>] &lt;= <span class="number">500</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE delay &gt; 0 OR origin = 'BUR'</span></span><br><span class="line">df[(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>) | (df[<span class="string">'origin'</span>] == <span class="string">'BUR'</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># WHERE NOT (delay &gt; 0)</span></span><br><span class="line">df[~(df[<span class="string">'delay'</span>] &gt; <span class="number">0</span>)]</span><br></pre></td></tr></table></figure><p>For <code>IS NULL</code> and <code>IS NOT NULL</code>, we can use the built-in functions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[df[<span class="string">'delay'</span>].isnull()] <span class="comment"># delay IS NULL</span></span><br><span class="line">df[df[<span class="string">'delay'</span>].notnull()] <span class="comment"># delay IS NOT NUL</span></span><br></pre></td></tr></table></figure><p>There’s also a <code>df.query</code> method to write filters as string expression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.query(<span class="string">'delay &gt; 0 and distaince &lt;= 500'</span>)</span><br><span class="line">df.query(<span class="string">'(delay &gt; 0) | (origin == "BUR")'</span>)</span><br></pre></td></tr></table></figure><p>Actually, Pandas provides more powerful functionalities for <a href="https://pandas.pydata.org/pandas-docs/stable/indexing.html" target="_blank" rel="noopener">Indexing and Selecting Data</a>, and some of them cannot be expressed by SQL. You can find more usages in the docs.</p><h2 id="GROUP-BY-Aggregation"><a href="#GROUP-BY-Aggregation" class="headerlink" title="GROUP BY - Aggregation"></a><code>GROUP BY</code> - Aggregation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT origin, COUNT(*) FROM flights GROUP BY origin</span></span><br><span class="line">df.groupby(<span class="string">'origin'</span>).size()</span><br><span class="line"><span class="comment"># origin</span></span><br><span class="line"><span class="comment"># ABQ    22</span></span><br><span class="line"><span class="comment"># ALB     4</span></span><br><span class="line"><span class="comment"># AMA     4</span></span><br><span class="line"><span class="comment"># dtype: int64</span></span><br></pre></td></tr></table></figure><p>There’re two parts in an aggregation statement, the columns to group by and the aggregation function. It’s possible to pass multiple columns to <code>df.groupby</code>, as well as multiple aggregators.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT origin, destination, SUM(delay), AVG(distance)</span></span><br><span class="line"><span class="comment"># GROUP BY origin, destination</span></span><br><span class="line">df.groupby([<span class="string">'origin'</span>, <span class="string">'destination'</span>]).agg(&#123;</span><br><span class="line">    <span class="string">'delay'</span>: np.sum,</span><br><span class="line">    <span class="string">'distance'</span>: np.mean</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SELECT origin, MIN(delay), MAX(delay) GROUP BY origin</span></span><br><span class="line">df.groupby(<span class="string">'origin'</span>)[<span class="string">'delay'</span>].agg([<span class="string">'min'</span>, <span class="string">'max'</span>])</span><br></pre></td></tr></table></figure><p>We can also group by a function result. More usages can be found in <a href="https://pandas.pydata.org/pandas-docs/stable/groupby.html" target="_blank" rel="noopener">Group By: split-apply-combine</a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT LENGTH(origin), COUNT(*) GROUP BY LENGTH(origin)</span></span><br><span class="line">df.set_index(<span class="string">'origin'</span>).groupby(len).size()</span><br></pre></td></tr></table></figure><h2 id="ORDER-BY-Sorting-Rows"><a href="#ORDER-BY-Sorting-Rows" class="headerlink" title="ORDER BY - Sorting Rows"></a><code>ORDER BY</code> - Sorting Rows</h2><p>There’re two types of sort, by index and by values. If you are not familiar with the concept index, please refer to Pandas tutorials.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ORDER BY origin</span></span><br><span class="line">df.set_index(<span class="string">'origin'</span>).sort_index()</span><br><span class="line">df.sort_values(by=<span class="string">'origin'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ORDER BY origin ASC, destination DESC</span></span><br><span class="line">df.sort_values(by=[<span class="string">'origin'</span>, <span class="string">'destination'</span>], ascending=[<span class="keyword">True</span>, <span class="keyword">False</span>])</span><br></pre></td></tr></table></figure><h2 id="JOIN-Merge-DateFrames"><a href="#JOIN-Merge-DateFrames" class="headerlink" title="JOIN - Merge DateFrames"></a><code>JOIN</code> - Merge DateFrames</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># FROM product a LEFT JOIN category b ON a.cid = b.id</span></span><br><span class="line">pd.merge(df_product, df_category, left_on=<span class="string">'cid'</span>, right_on=<span class="string">'id'</span>, how=<span class="string">'left'</span>)</span><br></pre></td></tr></table></figure><p>If join key is the same, we can use <code>on=[&#39;k1&#39;, &#39;k2&#39;]</code>. The default join method (<code>how</code>) is inner join. Other options are <code>left</code> for left join, <code>right</code> outer join, and <code>outer</code> for full outer join.</p><p><code>pd.concat</code> can be used to perform <code>UNION</code>. More usages can be found in <a href="https://pandas.pydata.org/pandas-docs/stable/merging.html" target="_blank" rel="noopener">Merge, join, and concatenate</a>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SELECT * FROM a UNION SELECT * FROM b</span></span><br><span class="line">pd.concat([df_a, df_b]).drop_duplicates()</span><br></pre></td></tr></table></figure><h1 id="Rank-Within-Groups"><a href="#Rank-Within-Groups" class="headerlink" title="Rank Within Groups"></a>Rank Within Groups</h1><p>Last but not least, it’s common to select top n items within each groups. In MySQL, we have to use variables. In Pandas, we can use the <code>rank</code> function on grouped DataFrame:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rnk = df.groupby(<span class="string">'origin'</span>)[<span class="string">'delay'</span>].rank(method=<span class="string">'first'</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line">df.assign(rnk=rnk).query(<span class="string">'rnk &lt;= 3'</span>).sort_values([<span class="string">'origin'</span>, <span class="string">'rnk'</span>])</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html" target="_blank" rel="noopener">https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html</a></li><li><a href="http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/" target="_blank" rel="noopener">http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/</a></li><li><a href="http://codingsight.com/pivot-tables-in-mysql/" target="_blank" rel="noopener">http://codingsight.com/pivot-tables-in-mysql/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://pandas.pydata.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pandas&lt;/a&gt; is a widely used data processing tool for Python. Along with NumPy and Matplotlib, it provides in-memory high-performance data munging, analyzing, and visualization capabilities. Although Python is an easy-to-learn programming language, it still takes time to learn Pandas APIs and the idiomatic usages. For data engineer and analysts, SQL is the de-facto standard language of data queries. This article will provide examples of how some common SQL queries can be rewritten with Pandas.&lt;/p&gt;
&lt;p&gt;The installation and basic concepts of Pandas is not covered in this post. One can check out the offical documentation, or read the book &lt;a href=&quot;https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1491957662/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Python for Data Analysis&lt;/a&gt;. And I recommend using the &lt;a href=&quot;https://www.continuum.io/downloads&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Anaconda&lt;/a&gt; Python distribution, with &lt;a href=&quot;https://pythonhosted.org/spyder/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spyder&lt;/a&gt; IDE included. Before diving into the codes, please import Pandas and NumPy as follows:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; pd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;FROM-Load-Data-into-Memory&quot;&gt;&lt;a href=&quot;#FROM-Load-Data-into-Memory&quot; class=&quot;headerlink&quot; title=&quot;FROM - Load Data into Memory&quot;&gt;&lt;/a&gt;&lt;code&gt;FROM&lt;/code&gt; - Load Data into Memory&lt;/h2&gt;&lt;p&gt;First of all, let’s read some data into the workspace (memory). Pandas supports a variety of formats, one of them is CSV. Take the following flight delay dataset for example (&lt;a href=&quot;/uploads/flights.csv&quot;&gt;link&lt;/a&gt;):&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;date,delay,distance,origin,destination&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;02221605,3,358,BUR,SMF&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;01022100,-5,239,HOU,DAL&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;03210808,6,288,BWI,ALB&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;We can use &lt;code&gt;pd.read_csv&lt;/code&gt; to load this file:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;df = pd.read_csv(&lt;span class=&quot;string&quot;&gt;&#39;flights.csv&#39;&lt;/span&gt;, dtype=&amp;#123;&lt;span class=&quot;string&quot;&gt;&#39;date&#39;&lt;/span&gt;: str&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;df.head()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;This statement will load &lt;code&gt;flights.csv&lt;/code&gt; file into memory, use first line as column names, and try to figure out each column’s type. Since the &lt;code&gt;date&lt;/code&gt; column is in &lt;code&gt;%m%d%H%M&lt;/code&gt; format, we don’t want to lose the initial &lt;code&gt;0&lt;/code&gt; in month, so we pass an explict &lt;code&gt;dtype&lt;/code&gt; for it, indicating that this column should stay unparsed.&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/tags/analytics/"/>
    
      <category term="pandas" scheme="http://shzhangji.com/tags/pandas/"/>
    
      <category term="sql" scheme="http://shzhangji.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>Log Tailer with WebSocket and Python</title>
    <link href="http://shzhangji.com/blog/2017/07/15/log-tailer-with-websocket-and-python/"/>
    <id>http://shzhangji.com/blog/2017/07/15/log-tailer-with-websocket-and-python/</id>
    <published>2017-07-15T11:21:03.000Z</published>
    <updated>2017-07-15T11:22:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>Tailing a log file is a common task when we deploy or maintain some software in production. Instead of logging into the server and <code>tail -f</code>, it would be nice if we can tail a log file in the browser. With WebSocket, this can be done easily. In this article, I’ll walk you through a simple <strong>logviewer</strong> (<a href="http://github.com/jizhang/logviewer" target="_blank" rel="noopener">source</a>) utility that is written in Python.</p><p><img src="/images/logviewer-websocket.png" alt="Logviewer with WebSocket"></p><h2 id="WebSocket-Intro"><a href="#WebSocket-Intro" class="headerlink" title="WebSocket Intro"></a>WebSocket Intro</h2><p>WebSocket is standard protocol over TCP, that provides full-duplex communication between client and server side, usually a browser and a web server. Before WebSocket, when we want to keep an alive browser-server connection, we choose from long polling, forever frame or Comet techniques. Now that WebSocket is widely supported by major browsers, we can use it to implement web chatroom, games, realtime dashboard, etc. Besides, WebSocket connection can be established by an HTTP upgrade request, and communicate over 80 port, so as to bring minimum impact on existing network facility.</p><a id="more"></a><h2 id="Python’s-websockets-Package"><a href="#Python’s-websockets-Package" class="headerlink" title="Python’s websockets Package"></a>Python’s <code>websockets</code> Package</h2><p><code>websockets</code> is a Python package that utilize Python’s <code>asyncio</code> to develop WebSocket servers and clients. The package can be installed via <code>pip</code>, and it requires Python 3.3+.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install websockets</span><br><span class="line"><span class="comment"># For Python 3.3</span></span><br><span class="line">pip install asyncio</span><br></pre></td></tr></table></figure><p>Following is a simple Echo server:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> websockets</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">echo</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    message = <span class="keyword">yield</span> <span class="keyword">from</span> websocket.recv()</span><br><span class="line">    print(<span class="string">'recv'</span>, message)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(message)</span><br><span class="line"></span><br><span class="line">start_server = websockets.serve(echo, <span class="string">'localhost'</span>, <span class="number">8765</span>)</span><br><span class="line"></span><br><span class="line">asyncio.get_event_loop().run_until_complete(start_server)</span><br><span class="line">asyncio.get_event_loop().run_forever()</span><br></pre></td></tr></table></figure><p>Here we use Python’s coroutines to handle client requests. Coroutine enables single-threaded application to run concurrent codes, such as handling socket I/O. Note that Python 3.5 introduced two new keywords for coroutine, <code>async</code> and <code>await</code>, so the Echo server can be rewritten as:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">echo</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    message = <span class="keyword">await</span> websocket.recv()</span><br><span class="line">    <span class="keyword">await</span> websocket.send(message)</span><br></pre></td></tr></table></figure><p>For client side, we use the built-in <code>WebSocket</code> class. You can simply paste the following code into Chrome’s JavaScript console:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> ws = <span class="keyword">new</span> WebSocket(<span class="string">'ws://localhost:8765'</span>)</span><br><span class="line">ws.onmessage = <span class="function">(<span class="params">event</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(event.data)</span><br><span class="line">&#125;</span><br><span class="line">ws.onopen = <span class="function"><span class="params">()</span> =&gt;</span> &#123;</span><br><span class="line">  ws.send(<span class="string">'hello'</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Tail-a-Log-File"><a href="#Tail-a-Log-File" class="headerlink" title="Tail a Log File"></a>Tail a Log File</h2><p>We’ll take the following steps to implement a log viewer:</p><ul><li>Client opens a WebSocket connection, and puts the file path in the url, like <code>ws://localhost:8765/tmp/build.log?tail=1</code>;</li><li>Server parses the file path, along with a flag that indicates whether this is a view once or tail request;</li><li>Open file and start sending contents within a for loop.</li></ul><p>Full code can be found on <a href="https://github.com/jizhang/logviewer" target="_blank" rel="noopener">GitHub</a>, so here I’ll select some important parts:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">view_log</span><span class="params">(websocket, path)</span>:</span></span><br><span class="line">    parse_result = urllib.parse.urlparse(path)</span><br><span class="line">    file_path = os.path.abspath(parse_result.path)</span><br><span class="line">    query = urllib.parse.parse_qs(parse_result.query)</span><br><span class="line">    tail = query <span class="keyword">and</span> query[<span class="string">'tail'</span>] <span class="keyword">and</span> query[<span class="string">'tail'</span>][<span class="number">0</span>] == <span class="string">'1'</span></span><br><span class="line">    <span class="keyword">with</span> open(file_path) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(f.read())</span><br><span class="line">        <span class="keyword">if</span> tail:</span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">                content = f.read()</span><br><span class="line">                <span class="keyword">if</span> content:</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(content)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">yield</span> <span class="keyword">from</span> websocket.close()</span><br></pre></td></tr></table></figure><h2 id="Miscellaneous"><a href="#Miscellaneous" class="headerlink" title="Miscellaneous"></a>Miscellaneous</h2><ul><li>Sometimes the client browser will not close the connection properly, so it’s necessary to add some heartbeat mechanism. For instance:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> time.time() - last_heartbeat &gt; HEARTBEAT_INTERVAL:</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(<span class="string">'ping'</span>)</span><br><span class="line">    pong = <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.wait_for(websocket.recv(), <span class="number">5</span>)</span><br><span class="line">    <span class="keyword">if</span> pong != <span class="string">'pong'</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Ping error'</span>))</span><br><span class="line">    last_heartbeat = time.time()</span><br></pre></td></tr></table></figure><ul><li>Log files may contain ANSI color codes (e.g. logging level). We can use <code>ansi2html</code> package to convert them into HTML:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ansi2html <span class="keyword">import</span> Ansi2HTMLConverter</span><br><span class="line">conv = Ansi2HTMLConverter(inline=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">yield</span> <span class="keyword">from</span> websocket.send(conv.convert(content, full=<span class="keyword">False</span>))</span><br></pre></td></tr></table></figure><ul><li>It’s also necessary to do some permission checks on the file path. For example, convert to absolute path and do a simple prefix check.</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://en.wikipedia.org/wiki/WebSocket" target="_blank" rel="noopener">WebSocket - Wikipedia</a></li><li><a href="https://websockets.readthedocs.io/en/stable/intro.html" target="_blank" rel="noopener">websockets - Get Started</a></li><li><a href="https://docs.python.org/3/library/asyncio-task.html" target="_blank" rel="noopener">Tasks and coroutines</a></li><li><a href="https://stackoverflow.com/questions/12523044/how-can-i-tail-a-log-file-in-python" target="_blank" rel="noopener">How can I tail a log file in Python?</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Tailing a log file is a common task when we deploy or maintain some software in production. Instead of logging into the server and &lt;code&gt;tail -f&lt;/code&gt;, it would be nice if we can tail a log file in the browser. With WebSocket, this can be done easily. In this article, I’ll walk you through a simple &lt;strong&gt;logviewer&lt;/strong&gt; (&lt;a href=&quot;http://github.com/jizhang/logviewer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;source&lt;/a&gt;) utility that is written in Python.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/logviewer-websocket.png&quot; alt=&quot;Logviewer with WebSocket&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;WebSocket-Intro&quot;&gt;&lt;a href=&quot;#WebSocket-Intro&quot; class=&quot;headerlink&quot; title=&quot;WebSocket Intro&quot;&gt;&lt;/a&gt;WebSocket Intro&lt;/h2&gt;&lt;p&gt;WebSocket is standard protocol over TCP, that provides full-duplex communication between client and server side, usually a browser and a web server. Before WebSocket, when we want to keep an alive browser-server connection, we choose from long polling, forever frame or Comet techniques. Now that WebSocket is widely supported by major browsers, we can use it to implement web chatroom, games, realtime dashboard, etc. Besides, WebSocket connection can be established by an HTTP upgrade request, and communicate over 80 port, so as to bring minimum impact on existing network facility.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="websocket" scheme="http://shzhangji.com/tags/websocket/"/>
    
      <category term="ops" scheme="http://shzhangji.com/tags/ops/"/>
    
  </entry>
  
  <entry>
    <title>Build Interactive Report with Crossfilter and dc.js</title>
    <link href="http://shzhangji.com/blog/2017/06/18/build-interactive-report-with-crossfilter-and-dc-js/"/>
    <id>http://shzhangji.com/blog/2017/06/18/build-interactive-report-with-crossfilter-and-dc-js/</id>
    <published>2017-06-18T08:38:01.000Z</published>
    <updated>2017-06-19T01:06:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>When visualizing multidimensional datasets, we often want to connect individual charts together, so that one chart’s filter will apply to all the other charts. We can do it manually, filter data on the server side, and update the rendered charts. Or we can filter data on the client side, and let charts update themselves. With Crossfilter and dc.js, this work becomes simple and intuitive.</p><h2 id="Airline-On-time-Performance"><a href="#Airline-On-time-Performance" class="headerlink" title="Airline On-time Performance"></a>Airline On-time Performance</h2><p>Here’s an example taken from Crossfilter’s official website. It’s a flight delay analysis report based on <a href="http://stat-computing.org/dataexpo/2009/" target="_blank" rel="noopener">ASA Data Expo</a> dataset. And this post will introduce how to use dc.js to build the report. A runnable JSFiddle can be found <a href="https://jsfiddle.net/zjerryj/gjao9sws/" target="_blank" rel="noopener">here</a>, though the dataset is reduced to 1,000 records.</p><p><img src="/images/airline-ontime-performance.png" alt=""></p><a id="more"></a><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p><a href="http://crossfilter.github.io/crossfilter/" target="_blank" rel="noopener">Crossfilter</a> is a JavaScript library to do multidimensional queries on large amount of data in the client’s browser. It can <strong>cross-filter</strong> between different group-by queries, so that query results will be connected and updated automatically. With the help of <a href="https://dc-js.github.io/dc.js/" target="_blank" rel="noopener">dc.js</a>, also a JavaScript library that provides charting capability, together we can develop high-performance, interactive reports.</p><h2 id="Dataset-Dimension-and-Measure"><a href="#Dataset-Dimension-and-Measure" class="headerlink" title="Dataset, Dimension, and Measure"></a>Dataset, Dimension, and Measure</h2><p>There’re several concepts in Crossfilter, namely dataset, dimension, measure. If you come from a data warehouse or analytics background, these are similar to the terms in OLAP Cube.</p><ul><li>Dataset, or a list of records, is a two dimensional table that contains rows and columns.</li><li>Dimension columns are used to do group-bys. They are either categorical, like dates, gender, or represents a range of values, like age range, etc.</li><li>Measure columns are used to do aggregations, such as sum, standard deviation, so they are mostly numeric. Examples are income, number of children.</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> flights = d3.csv.parse(flightsCsv)</span><br><span class="line"><span class="keyword">let</span> flight = crossfilter(flights)</span><br><span class="line"><span class="keyword">let</span> hour = flight.dimension(<span class="function">(<span class="params">d</span>) =&gt;</span> d.date.getHours() + d.date.getMinutes() / <span class="number">60</span>)</span><br><span class="line"><span class="keyword">let</span> hours = hour.group(<span class="built_in">Math</span>.floor)</span><br></pre></td></tr></table></figure><p>Here we create a crossfilter object from a parsed csv data. And we define a dimension that is derived from <code>date</code> column, hour of day represented by float values. Then we group by its integer part. To query the top 3 hours that contains most delays:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hours.top(<span class="number">3</span>)</span><br><span class="line"><span class="comment">// output</span></span><br><span class="line">[</span><br><span class="line">  &#123; <span class="attr">key</span>: <span class="number">13</span>, <span class="attr">value</span>: <span class="number">72</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">key</span>: <span class="number">20</span>, <span class="attr">value</span>: <span class="number">72</span> &#125;,</span><br><span class="line">  &#123; <span class="attr">key</span>:  <span class="number">8</span>, <span class="attr">value</span>: <span class="number">71</span> &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h2><p>Now we can plot the hour of delays in a bar chart:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> hourChart = dc.barChart(<span class="string">'#hour-chart'</span>)</span><br><span class="line">hourChart</span><br><span class="line">  .width(<span class="number">350</span>)</span><br><span class="line">  .height(<span class="number">150</span>)</span><br><span class="line">  .dimension(hour)</span><br><span class="line">  .group(hours)</span><br><span class="line">  .x(d3.scale.linear()</span><br><span class="line">    .domain([<span class="number">0</span>, <span class="number">24</span>])</span><br><span class="line">    .rangeRound([<span class="number">0</span>, <span class="number">10</span> * <span class="number">24</span>]))</span><br><span class="line">  .controlsUseVisibility(<span class="literal">true</span>)</span><br></pre></td></tr></table></figure><p>The corresponding HTML code:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"hour-chart"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"title"</span>&gt;</span>Time of Day</span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"reset"</span> <span class="attr">href</span>=<span class="string">"javascript:;"</span> <span class="attr">style</span>=<span class="string">"visibility: hidden;"</span>&gt;</span>reset<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><p>We can see that dc.js is highly integrated with crossfilter. We simply pass the dimension objects and do some setup for chart axes. In this example, x axis is hours of the day, and y axis is the count of delayed flights.</p><p>Note <code>class=&quot;reset&quot;</code> is used with <code>controlUseVisibility</code>, that provides a <code>reset</code> button. Try to drag on the chart to filter a range of data, and you’ll see how this button is used.</p><h2 id="Cross-Filtering"><a href="#Cross-Filtering" class="headerlink" title="Cross Filtering"></a>Cross Filtering</h2><p>We can create other charts, such as a hitogram of arrival delay in minutes. You can find the source code in JSFiddle. When you do some filtering (drag and select), the other charts will be updated simultaneously. It is great when you want to explore the distribution of data combined with filtering conditions. Just declare the relationship, and dc.js will do the rest for you.</p><p>There’re many other components like pie chart, table grid, or even customized HTML. But to master these tools, you also need some knowledge of d3.js.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="http://crossfilter.github.io/crossfilter/" target="_blank" rel="noopener">Crossfilter - Fast Multidimensional Filtering for Coordinated Views</a></li><li><a href="https://dc-js.github.io/dc.js/" target="_blank" rel="noopener">dc.js - Dimensional Charting Javascript Library</a></li><li><a href="http://blog.rusty.io/2012/09/17/crossfilter-tutorial/" target="_blank" rel="noopener">Crossfiler Tutorial</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;When visualizing multidimensional datasets, we often want to connect individual charts together, so that one chart’s filter will apply to all the other charts. We can do it manually, filter data on the server side, and update the rendered charts. Or we can filter data on the client side, and let charts update themselves. With Crossfilter and dc.js, this work becomes simple and intuitive.&lt;/p&gt;
&lt;h2 id=&quot;Airline-On-time-Performance&quot;&gt;&lt;a href=&quot;#Airline-On-time-Performance&quot; class=&quot;headerlink&quot; title=&quot;Airline On-time Performance&quot;&gt;&lt;/a&gt;Airline On-time Performance&lt;/h2&gt;&lt;p&gt;Here’s an example taken from Crossfilter’s official website. It’s a flight delay analysis report based on &lt;a href=&quot;http://stat-computing.org/dataexpo/2009/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ASA Data Expo&lt;/a&gt; dataset. And this post will introduce how to use dc.js to build the report. A runnable JSFiddle can be found &lt;a href=&quot;https://jsfiddle.net/zjerryj/gjao9sws/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;, though the dataset is reduced to 1,000 records.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/airline-ontime-performance.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Big Data" scheme="http://shzhangji.com/categories/Big-Data/"/>
    
    
      <category term="crossfilter" scheme="http://shzhangji.com/tags/crossfilter/"/>
    
      <category term="dc.js" scheme="http://shzhangji.com/tags/dc-js/"/>
    
      <category term="analytics" scheme="http://shzhangji.com/tags/analytics/"/>
    
  </entry>
  
  <entry>
    <title>Why Use Lodash When ES6 Is Available</title>
    <link href="http://shzhangji.com/blog/2017/03/13/why-use-lodash-when-es6-is-available/"/>
    <id>http://shzhangji.com/blog/2017/03/13/why-use-lodash-when-es6-is-available/</id>
    <published>2017-03-13T14:39:01.000Z</published>
    <updated>2017-03-14T01:40:57.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://lodash.com/" target="_blank" rel="noopener">Lodash</a> is a well-known JavaScript utility library that makes it easy to manipulate arrays and objects, as well as functions, strings, etc. I myself enjoys its functional way to process collections, especially chaining and lazy evaluation. But as <a href="http://www.ecma-international.org/ecma-262/6.0/" target="_blank" rel="noopener">ECMAScript 2015 Standard</a> (ES6) becomes widely supported by major browsers, and <a href="https://babeljs.io/" target="_blank" rel="noopener">Babel</a>, the JavaScript compiler that transforms ES6 codes to ES5, plays a major role in today’s frontend development, it seems that most Lodash utilities can be replaced by ES6. But should we? In my opinion, Lodash will remain popular, for it still has lots of useful features that could improve the way of programming.</p><h2 id="map-and-Array-map-Are-Different"><a href="#map-and-Array-map-Are-Different" class="headerlink" title="_.map and Array#map Are Different"></a><code>_.map</code> and <code>Array#map</code> Are Different</h2><p><code>_.map</code>, <code>_.reduce</code>, <code>_.filter</code> and <code>_.forEach</code> are frequently used functions when processing collections, and ES6 provides direct support for them:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">_.map([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; i + <span class="number">1</span>)</span><br><span class="line">_.reduce([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (sum, i) =&gt; sum + i, <span class="number">0</span>)</span><br><span class="line">_.filter([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; i &gt; <span class="number">1</span>)</span><br><span class="line">_.forEach([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], (i) =&gt; &#123; <span class="built_in">console</span>.log(i) &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// becomes</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].map(<span class="function">(<span class="params">i</span>) =&gt;</span> i + <span class="number">1</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].reduce(<span class="function">(<span class="params">sum, i</span>) =&gt;</span> sum + i, <span class="number">0</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].filter(<span class="function">(<span class="params">i</span>) =&gt;</span> i &gt; <span class="number">1</span>)</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>].forEach(<span class="function">(<span class="params">i</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(i) &#125;)</span><br></pre></td></tr></table></figure><p>But Lodash’s <code>_.map</code> is more powerful, in that it works on objects, has iteratee / predicate shorthands, lazy evaluation, guards against null parameter, and has better performance.</p><a id="more"></a><h3 id="Iterate-over-Objects"><a href="#Iterate-over-Objects" class="headerlink" title="Iterate over Objects"></a>Iterate over Objects</h3><p>To iterate over an object in ES6, there’re several approaches:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">in</span> obj) &#123; <span class="built_in">console</span>.log(obj[key]) &#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">of</span> <span class="built_in">Object</span>.keys(obj)) &#123; <span class="built_in">console</span>.log(obj[key]) &#125;</span><br><span class="line"><span class="built_in">Object</span>.keys(obj).forEach(<span class="function">(<span class="params">key</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(obj[key]) &#125;)</span><br></pre></td></tr></table></figure><p>With Lodash, there’s a unified <code>_.forEach</code>, for both array and object:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_.forEach(obj, (value, key) =&gt; &#123; <span class="built_in">console</span>.log(value) &#125;)</span><br></pre></td></tr></table></figure><p>Although ES6 does <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map" target="_blank" rel="noopener">provide</a> <code>forEach</code> for the newly added <code>Map</code> type, it takes some effort to first convert an object into a <code>Map</code>:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// http://stackoverflow.com/a/36644532/1030720</span></span><br><span class="line"><span class="keyword">const</span> buildMap = <span class="function"><span class="params">o</span> =&gt;</span> <span class="built_in">Object</span>.keys(o).reduce(<span class="function">(<span class="params">m, k</span>) =&gt;</span> m.set(k, o[k]), <span class="keyword">new</span> <span class="built_in">Map</span>());</span><br></pre></td></tr></table></figure><h3 id="Iteratee-Predicate-Shorthands"><a href="#Iteratee-Predicate-Shorthands" class="headerlink" title="Iteratee / Predicate Shorthands"></a>Iteratee / Predicate Shorthands</h3><p>To extract some property from an array of objects:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr = [&#123; <span class="attr">n</span>: <span class="number">1</span> &#125;, &#123; <span class="attr">n</span>: <span class="number">2</span> &#125;]</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">arr.map(<span class="function">(<span class="params">obj</span>) =&gt;</span> obj.n)</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.map(arr, <span class="string">'n'</span>)</span><br></pre></td></tr></table></figure><p>This can be more helpful when it comes to complex objects:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> arr = [</span><br><span class="line">  &#123; <span class="attr">a</span>: [ &#123; <span class="attr">n</span>: <span class="number">1</span> &#125; ]&#125;,</span><br><span class="line">  &#123; <span class="attr">b</span>: [ &#123; <span class="attr">n</span>: <span class="number">1</span> &#125; ]&#125;</span><br><span class="line">]</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">arr.map(<span class="function">(<span class="params">obj</span>) =&gt;</span> obj.a[<span class="number">0</span>].n) <span class="comment">// TypeError: property 'a' is not defined in arr[1]</span></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.map(arr, <span class="string">'a[0].n'</span>) <span class="comment">// =&gt; [1, undefined]</span></span><br></pre></td></tr></table></figure><p>As we can see, Lodash not only provides conveniet shorthands, it also guards against undefined values. For <code>_.filter</code>, there’s also predicate shorthand. Here are some examples from Lodash documentation:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> users = [</span><br><span class="line">  &#123; <span class="string">'user'</span>: <span class="string">'barney'</span>, <span class="string">'age'</span>: <span class="number">36</span>, <span class="string">'active'</span>: <span class="literal">true</span> &#125;,</span><br><span class="line">  &#123; <span class="string">'user'</span>: <span class="string">'fred'</span>,   <span class="string">'age'</span>: <span class="number">40</span>, <span class="string">'active'</span>: <span class="literal">false</span> &#125;</span><br><span class="line">];</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">users.filter(<span class="function">(<span class="params">o</span>) =&gt;</span> o.active)</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.filter(users, <span class="string">'active'</span>)</span><br><span class="line">_.filter(users, [<span class="string">'active'</span>, <span class="literal">true</span>])</span><br><span class="line">_.filter(users, &#123;<span class="string">'active'</span>: <span class="literal">true</span>, <span class="string">'age'</span>: <span class="number">36</span>&#125;)</span><br></pre></td></tr></table></figure><h3 id="Chain-and-Lazy-Evaluation"><a href="#Chain-and-Lazy-Evaluation" class="headerlink" title="Chain and Lazy Evaluation"></a>Chain and Lazy Evaluation</h3><p>Here comes the fun part. Processing collections with chaining, lazy evaluation, along with short, easy-to-test functions, is quite popular these days. Most Lodash functions regarding collections can be chained easily. The following is a wordcount example:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> lines = <span class="string">`</span></span><br><span class="line"><span class="string">an apple orange the grape</span></span><br><span class="line"><span class="string">banana an apple melon</span></span><br><span class="line"><span class="string">an orange banana apple</span></span><br><span class="line"><span class="string">`</span>.split(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">_.chain(lines)</span><br><span class="line">  .flatMap(<span class="function"><span class="params">line</span> =&gt;</span> line.split(<span class="regexp">/\s+/</span>))</span><br><span class="line">  .filter(<span class="function"><span class="params">word</span> =&gt;</span> word.length &gt; <span class="number">3</span>)</span><br><span class="line">  .groupBy(_.identity)</span><br><span class="line">  .mapValues(_.size)</span><br><span class="line">  .forEach(<span class="function">(<span class="params">count, word</span>) =&gt;</span> &#123; <span class="built_in">console</span>.log(word, count) &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// apple 3</span></span><br><span class="line"><span class="comment">// orange 2</span></span><br><span class="line"><span class="comment">// grape 1</span></span><br><span class="line"><span class="comment">// banana 2</span></span><br><span class="line"><span class="comment">// melon 1</span></span><br></pre></td></tr></table></figure><h2 id="Destructuring-Spread-and-Arrow-Function"><a href="#Destructuring-Spread-and-Arrow-Function" class="headerlink" title="Destructuring, Spread and Arrow Function"></a>Destructuring, Spread and Arrow Function</h2><p>ES6 introduces some useful syntaxes like destructuring, spread and arrow function, which can be used to replace a lot of Lodash functions. For instance:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.head([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment">// =&gt; 1</span></span><br><span class="line">_.tail([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment">// =&gt; [2, 3]</span></span><br><span class="line"><span class="comment">// ES6 destructuring syntax</span></span><br><span class="line"><span class="keyword">const</span> [head, ...tail] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> say = _.rest(<span class="function">(<span class="params">who, fruits</span>) =&gt;</span> who + <span class="string">' likes '</span> + fruits.join(<span class="string">','</span>))</span><br><span class="line">say(<span class="string">'Jerry'</span>, <span class="string">'apple'</span>, <span class="string">'grape'</span>)</span><br><span class="line"><span class="comment">// ES6 spread syntax</span></span><br><span class="line">say = <span class="function">(<span class="params">who, ...fruits</span>) =&gt;</span> who + <span class="string">' likes '</span> + fruits.join(<span class="string">','</span>)</span><br><span class="line">say(<span class="string">'Mary'</span>, <span class="string">'banana'</span>, <span class="string">'orange'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line">_.constant(<span class="number">1</span>)() <span class="comment">// =&gt; 1</span></span><br><span class="line">_.identity(<span class="number">2</span>) <span class="comment">// =&gt; 2</span></span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">(<span class="function"><span class="params">x</span> =&gt;</span> (<span class="function"><span class="params">()</span> =&gt;</span> x))(<span class="number">1</span>)() <span class="comment">// =&gt; 1</span></span><br><span class="line">(<span class="function"><span class="params">x</span> =&gt;</span> x)(<span class="number">2</span>) <span class="comment">// =&gt; 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Partial application</span></span><br><span class="line"><span class="keyword">let</span> add = <span class="function">(<span class="params">a, b</span>) =&gt;</span> a + b</span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> add1 = _.partial(add, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">add1 = <span class="function"><span class="params">b</span> =&gt;</span> add(<span class="number">1</span>, b)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Curry</span></span><br><span class="line"><span class="comment">// Lodash</span></span><br><span class="line"><span class="keyword">let</span> curriedAdd = _.curry(add)</span><br><span class="line"><span class="keyword">let</span> add1 = curriedAdd(<span class="number">1</span>)</span><br><span class="line"><span class="comment">// ES6</span></span><br><span class="line">curriedAdd = <span class="function"><span class="params">a</span> =&gt;</span> b =&gt; a + b</span><br><span class="line">add1 = curriedAdd(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>For collection related operations, I prefer Lodash functions for they are more concise and can be chained; for functions that can be rewritten by arrow function, Lodash still seems more simple and clear. And according to some arguments in the <a href="#References">references</a>, the currying, <a href="https://lodash.com/docs/#add" target="_blank" rel="noopener">operators</a> and <a href="https://github.com/lodash/lodash/wiki/FP-Guide" target="_blank" rel="noopener">fp style</a> from Lodash are far more useful in scenarios like function composition.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Lodash adds great power to JavaScript language. One can write concise and efficient codes with minor efforts. Besides, Lodash is fully <a href="https://lodash.com/custom-builds" target="_blank" rel="noopener">modularized</a>. Though some of its functions will eventually deprecate, but I believe it’ll still bring many benifits to developers, while pushing the development of JS language as well.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.sitepoint.com/lodash-features-replace-es6/" target="_blank" rel="noopener">10 Lodash Features You Can Replace with ES6</a></li><li><a href="https://derickbailey.com/2016/09/12/does-es6-mean-the-end-of-underscore-lodash/" target="_blank" rel="noopener">Does ES6 Mean The End Of Underscore / Lodash?</a></li><li><a href="https://www.reddit.com/r/javascript/comments/41fq2s/why_should_i_use_lodash_or_rather_what_lodash/" target="_blank" rel="noopener">Why should I use lodash - reddit</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://lodash.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lodash&lt;/a&gt; is a well-known JavaScript utility library that makes it easy to manipulate arrays and objects, as well as functions, strings, etc. I myself enjoys its functional way to process collections, especially chaining and lazy evaluation. But as &lt;a href=&quot;http://www.ecma-international.org/ecma-262/6.0/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ECMAScript 2015 Standard&lt;/a&gt; (ES6) becomes widely supported by major browsers, and &lt;a href=&quot;https://babeljs.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Babel&lt;/a&gt;, the JavaScript compiler that transforms ES6 codes to ES5, plays a major role in today’s frontend development, it seems that most Lodash utilities can be replaced by ES6. But should we? In my opinion, Lodash will remain popular, for it still has lots of useful features that could improve the way of programming.&lt;/p&gt;
&lt;h2 id=&quot;map-and-Array-map-Are-Different&quot;&gt;&lt;a href=&quot;#map-and-Array-map-Are-Different&quot; class=&quot;headerlink&quot; title=&quot;_.map and Array#map Are Different&quot;&gt;&lt;/a&gt;&lt;code&gt;_.map&lt;/code&gt; and &lt;code&gt;Array#map&lt;/code&gt; Are Different&lt;/h2&gt;&lt;p&gt;&lt;code&gt;_.map&lt;/code&gt;, &lt;code&gt;_.reduce&lt;/code&gt;, &lt;code&gt;_.filter&lt;/code&gt; and &lt;code&gt;_.forEach&lt;/code&gt; are frequently used functions when processing collections, and ES6 provides direct support for them:&lt;/p&gt;
&lt;figure class=&quot;highlight js&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;_.map([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; i + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.reduce([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (sum, i) =&amp;gt; sum + i, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.filter([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; i &amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.forEach([&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;], (i) =&amp;gt; &amp;#123; &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(i) &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// becomes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].map(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; i + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].reduce(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;sum, i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; sum + i, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].filter(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; i &amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;].forEach(&lt;span class=&quot;function&quot;&gt;(&lt;span class=&quot;params&quot;&gt;i&lt;/span&gt;) =&amp;gt;&lt;/span&gt; &amp;#123; &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(i) &amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;But Lodash’s &lt;code&gt;_.map&lt;/code&gt; is more powerful, in that it works on objects, has iteratee / predicate shorthands, lazy evaluation, guards against null parameter, and has better performance.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="lodash" scheme="http://shzhangji.com/tags/lodash/"/>
    
      <category term="javascript" scheme="http://shzhangji.com/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/tags/frontend/"/>
    
      <category term="es6" scheme="http://shzhangji.com/tags/es6/"/>
    
  </entry>
  
  <entry>
    <title>Process Python Collections with Functional Programming</title>
    <link href="http://shzhangji.com/blog/2017/03/04/process-python-collections-with-functional-programming/"/>
    <id>http://shzhangji.com/blog/2017/03/04/process-python-collections-with-functional-programming/</id>
    <published>2017-03-04T14:32:17.000Z</published>
    <updated>2017-03-09T05:49:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>I develop Spark applications with Scala, and it has a very powerful <a href="http://docs.scala-lang.org/overviews/collections/introduction" target="_blank" rel="noopener">collection system</a>, in which functional programming is certainly a key. Java 8 also introduces Lambda Expression and Stream API. In JavaScript, there is a <a href="https://lodash.com/" target="_blank" rel="noopener">Lodash</a> library that provides powerful tools to process arrays and objects. When my primary work language changes to Python, I am wondering if it’s possible to manipulate collections in a FP way, and fortunately Python already provides syntax and tools for functional programming. Though list comprehension is the pythonic way to deal with collections, but the idea and concepts of FP is definitely worth learning.</p><h2 id="Wordcount-Example"><a href="#Wordcount-Example" class="headerlink" title="Wordcount Example"></a>Wordcount Example</h2><p>Let’s first write a snippet to count the word occurences from a paragraph, in of course a functional way.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">content = <span class="string">"""</span></span><br><span class="line"><span class="string">an apple orange the grape</span></span><br><span class="line"><span class="string">banana an apple melon</span></span><br><span class="line"><span class="string">an orange banana apple</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">word_matches = re.finditer(<span class="string">r'\S+'</span>, content)</span><br><span class="line">words = map(<span class="keyword">lambda</span> m: m.group(<span class="number">0</span>), word_matches)</span><br><span class="line">fruits = filter(<span class="keyword">lambda</span> s: len(s) &gt; <span class="number">3</span>, words)</span><br><span class="line">grouped_fruits = itertools.groupby(sorted(fruits))</span><br><span class="line">fruit_counts = map(<span class="keyword">lambda</span> t: (t[<span class="number">0</span>], len(list(t[<span class="number">1</span>]))), grouped_fruits)</span><br><span class="line">print(list(fruit_counts))</span><br></pre></td></tr></table></figure><p>Run this example and you’ll get a list of fruits, along with their counts:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(&apos;apple&apos;, 3), (&apos;banana&apos;, 2), (&apos;grape&apos;, 1), (&apos;melon&apos;, 1), (&apos;orange&apos;, 2)]</span><br></pre></td></tr></table></figure><p>This example includes most aspects of processing collections with FP style. For instance, <code>re.finditer</code> returns an <code>iterator</code> that is lazily evaluated; <code>map</code> and <code>filter</code> are used to do transformations; <code>itertools</code> module provides various functions to cope with iterables; and last but not least, the <code>lambda</code> expression, an easy way to define inline anonymous function. All of them will be described in the following sections.</p><a id="more"></a><h2 id="Ingredients-of-Functional-Programming"><a href="#Ingredients-of-Functional-Programming" class="headerlink" title="Ingredients of Functional Programming"></a>Ingredients of Functional Programming</h2><p>Python is far from being a functional language, but it provides some basic syntax and tools so that we can choose to write Python in a functional way.</p><h3 id="Function-as-First-class-Citizen"><a href="#Function-as-First-class-Citizen" class="headerlink" title="Function as First-class Citizen"></a>Function as First-class Citizen</h3><p>Function is data. It can be assigned to a variable, pass as a parameter to another function, or returned by a function. The later two cases also refers to higher order functions. Python makes it quite easy, you can define and pass around the function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">add_two = add</span><br><span class="line">print(add_two(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># =&gt; 3</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate</span><span class="params">(a, b, operation)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> operation(a, b)</span><br><span class="line"></span><br><span class="line">print(calculate(<span class="number">1</span>, <span class="number">2</span>, add)) <span class="comment"># =&gt; 3</span></span><br></pre></td></tr></table></figure><p>Or generate a new function from a function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_n</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> a + n</span><br><span class="line">    <span class="keyword">return</span> add</span><br><span class="line"></span><br><span class="line">add_1 = add_n(<span class="number">1</span>)</span><br><span class="line">print(add_1(<span class="number">1</span>)) <span class="comment"># =&gt; 2</span></span><br></pre></td></tr></table></figure><p>To use function in <code>map</code>, which applies the function to every element of the iterable:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(list(map(add_1, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))) <span class="comment"># =&gt; [2, 3, 4]</span></span><br></pre></td></tr></table></figure><p>For very short function, we can use lambda expression:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map(<span class="keyword">lambda</span> a: a + <span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><h3 id="Being-Lazy"><a href="#Being-Lazy" class="headerlink" title="Being Lazy"></a>Being Lazy</h3><p>Lazy evaluation means postponing the execution until it’s necessary. It’s a very common optimization strategy in big data transformation, becuase all map-like operations should be chained and assigned to a single task. In Python, there’s iterator, an stateful object that remembers the current element during iteration. Let’s assume <code>calc</code> is a heavy function, and the following two lines differ:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[calc(i) <span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]</span><br><span class="line">map(calc, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p>List comprehension is eager-evaluated, while <code>map</code> (from Python 3.x on) returns an iterator. You can use the <code>next</code> global function to fetch the next element, or take the first two results using:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> islice</span><br><span class="line">list(islice(map(calc, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]), <span class="number">2</span>))</span><br></pre></td></tr></table></figure><p>It’s worth mentioning that from Python 3.x on a lot of methods returns iterator instead of concrete list, you can refer to <a href="http://shzhangji.com/blog/2017/01/08/python-2-to-3-quick-guide/#Less-Lists-More-Views">this article</a>.</p><h3 id="Purity"><a href="#Purity" class="headerlink" title="Purity"></a>Purity</h3><p>A function is pure if its output only depends on its input, and it has no side-effect, i.e. without changing outer/global variable space. Here’re some examples of pure/non-pure functions:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inc</span><span class="params">(a)</span>:</span> <span class="comment"># pure</span></span><br><span class="line">    <span class="keyword">return</span> a + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">(a)</span>:</span> <span class="comment"># non-pure</span></span><br><span class="line">    i = len(a)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(name)</span>:</span> <span class="comment"># non-pure, change the console</span></span><br><span class="line">    print(<span class="string">'hi'</span>, name)</span><br></pre></td></tr></table></figure><p>Purity is a good functional style because:</p><ul><li>it makes you re-design the functions so that they become shorter;</li><li>and short functions are easier to test, have less bugs;</li><li>purity also enables parallel execution.</li></ul><p>In concurrency programming, sharing state, lock, and context switch are all performance killers. Pure functions ensures codes can be executed in parallel without coordination of states, and can be re-executed multiple times safely.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line">executor = ThreadPoolExecutor(<span class="number">5</span>)</span><br><span class="line">list(executor.map(add_1, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure><h3 id="Function-Composition"><a href="#Function-Composition" class="headerlink" title="Function Composition"></a>Function Composition</h3><p>There’re also topics on combining, currying, partially applying functions, so we can tackle complex problems with small well-defined functions. Python provides <code>decorator</code>, <code>generator</code> syntax, along with <code>functools</code>, <code>operator</code> modules for such tasks. These can be found in Python official documentation.</p><h2 id="Chaining-Operations"><a href="#Chaining-Operations" class="headerlink" title="Chaining Operations"></a>Chaining Operations</h2><p><code>map</code>, <code>filter</code>, and functions in <code>itertools</code> cannot be easily chained. We have to nest the function calls or introduce intermediate variables. Luckily, there’s an open-sourced <a href="https://github.com/EntilZha/PyFunctional" target="_blank" rel="noopener">PyFunctional</a> package that can help us transform or aggregate collections in a funcional way quite fluently.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functional <span class="keyword">import</span> seq</span><br><span class="line"></span><br><span class="line">seq(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)\</span><br><span class="line">    .map(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)\</span><br><span class="line">    .filter(<span class="keyword">lambda</span> x: x &gt; <span class="number">4</span>)\</span><br><span class="line">    .reduce(<span class="keyword">lambda</span> x, y: x + y)</span><br><span class="line"><span class="comment"># =&gt; 14</span></span><br></pre></td></tr></table></figure><h2 id="List-Comprehension-Or-map"><a href="#List-Comprehension-Or-map" class="headerlink" title="List Comprehension Or map?"></a>List Comprehension Or <code>map</code>?</h2><p>List comprehension and generator expression are the pythonic way of processing collections, and the communiy encourages using list comprehension instead of <code>map</code>, etc. There’s a nice <a href="http://stackoverflow.com/a/6407222/1030720" target="_blank" rel="noopener">answer</a> on StackOverflow that addresses the following principle: use <code>map</code> only when you already have a function defined. Otherwise just stick to listcomps for it’s more widely accepted. Neverthelss, one should still pay attention to the laziness of various methods.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Processing collections is only one application of functional programming. This program paradigm can be applied to other phases of designing your systems. Further materials like <a href="http://deptinfo.unice.fr/~roy/sicp.pdf" target="_blank" rel="noopener">SICP</a>, <a href="https://www.manning.com/books/functional-programming-in-scala" target="_blank" rel="noopener">Functional Programming in Scala</a> are all very informative. Hope you enjoy.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.python.org/3/howto/functional.html" target="_blank" rel="noopener">Functional Programming HOWTO</a></li><li><a href="http://kachayev.github.io/talks/uapycon2012/" target="_blank" rel="noopener">Functional Programming with Python</a></li><li><a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" target="_blank" rel="noopener">Itertools Recipes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I develop Spark applications with Scala, and it has a very powerful &lt;a href=&quot;http://docs.scala-lang.org/overviews/collections/introduction&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;collection system&lt;/a&gt;, in which functional programming is certainly a key. Java 8 also introduces Lambda Expression and Stream API. In JavaScript, there is a &lt;a href=&quot;https://lodash.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lodash&lt;/a&gt; library that provides powerful tools to process arrays and objects. When my primary work language changes to Python, I am wondering if it’s possible to manipulate collections in a FP way, and fortunately Python already provides syntax and tools for functional programming. Though list comprehension is the pythonic way to deal with collections, but the idea and concepts of FP is definitely worth learning.&lt;/p&gt;
&lt;h2 id=&quot;Wordcount-Example&quot;&gt;&lt;a href=&quot;#Wordcount-Example&quot; class=&quot;headerlink&quot; title=&quot;Wordcount Example&quot;&gt;&lt;/a&gt;Wordcount Example&lt;/h2&gt;&lt;p&gt;Let’s first write a snippet to count the word occurences from a paragraph, in of course a functional way.&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; re&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; itertools&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;content = &lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;an apple orange the grape&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;banana an apple melon&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;an orange banana apple&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;word_matches = re.finditer(&lt;span class=&quot;string&quot;&gt;r&#39;\S+&#39;&lt;/span&gt;, content)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;words = map(&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt; m: m.group(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;), word_matches)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fruits = filter(&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt; s: len(s) &amp;gt; &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, words)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;grouped_fruits = itertools.groupby(sorted(fruits))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;fruit_counts = map(&lt;span class=&quot;keyword&quot;&gt;lambda&lt;/span&gt; t: (t[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;], len(list(t[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]))), grouped_fruits)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print(list(fruit_counts))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;Run this example and you’ll get a list of fruits, along with their counts:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[(&amp;apos;apple&amp;apos;, 3), (&amp;apos;banana&amp;apos;, 2), (&amp;apos;grape&amp;apos;, 1), (&amp;apos;melon&amp;apos;, 1), (&amp;apos;orange&amp;apos;, 2)]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;This example includes most aspects of processing collections with FP style. For instance, &lt;code&gt;re.finditer&lt;/code&gt; returns an &lt;code&gt;iterator&lt;/code&gt; that is lazily evaluated; &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;filter&lt;/code&gt; are used to do transformations; &lt;code&gt;itertools&lt;/code&gt; module provides various functions to cope with iterables; and last but not least, the &lt;code&gt;lambda&lt;/code&gt; expression, an easy way to define inline anonymous function. All of them will be described in the following sections.&lt;/p&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
      <category term="functional programming" scheme="http://shzhangji.com/tags/functional-programming/"/>
    
  </entry>
  
  <entry>
    <title>Difference Between Lodash _.assign and _.assignIn</title>
    <link href="http://shzhangji.com/blog/2017/01/29/difference-between-lodash-assign-and-assignin/"/>
    <id>http://shzhangji.com/blog/2017/01/29/difference-between-lodash-assign-and-assignin/</id>
    <published>2017-01-29T06:18:29.000Z</published>
    <updated>2017-02-16T07:35:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>In Lodash, both <code>_.assign</code> and <code>_.assignIn</code> are ways to copy source objects’ properties into target object. According the <a href="https://lodash.com/docs/" target="_blank" rel="noopener">documentation</a>, <code>_.assign</code> processes <strong>own enumerable string keyed properties</strong>, while <code>_.assignIn</code> processes both <strong>own and inherited source properties</strong>. There’re also other companion functions like <code>_.forOwn</code> and <code>_.forIn</code>, <code>_.has</code> and <code>_.hasIn</code>. So what’s the difference between them?</p><p>In brief, the <code>In</code> in latter methods implies the way <code>for...in</code> loop behaves, which <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for...in" target="_blank" rel="noopener">iterates all enumerable properties of the object itself and those the object inherits from its constructor’s prototype</a>. JavaScript has an inheritance mechanism called prototype chain. When iterating an object’s properties with <code>for...in</code> or <code>_.forIn</code>, all properties appeared in the object and its prototype are processed, until the prototype resolves to <code>null</code>. Here’s the example code taken from Lodash’s doc:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Foo</span>(<span class="params"></span>) </span>&#123; <span class="keyword">this</span>.a = <span class="number">1</span>; &#125;</span><br><span class="line">Foo.prototype.b = <span class="number">2</span>;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Bar</span>(<span class="params"></span>) </span>&#123; <span class="keyword">this</span>.c = <span class="number">3</span>; &#125;</span><br><span class="line">Bar.prototype.d = <span class="number">4</span>;</span><br><span class="line">_.assign(&#123;<span class="attr">a</span>: <span class="number">0</span>&#125;, <span class="keyword">new</span> Foo, <span class="keyword">new</span> Bar); <span class="comment">// =&gt; &#123;a: 1, c: 3&#125;</span></span><br><span class="line">_.assignIn(&#123;<span class="attr">a</span>: <span class="number">0</span>&#125;, <span class="keyword">new</span> Foo, <span class="keyword">new</span> Bar); <span class="comment">// =&gt; &#123;a:1, b:2, c:3, d:4&#125;</span></span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="How-assign-Picks-Properties"><a href="#How-assign-Picks-Properties" class="headerlink" title="How _.assign Picks Properties"></a>How <code>_.assign</code> Picks Properties</h2><p>Let’s dissect the phrase “own enumerable string-keys properties” into three parts. </p><h3 id="Own-Property"><a href="#Own-Property" class="headerlink" title="Own Property"></a>Own Property</h3><p>JavaScript is a prototype-based language, but there’re several ways to simulate class and instance, like object literal, function prototype, <code>Object.create</code>, and the newly added <code>class</code> keyword. In either case, we can use <code>Object.prototype.hasOwnProperty()</code> to determine if the property is inherited or not.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> foo = <span class="keyword">new</span> Foo();</span><br><span class="line">foo.hasOwnProperty(<span class="string">'a'</span>); <span class="comment">// =&gt; true</span></span><br><span class="line"><span class="built_in">Object</span>.prototype.hasOwnProperty.call(foo, <span class="string">'b'</span>); <span class="comment">// =&gt; false</span></span><br></pre></td></tr></table></figure><p><code>Object.getOwnPropertyNames()</code> and <code>Object.keys()</code> can retrieve all properties defined directly in the object, except that <code>Object.keys()</code> only returns enumerable keys (see next section).</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> o1 = &#123;<span class="attr">a</span>: <span class="number">1</span>&#125;;</span><br><span class="line"><span class="keyword">let</span> o2 = <span class="built_in">Object</span>.create(o1);</span><br><span class="line">o2.b = <span class="number">2</span>;</span><br><span class="line"><span class="built_in">Object</span>.getOwnPropertyNames(o2); <span class="comment">// =&gt; ['b']</span></span><br><span class="line"><span class="built_in">Object</span>.keys(o2); <span class="comment">// =&gt; ['b']</span></span><br></pre></td></tr></table></figure><h3 id="Enumerable-Property"><a href="#Enumerable-Property" class="headerlink" title="Enumerable Property"></a>Enumerable Property</h3><p>Object property can be defined with either data descriptor or accessor descriptor. Among data descriptor options, the <code>enumerable</code> boolean indicates whether this property shows in <code>for...in</code> or <code>Object.keys()</code>. </p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> o = &#123;&#125;;</span><br><span class="line"><span class="built_in">Object</span>.defineProperty(o, <span class="string">'a'</span>, &#123; <span class="attr">enumerable</span>: <span class="literal">false</span>, <span class="attr">value</span>: <span class="number">1</span> &#125;);</span><br><span class="line"><span class="built_in">Object</span>.keys(o); <span class="comment">// =&gt; []</span></span><br><span class="line">o.propertyIsEnumerable(<span class="string">'a'</span>); <span class="comment">// =&gt; false</span></span><br></pre></td></tr></table></figure><p>You can refer to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperty" target="_blank" rel="noopener">Object.defineProperty()</a> for more information.</p><h3 id="String-keyed-Property"><a href="#String-keyed-Property" class="headerlink" title="String-keyed Property"></a>String-keyed Property</h3><p>Before ES6, object’s keys are always String. ES6 introduces a new primitive type <a href="https://developer.mozilla.org/en-US/docs/Glossary/Symbol" target="_blank" rel="noopener">Symbol</a>, which can be used as a key for private property. Symbol property is non-enumerable.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> s = <span class="built_in">Symbol</span>();</span><br><span class="line"><span class="keyword">let</span> o = &#123;&#125;;</span><br><span class="line">o[s] = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">Object</span>.keys(o); <span class="comment">// =&gt; []</span></span><br></pre></td></tr></table></figure><p>There’s a nice <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Enumerability_and_ownership_of_properties#Detection_Table" target="_blank" rel="noopener">Detection Table</a> to help you figure out which built-in methods process enumerable or inherited properties.</p><h2 id="assign-and-assignIn-Implementation"><a href="#assign-and-assignIn-Implementation" class="headerlink" title="_.assign and _.assignIn Implementation"></a><code>_.assign</code> and <code>_.assignIn</code> Implementation</h2><p>Both methods calls <code>_.keys</code> and <code>_.keysIn</code> respectively. <code>_.keys</code> calls <code>Object.keys()</code> and <code>_.keysIn</code> uses <code>for...in</code> loop. Actually <code>Object.keys()</code> is not difficult to implement. As mentioned above, <code>for...in</code> can be used to retrieve both own and inherited properties, while <code>hasOwnProperty</code> determines whether this property is defined in the object itself.</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">keys</span>(<span class="params">object</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> result = [];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">in</span> <span class="built_in">Object</span>(object)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">Object</span>.prototype.hasOwnProperty.call(object, key)) &#123;</span><br><span class="line">      result.push(key);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Object.assign()</code> does the same thing as <code>_.assign()</code>. Use Lodash if you need to run your code on older browsers.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign" target="_blank" rel="noopener">Object.assign() - JavaScript | MDN</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Inheritance_and_the_prototype_chain" target="_blank" rel="noopener">Inheritance and The Prototype Chain</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In Lodash, both &lt;code&gt;_.assign&lt;/code&gt; and &lt;code&gt;_.assignIn&lt;/code&gt; are ways to copy source objects’ properties into target object. According the &lt;a href=&quot;https://lodash.com/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt;, &lt;code&gt;_.assign&lt;/code&gt; processes &lt;strong&gt;own enumerable string keyed properties&lt;/strong&gt;, while &lt;code&gt;_.assignIn&lt;/code&gt; processes both &lt;strong&gt;own and inherited source properties&lt;/strong&gt;. There’re also other companion functions like &lt;code&gt;_.forOwn&lt;/code&gt; and &lt;code&gt;_.forIn&lt;/code&gt;, &lt;code&gt;_.has&lt;/code&gt; and &lt;code&gt;_.hasIn&lt;/code&gt;. So what’s the difference between them?&lt;/p&gt;
&lt;p&gt;In brief, the &lt;code&gt;In&lt;/code&gt; in latter methods implies the way &lt;code&gt;for...in&lt;/code&gt; loop behaves, which &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for...in&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;iterates all enumerable properties of the object itself and those the object inherits from its constructor’s prototype&lt;/a&gt;. JavaScript has an inheritance mechanism called prototype chain. When iterating an object’s properties with &lt;code&gt;for...in&lt;/code&gt; or &lt;code&gt;_.forIn&lt;/code&gt;, all properties appeared in the object and its prototype are processed, until the prototype resolves to &lt;code&gt;null&lt;/code&gt;. Here’s the example code taken from Lodash’s doc:&lt;/p&gt;
&lt;figure class=&quot;highlight javascript&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Foo&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;&amp;#123; &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;.a = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Foo.prototype.b = &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Bar&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;&amp;#123; &lt;span class=&quot;keyword&quot;&gt;this&lt;/span&gt;.c = &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;; &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Bar.prototype.d = &lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.assign(&amp;#123;&lt;span class=&quot;attr&quot;&gt;a&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&amp;#125;, &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Foo, &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Bar); &lt;span class=&quot;comment&quot;&gt;// =&amp;gt; &amp;#123;a: 1, c: 3&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;_.assignIn(&amp;#123;&lt;span class=&quot;attr&quot;&gt;a&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&amp;#125;, &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Foo, &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Bar); &lt;span class=&quot;comment&quot;&gt;// =&amp;gt; &amp;#123;a:1, b:2, c:3, d:4&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="lodash" scheme="http://shzhangji.com/tags/lodash/"/>
    
      <category term="javascript" scheme="http://shzhangji.com/tags/javascript/"/>
    
      <category term="frontend" scheme="http://shzhangji.com/tags/frontend/"/>
    
  </entry>
  
  <entry>
    <title>Python 2 to 3 Quick Guide</title>
    <link href="http://shzhangji.com/blog/2017/01/08/python-2-to-3-quick-guide/"/>
    <id>http://shzhangji.com/blog/2017/01/08/python-2-to-3-quick-guide/</id>
    <published>2017-01-08T04:26:54.000Z</published>
    <updated>2017-03-09T05:48:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>Few years ago I was programming Python 2.7, when 3.x was still not an option, because of its backward-incompatibiliy and lack of popular third-party libraries support. But now it’s safe to say Python 3 is <a href="http://py3readiness.org/" target="_blank" rel="noopener">totally ready</a>, and here’s a list of references for those (including me) who are adopting Python 3 with a 2.x background.</p><ol><li>All Strings Are Unicode</li><li><code>print</code> Becomes a Function</li><li>Less Lists More Views</li><li>Integer Division Returns Float</li><li>Comparison Operators Raises <code>TypeError</code></li><li>Set Literal Support</li><li>New String Formatting</li><li>Exception Handling</li><li>Global Function Changes</li><li>Renaming Modules and Relative Import</li></ol><h2 id="All-Strings-Are-Unicode"><a href="#All-Strings-Are-Unicode" class="headerlink" title="All Strings Are Unicode"></a>All Strings Are Unicode</h2><p>When dealing with non-ASCII encodings in Python 2, there’re <code>str</code>, <code>unicode</code>, <code>u&#39;...&#39;</code>, <code>s.encode()</code>, etc. In Python 3, there’re only <strong>text</strong> and <strong>binary data</strong>. The former is <code>str</code>, strings that are always represented in Unicode; the later is <code>bytes</code>, which is just a sequence of byte numbers.</p><ul><li>Conversion between <code>str</code> and <code>bytes</code>:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># str to bytes</span></span><br><span class="line"><span class="string">'str'</span>.encode(<span class="string">'UTF-8'</span>)</span><br><span class="line">bytes(<span class="string">'str'</span>, encoding=<span class="string">'UTF-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># bytes to str</span></span><br><span class="line"><span class="string">b'bytes'</span>.decode(<span class="string">'UTF-8'</span>)</span><br><span class="line">str(<span class="string">b'bytes'</span>, encoding=<span class="string">'UTF-8'</span>)</span><br></pre></td></tr></table></figure><ul><li><code>basestring</code> is removed, use <code>str</code> as type: <code>isinstance(s, str)</code></li><li><code>bytes</code> is immutable, the corresponding mutable version is <code>bytearray</code>.</li><li>The default source file encoding is UTF-8 now.</li></ul><a id="more"></a><h2 id="print-Becomes-a-Function"><a href="#print-Becomes-a-Function" class="headerlink" title="print Becomes a Function"></a><code>print</code> Becomes a Function</h2><p>In Python 2, <code>print</code> is a statement, and now it’s used as a function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span>   <span class="comment"># Old: print a new line</span></span><br><span class="line">print() <span class="comment"># New</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'hello'</span>, <span class="string">'world'</span>,          <span class="comment"># Old: trailing comma suppresses new line</span></span><br><span class="line">print(<span class="string">'hello'</span>, <span class="string">'world'</span>, end=<span class="string">' '</span>) <span class="comment"># New: end defaults to '\n'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> &gt;&gt;sys.stderr, <span class="string">'error'</span>     <span class="comment"># Old: write to stderr</span></span><br><span class="line">print(<span class="string">'error'</span>, file=sys.stderr) <span class="comment"># New</span></span><br></pre></td></tr></table></figure><p><code>print</code> function also provides <code>sep</code> and <code>flush</code> parameters:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'hello'</span>, <span class="string">'world'</span>, sep=<span class="string">','</span>, flush=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Instead of:</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">','</span>.join((<span class="string">'hello'</span>, <span class="string">'world'</span>))</span><br><span class="line">sys.stdout.flush()</span><br></pre></td></tr></table></figure><h2 id="Less-Lists-More-Views"><a href="#Less-Lists-More-Views" class="headerlink" title="Less Lists More Views"></a>Less Lists More Views</h2><p>A lot of well-known methods now return iterators, or ‘views’,  instead of eager-evaluated lists.</p><ul><li>Dictionary’s <code>keys</code>, <code>items</code>, and <code>values</code> methods, while removing <code>iterkeys</code>, <code>iteritems</code>, and <code>itervalues</code>. For example, when you need a sorted key list:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k = d.keys(); k.sort() <span class="comment"># Old</span></span><br><span class="line">k = sorted(d.keys())   <span class="comment"># New</span></span><br></pre></td></tr></table></figure><ul><li><code>map</code>, <code>filter</code>, and <code>zip</code>, while removing <code>imap</code> methods in <code>itertools</code> module. To get a concrete list, use list comprehension or the <code>list</code> global function:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[x * <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]</span><br><span class="line">list(map(<span class="keyword">lambda</span> x: x * <span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure><ul><li><code>range</code> is now equivalent to <code>xrange</code> in Python 2, the later is removed.</li><li>For iterators, the <code>next</code> method is renamed to <code>__next__</code>, and there’s a global <code>next</code> function, which accepts an iterator and calls its <code>__next__</code> method.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iter([<span class="number">1</span>]).next()     <span class="comment"># Old</span></span><br><span class="line">iter([<span class="number">1</span>]).__next__() <span class="comment"># New</span></span><br><span class="line">next(iter([<span class="number">1</span>]))      <span class="comment"># New</span></span><br></pre></td></tr></table></figure><h2 id="Integer-Division-Returns-Float"><a href="#Integer-Division-Returns-Float" class="headerlink" title="Integer Division Returns Float"></a>Integer Division Returns Float</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print 1 / 2   # Old: prints 0</span><br><span class="line">print 1 / 2.0 # Old: prints 0.5</span><br><span class="line">print(1 / 2)  # New: prints 0.5</span><br><span class="line">print(1 // 2) # New: prints 0</span><br></pre></td></tr></table></figure><ul><li>There’s no difference between <code>long</code> and <code>int</code> now, use <code>int</code> only.</li><li>Octal literals are represented as <code>0o755</code>, instead of <code>0755</code>.</li></ul><h2 id="Comparison-Operators-Raises-TypeError"><a href="#Comparison-Operators-Raises-TypeError" class="headerlink" title="Comparison Operators Raises TypeError"></a>Comparison Operators Raises <code>TypeError</code></h2><ul><li><code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>&gt;</code> can no longer be used between different types.</li><li><code>==</code> and <code>!=</code> remains the same.</li><li><code>cmp</code> parameter in <code>sort</code> is removed. Use <code>key</code> to extract a comparison key from each element.</li></ul><h2 id="Set-Literal-Support"><a href="#Set-Literal-Support" class="headerlink" title="Set Literal Support"></a>Set Literal Support</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = set([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment"># Old, also valid in Python 3</span></span><br><span class="line">s = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;      <span class="comment"># New</span></span><br><span class="line">s = set()          <span class="comment"># Empty set</span></span><br><span class="line">d = &#123;&#125;             <span class="comment"># Empty dict</span></span><br></pre></td></tr></table></figure><h2 id="New-String-Formatting"><a href="#New-String-Formatting" class="headerlink" title="New String Formatting"></a>New String Formatting</h2><p>Python 3 introduces a new form of string formatting, and it’s also back-ported to Python 2.x. The old <code>%s</code> formatting is still available in 3.x, but the <a href="https://docs.python.org/3/library/string.html#format-string-syntax" target="_blank" rel="noopener">new format</a> seems more expressive and powerful.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># by position</span></span><br><span class="line"><span class="string">'&#123;&#125;, &#123;&#125;, &#123;&#125;'</span>.format(<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>)    <span class="comment"># a, b, c</span></span><br><span class="line"><span class="string">'&#123;2&#125;, &#123;1&#125;, &#123;0&#125;'</span>.format(<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>) <span class="comment"># c, b, a</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># by name</span></span><br><span class="line"><span class="string">'Hello, &#123;name&#125;'</span>.format(name=<span class="string">'Jerry'</span>) <span class="comment"># Hello, Jerry</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># by attribute</span></span><br><span class="line">c = <span class="number">1</span> - <span class="number">2j</span></span><br><span class="line"><span class="string">'real: &#123;0.real&#125;'</span>.format(c) <span class="comment"># real: 1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># by index</span></span><br><span class="line"><span class="string">'X: &#123;0[0]&#125;, Y: &#123;0[1]&#125;'</span>.format((<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># X: 1, Y: 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># format number</span></span><br><span class="line"><span class="string">'&#123;:.2f&#125;'</span>.format(<span class="number">1.2</span>)   <span class="comment"># 1.20</span></span><br><span class="line"><span class="string">'&#123;:.2%&#125;'</span>.format(<span class="number">0.012</span>) <span class="comment"># 1.20%</span></span><br><span class="line"><span class="string">'&#123;:,&#125;'</span>.format(<span class="number">1234567</span>) <span class="comment"># 1,234,567</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># padding</span></span><br><span class="line"><span class="string">'&#123;:&gt;05&#125;'</span>.format(<span class="number">1</span>) <span class="comment"># 00001</span></span><br></pre></td></tr></table></figure><p>Furthermore, Python 3.6 introduces literal string interpolation (<a href="https://www.python.org/dev/peps/pep-0498/" target="_blank" rel="noopener">PEP 498</a>).</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">'Jerry'</span></span><br><span class="line">print(<span class="string">f'Hello, <span class="subst">&#123;name&#125;</span>'</span>)</span><br></pre></td></tr></table></figure><h2 id="Exception-Handling"><a href="#Exception-Handling" class="headerlink" title="Exception Handling"></a>Exception Handling</h2><p>Raise and catch exceptions in a more standard way:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Old</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="keyword">raise</span> Exception, <span class="string">'message'</span></span><br><span class="line"><span class="keyword">except</span> Exception, e:</span><br><span class="line">  tb = sys.exc_info()[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># New</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="keyword">raise</span> Exception(<span class="string">'message'</span>)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">  tb = e.__traceback__</span><br></pre></td></tr></table></figure><h2 id="Global-Function-Changes"><a href="#Global-Function-Changes" class="headerlink" title="Global Function Changes"></a>Global Function Changes</h2><p>Some global functions are (re)moved to reduce duplication and language cruft.</p><ul><li><code>reduce</code> is removed, use <code>functools.reduce</code>, or explict <code>for</code> loop instead.</li><li><code>apply</code> is removed, use <code>f(*args)</code> instead of <code>apply(f, args)</code>.</li><li><code>execfile</code> is removed, use <code>exec(open(fn).read())</code></li><li>Removed backticks, use <code>repr</code> instread.</li><li><code>raw_input</code> is renamed to <code>input</code>, and the old <code>input</code> behaviour can be achieved by <code>eval(input())</code></li></ul><h2 id="Renaming-Modules-and-Relative-Import"><a href="#Renaming-Modules-and-Relative-Import" class="headerlink" title="Renaming Modules and Relative Import"></a>Renaming Modules and Relative Import</h2><ul><li>Different URL modules are unified into <code>urllib</code> module, e.g.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen, Request</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line">req = Request(<span class="string">'http://shzhangji.com?'</span> + urlencode(&#123;<span class="string">'t'</span>: <span class="number">1</span>&#125;)</span><br><span class="line"><span class="keyword">with</span> urlopen(req) <span class="keyword">as</span> f:</span><br><span class="line">  print(f.read())</span><br></pre></td></tr></table></figure><ul><li>Some modules are renamed according to <a href="https://www.python.org/dev/peps/pep-0008" target="_blank" rel="noopener">PEP 8</a>, such as:<ul><li>ConfigParser -&gt; configparser</li><li>copy_reg -&gt; copyreg</li><li>test.test_support -&gt; test.support</li></ul></li><li>Some modules have both pure Python implementation along with an accelerated version, like StringIO and cStringIO. In Python 3, user should always import the standard module, and fallback would happen automatically.<ul><li>StringIO + cStringIO -&gt; io</li><li>pickle + cPickle -&gt; pickle</li></ul></li><li>All <code>import</code> forms are interpreted as absolute imports, unless started with <code>.</code>:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> somemod</span><br><span class="line"><span class="keyword">from</span> .somemod <span class="keyword">import</span> moremod</span><br></pre></td></tr></table></figure><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://docs.python.org/3/whatsnew/3.0.html" target="_blank" rel="noopener">What’s New In Python 3.0</a></li><li><a href="http://www.diveintopython3.net/porting-code-to-python-3-with-2to3.html" target="_blank" rel="noopener">Porting Code to Python 3 with 2to3</a></li><li><a href="http://sebastianraschka.com/Articles/2014_python_2_3_key_diff.html" target="_blank" rel="noopener">The key differences between Python 2.7.x and Python 3.x with examples</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Few years ago I was programming Python 2.7, when 3.x was still not an option, because of its backward-incompatibiliy and lack of popular third-party libraries support. But now it’s safe to say Python 3 is &lt;a href=&quot;http://py3readiness.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;totally ready&lt;/a&gt;, and here’s a list of references for those (including me) who are adopting Python 3 with a 2.x background.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All Strings Are Unicode&lt;/li&gt;
&lt;li&gt;&lt;code&gt;print&lt;/code&gt; Becomes a Function&lt;/li&gt;
&lt;li&gt;Less Lists More Views&lt;/li&gt;
&lt;li&gt;Integer Division Returns Float&lt;/li&gt;
&lt;li&gt;Comparison Operators Raises &lt;code&gt;TypeError&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set Literal Support&lt;/li&gt;
&lt;li&gt;New String Formatting&lt;/li&gt;
&lt;li&gt;Exception Handling&lt;/li&gt;
&lt;li&gt;Global Function Changes&lt;/li&gt;
&lt;li&gt;Renaming Modules and Relative Import&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;All-Strings-Are-Unicode&quot;&gt;&lt;a href=&quot;#All-Strings-Are-Unicode&quot; class=&quot;headerlink&quot; title=&quot;All Strings Are Unicode&quot;&gt;&lt;/a&gt;All Strings Are Unicode&lt;/h2&gt;&lt;p&gt;When dealing with non-ASCII encodings in Python 2, there’re &lt;code&gt;str&lt;/code&gt;, &lt;code&gt;unicode&lt;/code&gt;, &lt;code&gt;u&amp;#39;...&amp;#39;&lt;/code&gt;, &lt;code&gt;s.encode()&lt;/code&gt;, etc. In Python 3, there’re only &lt;strong&gt;text&lt;/strong&gt; and &lt;strong&gt;binary data&lt;/strong&gt;. The former is &lt;code&gt;str&lt;/code&gt;, strings that are always represented in Unicode; the later is &lt;code&gt;bytes&lt;/code&gt;, which is just a sequence of byte numbers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conversion between &lt;code&gt;str&lt;/code&gt; and &lt;code&gt;bytes&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# str to bytes&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&#39;str&#39;&lt;/span&gt;.encode(&lt;span class=&quot;string&quot;&gt;&#39;UTF-8&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bytes(&lt;span class=&quot;string&quot;&gt;&#39;str&#39;&lt;/span&gt;, encoding=&lt;span class=&quot;string&quot;&gt;&#39;UTF-8&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# bytes to str&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;b&#39;bytes&#39;&lt;/span&gt;.decode(&lt;span class=&quot;string&quot;&gt;&#39;UTF-8&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;str(&lt;span class=&quot;string&quot;&gt;b&#39;bytes&#39;&lt;/span&gt;, encoding=&lt;span class=&quot;string&quot;&gt;&#39;UTF-8&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;basestring&lt;/code&gt; is removed, use &lt;code&gt;str&lt;/code&gt; as type: &lt;code&gt;isinstance(s, str)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bytes&lt;/code&gt; is immutable, the corresponding mutable version is &lt;code&gt;bytearray&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The default source file encoding is UTF-8 now.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://shzhangji.com/categories/Programming/"/>
    
    
      <category term="python" scheme="http://shzhangji.com/tags/python/"/>
    
  </entry>
  
</feed>
