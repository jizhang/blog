---
layout: post
title: "Clojure实战(5)：Storm实时计算框架"
date: 2013-04-22 12:11
comments: true
categories: Tutorial
tags: [clojure, storm]
published: false
---

Storm简介
---------

上一章介绍的Hadoop工具能够对海量数据进行批量处理，采用分布式的并行计算架构，只需使用其提供的MapReduce API编写脚本即可。但随着人们对数据实时性的要求越来越高，如实时日志分析、实时推荐系统等，Hadoop就无能为力了。

这时，Storm诞生了。它的设计初衷就是提供一套分布式的实时计算框架，实现低延迟、高并发的海量数据处理，被誉为“Realtime Hadoop”。它提供了简单易用的API接口用于编写实时处理脚本；能够和现有各类消息系统整合；提供了HA、容错、事务、RPC等高级特性。

Storm的官网是：[storm-project.net](http://storm-project.net/)，它的[Wiki](https://github.com/nathanmarz/storm/wiki)上有非常详尽的说明文档。

### Storm与Clojure

Storm的主要贡献者[Nathan Marz](https://github.com/nathanmarz)和[徐明明](https://github.com/xumingming)都是活跃的Clojure开发者，因此在Storm框架中也提供了原生的[Clojure DSL](https://github.com/nathanmarz/storm/wiki/Clojure-DSL)。本文就将介绍如何使用这套DSL来编写Storm处理脚本。

Storm集群的安装配置这里不会讲述，具体请参考[这篇文档](https://github.com/nathanmarz/storm/wiki/Setting-up-a-Storm-cluster)。下文的脚本都运行在“本地模式”之下，因此即使不搭建集群也可以运行和调试。

<!-- more -->

Storm脚本的组件
---------------

<img src="http://storm-project.net/images/topology.png" height="200">

Storm脚本的英文名称叫做“Storm Topology”，直译过来是“拓扑结构”。这个脚本由两大类组建构成，`Spout`和`Bolt`，分别可以有任意多个。他们之间以“数据流”的方式连接起来，因此整体看来就像一张拓扑网络，因此得名`Topology`。

### Spout

数据源节点，是整个脚本的入口。Storm会不断调用该节点的`nextTuple()`方法来获取数据，分发给下游`Bolt`节点。`nextTuple()`方法中可以用各种方式从外部获取数据，如逐行读取一个文件、从消息队列（ZeroMQ、Kafka）中获取消息等。一个Storm脚本可以包含多个`Spout`节点，从而将多个数据流汇聚到一起进行处理。

### Bolt

数据处理节点，它是脚本的核心逻辑。它含有一个`execute()`方法，当接收到消息时，Storm会调用这个函数，并将消息传递给它。我们可以在`execute()`中对消息进行过滤（只接收符合条件的数据），或者进行聚合（统计某个条件的数据出现的次数）等。处理完毕后，这个节点可以选择将处理后的消息继续传递下去，或是持久化到数据库中。

`Bolt`同样是可以有多个的，且能够前后组合。`Bolt C`可以同时收取`Bolt A`和`Bolt B`的数据，并将处理结果继续传递给`Bolt D`。

此外， *一个Bolt可以产生多个实例* ，如某个`Bolt`包含复杂耗时的计算，那在运行时可以调高其并发数量（实例的个数），从而达到并行处理的目的。

### Tuple

`Tuple`是消息传输的基本单元，一条消息即一个`Tuple`。可以将其看做是一个`HashMap`对象，它能够包含任何可序列化的数据内容。对于简单的数据类型，如整型、字符串、Map等，Storm提供了内置的序列化支持。而用户自定义的数据类型，可以通过指定序列化/反序列化函数来处理。

### Stream Grouping

想象一个`Spout`连接了两个`Bolt`（或一个`Bolt`的两个实例），那数据应该如何分发呢？你可以选择轮询（`ShuffleGrouping`），或是广播（`GlobalGrouping`）、亦或是按照某一个字段进行哈希分组（`FieldGrouping`），这些都称作为[`Stream Grouping`](https://github.com/nathanmarz/storm/wiki/Concepts#stream-groupings)。

## 示例：WordCount

下面我们就来实现一个实时版的WordCount脚本，它由以下几个组件构成：

* sentence-spout：从已知的一段文字中随机选取一句话发送出来；
* split-bolt：将这句话按空格分割成单词；
* count-bolt：统计每个单词出现的次数，每五秒钟打印一次，并清零。

### 依赖项和配置文件

首先使用`lein new`新建一个项目，并修改`project.clj`文件：

```clojure
(defproject cia-storm "0.1.0-SNAPSHOT"
  ...
  :dependencies [[org.clojure/clojure "1.4.0"]
                 [org.clojure/tools.logging "0.2.6"]]
  :profiles {:dev {:dependencies [[storm "0.8.2"]]}}
  :plugins [[lein2-eclipse "2.0.0"]]
  :aot [cia-storm.wordcount])
```

其中`:profiles`表示定义不同的用户配置文件。Leiningen有类似于Maven的配置文件体系（profile），每个配置文件中可以定义`project.clj`所支持的各种属性，执行时会进行合并。`lein`命令默认调用`:dev`、`:user`等配置文件，可以使用`lein with-profiles prod run`来指定配置文件。具体可以参考[这份文档](https://github.com/technomancy/leiningen/blob/master/doc/PROFILES.md)。

这里将`[storm "0.8.2"]`依赖项定义在了`:dev`配置下，如果直接定义在外层的`:dependencies`下，那在使用`lein uberjar`进行打包时，会将`storm.jar`包含在最终的Jar包中，提交到Storm集群运行时就会报冲突。而`lein uberjar`默认会跳过`:dev`配置，所以才这样定义。

`:aot`表示`Ahead Of Time`，即预编译。我们在[Clojure实战（3）](http://shzhangji.com/blog/2012/12/16/cia-noir-3/)中提过`:gen-class`这个标识表示为当前`.clj`文件生成一个`.class`文件，从而能够作为`main`函数使用，因此也需要在`project.clj`中添加`:main`标识，指向这个`.clj`文件的命名空间。如果想为其它的命名空间也生成对应的`.class`文件，就需要用到`:aot`了。它的另一个用处是加速Clojure程序的启动速度。
